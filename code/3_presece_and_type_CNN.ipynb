{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.clouddiver.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/arwtdydhqhfa.helamind.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/andogaru.fumiko.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.summernight.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.cereris.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.alone.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ï¿½TAKUMIÂ³ï¿½OÐ¯DIN -Apocalyptic War-(Re Mastering).mp3 å¯¹åº”äºŽ song ID ant.ordin-tc åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/ant.ordin-tc.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anthony.lolk_muricaaaaa.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Langley_D - deli.+é§„ã€…å­ - æœ€æžœã¦ã®å‹‡è€…ã«ãƒ©ãƒ–ã‚½ãƒ³ã‚°ã‚’.ogg å¯¹åº”äºŽ song ID anoppo.furiy åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.furiy.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/aboal.43201.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Vicetoneã€Kat Nestel - Angels (Radio Edit).wav å¯¹åº”äºŽ song ID asuna_37 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/asuna_37.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.rainbow.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ self-dissociation - Lidelleã€Sobremã€Sennzai.ogg å¯¹åº”äºŽ song ID anoppo.selfdissociation åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.selfdissociation.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.rainmaker.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã‚³ãƒ³ã‚¦ã‚§ã‚¤ã®å­ - sta.ogg å¯¹åº”äºŽ song ID anoppo.conwayschild åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.conwayschild.cytoidlevel\n",
      "æœªæ‰¾åˆ° charts æ–‡ä»¶ ARo.txt å¯¹åº”äºŽ song ID enteraname6 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/AR-1.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ é»’é­” - Banbard (Chroma Remix).ogg å¯¹åº”äºŽ song ID anoppo.banbard åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.banbard.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å‰Šé™¤ (Sakuzyo) - Amateras.ogg å¯¹åº”äºŽ song ID anoppo.amateras åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.amateras.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã‹ã‚ã‚Šã‚_åˆéŸ³ãƒŸã‚¯-ãƒ’ã‚¢ã‚½ãƒ“-_feat.-åˆéŸ³ãƒŸã‚¯_(2).ogg å¯¹åº”äºŽ song ID aniloid.hiasobi åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/aniloid.hiasobi.cytoidlevel\n",
      "æœªæ‰¾åˆ° charts æ–‡ä»¶ ä¿—ç‰©ãƒ•ã‚§ã‚¹ãƒ†ã‚£ãƒãƒ«.json å¯¹åº”äºŽ song ID anoppo.su åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.su.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Sta _ B - ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚·ãƒ³ãƒ¡ãƒˆãƒªãƒ¼(1).mp3 å¯¹åº”äºŽ song ID anoppo.super åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.super.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å‰Šé™¤ - PANDORA PARADOXXX.ogg å¯¹åº”äºŽ song ID anoppo.pandora åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.pandora.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/ant.future.dominators.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.cord.reborn.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ With a Billion Worldful of 3 - Miliã€DE DE MOUSE.ogg å¯¹åº”äºŽ song ID anoppo.withabillionworldfulofthree åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.withabillionworldfulofthree.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å¤©hshsP.mp3 å¯¹åº”äºŽ song ID angelll.theweak åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/angelll.theweak.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã€Hardcoreã€‘Requillio _ Dopam!ne ðŸ‘»Free DLðŸ‘».mp3 å¯¹åº”äºŽ song ID ant.requillio-t3 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/ant.requillio-t3.cytoidlevel\n",
      "æ— æ³•è¯»å– /data1/yuchen/cytoid/final_code/../dataset/A/archore.lnd.lnyh.cytoidlevel/level.json: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/ap_mumayoru.ely.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ kei_iwata - ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢â†‘â†‘ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼.ogg å¯¹åº”äºŽ song ID amaneku.frontier_exploler åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/amaneku.frontier_exploler.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/ap_megalice.ely.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.wwp.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ (éŸ³æº) ã€SDVXã€‘ ãã—ã¦é»„é‡‘éƒ·ã¸ ã€NOFXã€‘ - 1.(éŸ³æº) [SDVX] ãã—ã¦é»„é‡‘éƒ·ã¸ [NOFX](Av29726758,P1).mp3 å¯¹åº”äºŽ song ID anoppo.golden åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.golden.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ é›²è½kyuuå¤© - Chapter.Qï¼šEuphoric World - Rabbit House.ogg å¯¹åº”äºŽ song ID anoppo.euphoricworld åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.euphoricworld.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Sta,bqã‚¹ã‚¿ãƒ‚ã‚ª - ã‚¢ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ãƒ³ãƒ¡ãƒˆãƒªãƒ¼.ogg å¯¹åº”äºŽ song ID anoppo.ink2 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.ink2.cytoidlevel\n",
      "ç›®å½•ä¸å­˜åœ¨: /data1/yuchen/cytoid/final_code/../dataset/C\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ kanone,Sennzai - èŠ±ã¨ã€é›ªã¨ã€ãƒ‰ãƒ©ãƒ ãƒ³ãƒ™ãƒ¼ã‚¹.ogg å¯¹åº”äºŽ song ID ztz.huayilun åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.huayilun.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ç”³ä¸œè¾‰ - NB Blast.mp3 å¯¹åº”äºŽ song ID zeng.nbblast åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.nbblast.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã‚¤ãƒ­ãƒ‰ãƒªãƒŸãƒ‰ãƒª - conflict (æ–‰å”±).ogg å¯¹åº”äºŽ song ID ztz.conflictcover åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.conflictcover.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Rintaro Soma - sÃ¸lips.ogg å¯¹åº”äºŽ song ID ztz.solips åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.solips.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ¢ãƒªãƒ¢ãƒªã‚ã¤ã— - Grand-Guignol.mp3 å¯¹åº”äºŽ song ID zeng.grandguignol åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.grandguignol.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ æ˜Ÿæ²³ä¸€å¤©.mp3 å¯¹åº”äºŽ song ID zirei.st åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.st.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ“ãƒ¼ãƒˆã¾ã‚ŠãŠ,ã‚ã¾ã­ - ã‚¦ã‚µãƒ†ã‚¤20XX.ogg å¯¹åº”äºŽ song ID ztz.usatei20xxre åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.usatei20xxre.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã‹ã‚ã‚Šã‚ - Hello (BPM) 2021.mp3 å¯¹åº”äºŽ song ID zeng.hellobpm åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.hellobpm.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Î£vreka.mp3 å¯¹åº”äºŽ song ID zirei.evreka åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.evreka.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ¢ãƒªãƒ¢ãƒªã‚ã¤ã— - Grand-Guignol.mp3 å¯¹åº”äºŽ song ID zeng.grand åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.grand.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ¢ãƒ³ãƒ€ã‚¤ãƒŠã‚¤ãƒˆãƒªãƒƒãƒ‘ãƒ¼ï¼.mp3 å¯¹åº”äºŽ song ID zirei.mondai åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.mondai.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å¢æ–‡éŸ¬ - å¥‡è½®ï¼æˆ‘çš„è‹±é›„ï¼ˆã€Šæ¿€æˆ˜å¥‡è½®2ã€‹OPï¼‰.mp3 å¯¹åº”äºŽ song ID zeng.qilunmyhero åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.qilunmyhero.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å…­å…†å¹´ã¨ä¸€å¤œç‰©èªžï¼Œï¼Œ.mp3 å¯¹åº”äºŽ song ID zhong_yu_six åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zhong_yu_six.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ç´°æ±Ÿæ…Žæ²» - Kattobi KEIKYU Rider.ogg å¯¹åº”äºŽ song ID ztz.kattobikeikyurider åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.kattobikeikyurider.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Team Grimoire - Excalibur ï½žRevived resolutionï½ž.ogg å¯¹åº”äºŽ song ID ztz.excalibur åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.excalibur.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãºã®ã‚Œã‚Š - Desperado Waltz.ogg å¯¹åº”äºŽ song ID ztz.desperadowaltz åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.desperadowaltz.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ miko - æ‚£éƒ¨ã§æ­¢ã¾ã£ã¦ã™ãæº¶ã‘ã‚‹ - ç‹‚æ°—ã®ä¼˜æ˜™åŽé™¢.ogg å¯¹åº”äºŽ song ID ztz.huanbu åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.huanbu.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Vâˆ…rstia.mp3 å¯¹åº”äºŽ song ID zirei.vo åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.vo.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã²ã¨ã‚Šãã‚Šã®ã‚¨ãƒ‡ãƒ³.mp3 å¯¹åº”äºŽ song ID zirei.d36 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.d36.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ æœ§æœˆ.mp3 å¯¹åº”äºŽ song ID zirei.ml åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.ml.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ“ãƒ¼ãƒˆã¾ã‚ŠãŠ,ã‚ã¾ã­ - ã‚¦ã‚µãƒ†ã‚¤20XX.mp3 å¯¹åº”äºŽ song ID ztz.usatei20xx åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.usatei20xx.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ”ãƒŽã‚­ã‚ªãƒ”ãƒ¼,åˆéŸ³ãƒŸã‚¯ - è…ã‚Œå¤–é“ã¨ãƒãƒ§ã‚³ãƒ¬ã‚ãƒˆ.ogg å¯¹åº”äºŽ song ID ztz.heterodoxusandchocolate åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.heterodoxusandchocolate.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ åˆéŸ³ - åƒæœ¬æ¡œã€åä¼¶è¨ˆç•« F ä¸­æ–‡å­—å¹•ã€‘.mp3 å¯¹åº”äºŽ song ID zhong_yu_1219 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zhong_yu_1219.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Se-U-Ra - ãƒã‚¸ãƒžã‚­ã‚»ã‚«ã‚¤ã®ç‹‚é¨’æ›².mp3 å¯¹åº”äºŽ song ID zeng.kuangsao åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.kuangsao.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ è¶…ç†Šè²“çš„å‘¨éŠè¨˜.mp3 å¯¹åº”äºŽ song ID zirei.fanta åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.fanta.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Taikes - ä¸–ç•Œå‡½æ•°~WorldÂ Function~.mp3 å¯¹åº”äºŽ song ID zeng.worldfunction åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.worldfunction.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Ponchi,æ‰“æ‰“ã ã„ãš - æ˜Ÿæ²³ä¸€å¤© (Ponchiâ™ªRemix).ogg å¯¹åº”äºŽ song ID ztz.xhytrmx åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.xhytrmx.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ‡ãƒ«ã‚¿ãƒ©ã‚¤ã‚ºã‚¯ãƒ­ãƒ¼ã®ãƒ†ãƒ¼ãƒž-å®‰æ¿‘åœ£.mp3 å¯¹åº”äºŽ song ID ztz.delta åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.delta.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ç›Ÿæœˆ.mp3 å¯¹åº”äºŽ song ID zirei.ddd åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.ddd.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å°é‡Žç§€å¹¸ - Prophesy One.ogg å¯¹åº”äºŽ song ID ztz.prophesy1 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.prophesy1.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ stÎµganography.mp3 å¯¹åº”äºŽ song ID zirei.steganography åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.steganography.cytoidlevel\n",
      "æœªæ‰¾åˆ° charts æ–‡ä»¶ loveand - å‰¯æœ¬.txt å¯¹åº”äºŽ song ID zeng.loveandj åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.loveandj.cytoidlevel\n",
      "æœªæ‰¾åˆ° charts æ–‡ä»¶ emp - å‰¯æœ¬.txt å¯¹åº”äºŽ song ID zeng.emp åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.emp.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ æ¸…æ°´é”ä¹Ÿ - IMAGE-MATERIAL-.mp3 å¯¹åº”äºŽ song ID zeng.image åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.image.cytoidlevel\n",
      "æ€»å…±è·³è¿‡çš„æ›²å­æ•°é‡: 69\n",
      "è·³è¿‡åŽŸå›  'json_decode_error': 15 ä¸ªæ›²å­\n",
      "è·³è¿‡åŽŸå›  'missing_audio_file': 49 ä¸ªæ›²å­\n",
      "è·³è¿‡åŽŸå›  'missing_charts_file': 4 ä¸ªæ›²å­\n",
      "è·³è¿‡åŽŸå›  'read_error': 1 ä¸ªæ›²å­\n",
      "è·³è¿‡åŽŸå›  'missing_directory': 1 ä¸ªæ›²å­\n",
      "Filtered Data Count (Difficulty>=15): 217\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/artzumaru.asunoyozorashoukanhen.cytoidlevel/AsunoYozora.hard.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.miracleallextracoremix.cytoidlevel/ex.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.pandora06.cytoidlevel/ex.Tag.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.pandora01.cytoidlevel/exnewnew.Tag.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.calamityfortune.cytoidlevel/hard.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.intensesinging.cytoidlevel/intense.Tag.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence Train Size: 858862\n",
      "Presence Validation Size: 214716\n",
      "Presence Validation Size after split: 107358\n",
      "Presence Test Size: 107358\n",
      "Epoch 1/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3996\n",
      "Saved Best Presence Model\n",
      "Epoch 2/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3695\n",
      "Saved Best Presence Model\n",
      "Epoch 3/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3430\n",
      "Saved Best Presence Model\n",
      "Epoch 4/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Saved Best Presence Model\n",
      "Epoch 5/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3150\n",
      "Saved Best Presence Model\n",
      "Epoch 6/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3057\n",
      "Saved Best Presence Model\n",
      "Epoch 7/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2988\n",
      "Saved Best Presence Model\n",
      "Epoch 8/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2934\n",
      "Saved Best Presence Model\n",
      "Epoch 9/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2872\n",
      "Saved Best Presence Model\n",
      "Epoch 10/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2834\n",
      "Saved Best Presence Model\n",
      "Epoch 11/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2771\n",
      "Saved Best Presence Model\n",
      "Epoch 12/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2765\n",
      "Saved Best Presence Model\n",
      "Epoch 13/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2746\n",
      "Saved Best Presence Model\n",
      "Epoch 14/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2748\n",
      "Epoch 15/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2700\n",
      "Saved Best Presence Model\n",
      "Epoch 16/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2707\n",
      "Epoch 17/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2649\n",
      "Saved Best Presence Model\n",
      "Epoch 18/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2646\n",
      "Saved Best Presence Model\n",
      "Epoch 19/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2626\n",
      "Saved Best Presence Model\n",
      "Epoch 20/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2617\n",
      "Saved Best Presence Model\n",
      "Epoch 21/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2600\n",
      "Saved Best Presence Model\n",
      "Epoch 22/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2579\n",
      "Saved Best Presence Model\n",
      "Epoch 23/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2619\n",
      "Epoch 24/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2576\n",
      "Saved Best Presence Model\n",
      "Epoch 25/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2602\n",
      "Epoch 26/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2557\n",
      "Saved Best Presence Model\n",
      "Epoch 27/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2583\n",
      "Epoch 28/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2545\n",
      "Saved Best Presence Model\n",
      "Epoch 29/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2545\n",
      "Saved Best Presence Model\n",
      "Epoch 30/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2543\n",
      "Saved Best Presence Model\n",
      "Epoch 31/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2520\n",
      "Saved Best Presence Model\n",
      "Epoch 32/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2531\n",
      "Epoch 33/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2526\n",
      "Epoch 34/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2506\n",
      "Saved Best Presence Model\n",
      "Epoch 35/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2528\n",
      "Epoch 36/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2504\n",
      "Saved Best Presence Model\n",
      "Epoch 37/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2506\n",
      "Epoch 38/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2498\n",
      "Saved Best Presence Model\n",
      "Epoch 39/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2491\n",
      "Saved Best Presence Model\n",
      "Epoch 40/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2503\n",
      "Epoch 41/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2486\n",
      "Saved Best Presence Model\n",
      "Epoch 42/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2474\n",
      "Saved Best Presence Model\n",
      "Epoch 43/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2475\n",
      "Epoch 44/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2479\n",
      "Epoch 45/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2472\n",
      "Saved Best Presence Model\n",
      "Epoch 46/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2492\n",
      "Epoch 47/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2457\n",
      "Saved Best Presence Model\n",
      "Epoch 48/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2474\n",
      "Epoch 49/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2457\n",
      "Epoch 50/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205621/3220993348.py:1229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Train Size: 858862\n",
      "Type Validation Size: 214716\n",
      "Type Validation Size after split: 107358\n",
      "Type Test Size: 107358\n",
      "Epoch 1/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1162, Train Acc: 83.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1110, Validation Acc: 83.77%\n",
      "Saved Best Type Model\n",
      "Epoch 2/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1107, Train Acc: 83.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1060, Validation Acc: 83.95%\n",
      "Saved Best Type Model\n",
      "Epoch 3/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1071, Train Acc: 83.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1023, Validation Acc: 84.24%\n",
      "Saved Best Type Model\n",
      "Epoch 4/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1041, Train Acc: 84.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0988, Validation Acc: 84.75%\n",
      "Saved Best Type Model\n",
      "Epoch 5/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1021, Train Acc: 84.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0965, Validation Acc: 85.04%\n",
      "Saved Best Type Model\n",
      "Epoch 6/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1002, Train Acc: 84.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0944, Validation Acc: 85.43%\n",
      "Saved Best Type Model\n",
      "Epoch 7/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0987, Train Acc: 84.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0936, Validation Acc: 85.50%\n",
      "Saved Best Type Model\n",
      "Epoch 8/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0976, Train Acc: 85.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0915, Validation Acc: 85.89%\n",
      "Saved Best Type Model\n",
      "Epoch 9/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0966, Train Acc: 85.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0907, Validation Acc: 86.11%\n",
      "Saved Best Type Model\n",
      "Epoch 10/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0957, Train Acc: 85.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0899, Validation Acc: 86.11%\n",
      "Saved Best Type Model\n",
      "Epoch 11/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0947, Train Acc: 85.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0896, Validation Acc: 86.29%\n",
      "Saved Best Type Model\n",
      "Epoch 12/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0940, Train Acc: 85.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0880, Validation Acc: 86.39%\n",
      "Saved Best Type Model\n",
      "Epoch 13/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0934, Train Acc: 85.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0887, Validation Acc: 86.56%\n",
      "Epoch 14/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0930, Train Acc: 85.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0894, Validation Acc: 86.34%\n",
      "Epoch 15/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0925, Train Acc: 85.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0875, Validation Acc: 86.56%\n",
      "Saved Best Type Model\n",
      "Epoch 16/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0919, Train Acc: 85.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0867, Validation Acc: 86.64%\n",
      "Saved Best Type Model\n",
      "Epoch 17/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0916, Train Acc: 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0861, Validation Acc: 86.79%\n",
      "Saved Best Type Model\n",
      "Epoch 18/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0911, Train Acc: 86.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0856, Validation Acc: 86.66%\n",
      "Saved Best Type Model\n",
      "Epoch 19/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0907, Train Acc: 86.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0855, Validation Acc: 86.73%\n",
      "Saved Best Type Model\n",
      "Epoch 20/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0905, Train Acc: 86.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0858, Validation Acc: 86.91%\n",
      "Epoch 21/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0901, Train Acc: 86.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0850, Validation Acc: 86.90%\n",
      "Saved Best Type Model\n",
      "Epoch 22/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0900, Train Acc: 86.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0841, Validation Acc: 86.98%\n",
      "Saved Best Type Model\n",
      "Epoch 23/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0897, Train Acc: 86.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0848, Validation Acc: 86.78%\n",
      "Epoch 24/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0895, Train Acc: 86.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0846, Validation Acc: 86.98%\n",
      "Epoch 25/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0891, Train Acc: 86.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0838, Validation Acc: 86.91%\n",
      "Saved Best Type Model\n",
      "Epoch 26/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0892, Train Acc: 86.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0845, Validation Acc: 87.06%\n",
      "Epoch 27/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0889, Train Acc: 86.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0826, Validation Acc: 87.28%\n",
      "Saved Best Type Model\n",
      "Epoch 28/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0886, Train Acc: 86.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0834, Validation Acc: 87.16%\n",
      "Epoch 29/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 85.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 30/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 31/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 32/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 33/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 34/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 35/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 36/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 37/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 38/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 39/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 40/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 41/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 42/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 43/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 44/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 45/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 46/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 47/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 48/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 49/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 50/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205621/3220993348.py:1415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  type_model.load_state_dict(torch.load(best_type_model_path))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1426: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path, map_location=device))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1431: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  type_model.load_state_dict(torch.load(best_type_model_path, map_location=device))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1435: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNOnsetDetector(\n",
       "  (conv1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2560, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Integrated Pipeline Example with LSTM Model\n",
    "# This Notebook integrates the training and evaluation of Presence and Type models across two stages and adds a note position prediction model based on LSTM.\n",
    "# \n",
    "# Please ensure to create a `model` folder before running to save the model files.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Import Necessary Libraries\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # Move to the top\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import enum\n",
    "import tqdm\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Constants Definition\n",
    "\n",
    "# STFT constants\n",
    "SAMPLE_RATE = 22050  \n",
    "HOP_LENGTH = 512     \n",
    "NMELS = 128        \n",
    "WINDOW_SIZE = 40  # Number of frames before and after\n",
    "NUM_EPOCHS = 50    # Number of training epochs\n",
    "BATCH_SIZE = 64    # Batch size\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT = 0.5      # Dropout rate\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Preprocessing Functions\n",
    "\n",
    "def contains_non_ascii(s: str) -> bool:\n",
    "    \"\"\"Check if the string contains non-ASCII characters.\"\"\"\n",
    "    return any(ord(c) > 127 for c in s)\n",
    "\n",
    "def extract_level_json_multiple(directories: List[Path], min_difficulty: int = 15) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract level.json files from multiple directories, organize relevant information, and filter songs by specified difficulty.\n",
    "    If an unparseable name or other issue is encountered, skip the song.\n",
    "\n",
    "    Args:\n",
    "        directories (List[Path]): List of main directories containing multiple subfolders.\n",
    "        min_difficulty (int): Minimum difficulty level.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Contains relevant information for each level, limited to songs with difficulty >= min_difficulty.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    skipped_songs = 0\n",
    "    skipped_reasons = defaultdict(int)\n",
    "\n",
    "    for directory in directories:\n",
    "        if not directory.exists():\n",
    "            print(f\"Directory does not exist: {directory}\")\n",
    "            skipped_reasons['missing_directory'] += 1\n",
    "            continue\n",
    "        for folder_path in directory.iterdir():\n",
    "            if not folder_path.is_dir():\n",
    "                continue\n",
    "            json_file_path = folder_path / 'level.json'\n",
    "            if not json_file_path.is_file():\n",
    "                print(f\"Missing level.json file in {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_level_json'] += 1\n",
    "                continue\n",
    "            try:\n",
    "                with json_file_path.open('r', encoding='utf-8') as json_file:\n",
    "                    level_data = json.load(json_file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"JSON parse error: {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['json_decode_error'] += 1\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Unable to read {json_file_path}: {e}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['read_error'] += 1\n",
    "                continue\n",
    "\n",
    "            # Ensure all necessary fields exist\n",
    "            try:\n",
    "                level_id = level_data['id']\n",
    "                charts = level_data['charts']\n",
    "                music = level_data['music']\n",
    "            except KeyError as e:\n",
    "                print(f\"Missing key {e} in file: {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_keys'] += 1\n",
    "                continue\n",
    "\n",
    "            if not charts:\n",
    "                print(f\"No charts found in file {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['empty_charts'] += 1\n",
    "                continue\n",
    "\n",
    "            chart_difficulty = charts[0].get('difficulty', 0)\n",
    "            if chart_difficulty < min_difficulty:\n",
    "                continue\n",
    "\n",
    "            audio_file_name = music.get('path', '')\n",
    "            if not audio_file_name:\n",
    "                print(f\"No music path specified in file {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_music_path'] += 1\n",
    "                continue\n",
    "\n",
    "            audio_file_extensions = ['.mp3', '.ogg', '.wav']\n",
    "            audio_file_path = None\n",
    "            for ext in audio_file_extensions:\n",
    "                aud_path = folder_path / audio_file_name\n",
    "                if aud_path.suffix.lower() == ext and aud_path.is_file():\n",
    "                    audio_file_path = aud_path\n",
    "                    break\n",
    "            if audio_file_path is None:\n",
    "                print(f\"Audio file {audio_file_name} for song ID {level_id} not found in {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_audio_file'] += 1\n",
    "                continue\n",
    "\n",
    "            charts_path = folder_path / charts[0].get('path', '')\n",
    "            if not charts_path.is_file():\n",
    "                print(f\"Charts file {charts[0].get('path', '')} for song ID {level_id} not found in {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_charts_file'] += 1\n",
    "                continue\n",
    "\n",
    "            # Create unique ID, ensure name is parseable\n",
    "            unique_id = f\"{directory.name}_{level_id}\"\n",
    "            try:\n",
    "                unique_id.encode('ascii')  # Check if ASCII\n",
    "            except UnicodeEncodeError:\n",
    "                print(f\"Unparseable unique_id: {unique_id}, skipping song\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['unparseable_unique_id'] += 1\n",
    "                continue\n",
    "\n",
    "            # Add to result\n",
    "            result[unique_id] = {\n",
    "                'level': level_data,\n",
    "                'mp3_path': str(audio_file_path),\n",
    "                'charts_path': str(charts_path),\n",
    "                'charter': level_data.get('charter', ''),\n",
    "                'type': charts[0].get('type', ''),\n",
    "                'difficulty': chart_difficulty\n",
    "            }\n",
    "\n",
    "    print(f\"Total number of skipped songs: {skipped_songs}\")\n",
    "    for reason, count in skipped_reasons.items():\n",
    "        print(f\"Skipped reason '{reason}': {count} songs\")\n",
    "    return result\n",
    "\n",
    "def extract_charts(path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract chart data from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the chart JSON file.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Chart data.\n",
    "    \"\"\"\n",
    "    file_path = Path(path)\n",
    "    if file_path.exists() and file_path.is_file():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return data\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"JSON decode error for file: {path}\")\n",
    "    return {}\n",
    "\n",
    "def find_single_tempo_songs(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Filter songs with constant BPM.\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): Dictionary containing all song information.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: List of songs with constant BPM.\n",
    "    \"\"\"\n",
    "    single_tempo_songs = []\n",
    "    for song_id, song in data.items():\n",
    "        charts_data = extract_charts(song['charts_path'])\n",
    "        if charts_data and 'tempo_list' in charts_data:\n",
    "            if len(charts_data['tempo_list']) == 1:\n",
    "                single_tempo_songs.append(song)\n",
    "    return single_tempo_songs\n",
    "\n",
    "def map_note_to_time(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Map notes to time.\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): Chart data.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: Time mapping information for each note.\n",
    "    \"\"\"\n",
    "    time_base = data.get('time_base', 1000) \n",
    "    offset_universal = 0.033 \n",
    "    offset = data.get('music_offset', 0) - offset_universal\n",
    "    tempo_list = sorted(data.get('tempo_list', []), key=lambda x: x['tick'])  \n",
    "    note_list = data.get('note_list', [])\n",
    "    \n",
    "    note_time_map = []\n",
    "    accumulated_time = 0 \n",
    "    last_tick = 0  \n",
    "    if not tempo_list:\n",
    "        return note_time_map\n",
    "    current_tempo = tempo_list[0]['value']  \n",
    "    tempo_index = 0  \n",
    "\n",
    "    for note in note_list:\n",
    "        note_tick = note['tick']\n",
    "        while tempo_index < len(tempo_list) - 1 and tempo_list[tempo_index + 1]['tick'] <= note_tick:\n",
    "            next_tempo_tick = tempo_list[tempo_index + 1]['tick']\n",
    "            ticks_in_interval = next_tempo_tick - last_tick\n",
    "            tick_duration = (current_tempo / time_base) \n",
    "            accumulated_time += ticks_in_interval * tick_duration\n",
    "            last_tick = next_tempo_tick\n",
    "            tempo_index += 1\n",
    "            current_tempo = tempo_list[tempo_index]['value']\n",
    "\n",
    "        ticks_in_interval = note_tick - last_tick\n",
    "        tick_duration = (current_tempo / time_base) \n",
    "        note_time = accumulated_time + ticks_in_interval * tick_duration\n",
    "        note_time_map.append({\n",
    "            'note_id': note.get('id', 0),\n",
    "            'note_tick': note_tick,\n",
    "            'note_time_microseconds': note_time - offset * 1_000_000,\n",
    "            'note_type': note.get('type', 0),\n",
    "            'note_x': note.get('x', 0.0)\n",
    "        })\n",
    "\n",
    "    return note_time_map\n",
    "\n",
    "def generate_mel_spectrogram(\n",
    "    audio_path: Path,\n",
    "    log_enable: bool = True,\n",
    "    bpm_info: List[Dict[str, float]] = None,\n",
    "    note_info: List[Dict[str, Any]] = None,\n",
    "    max_frames: int = 5000  # New parameter to limit maximum frames\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Generate Mel spectrogram and corresponding labels, limiting its length to a maximum of max_frames.\n",
    "    \n",
    "    Args:\n",
    "        audio_path (Path): Path to the audio file.\n",
    "        log_enable (bool): Whether to apply logarithmic transformation.\n",
    "        bpm_info (List[Dict[str, float]]): BPM information.\n",
    "        note_info (List[Dict[str, Any]]): Note information.\n",
    "        max_frames (int): Maximum number of frames.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing Mel spectrogram, presence labels, and position_labels.\n",
    "    \"\"\"\n",
    "    data, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE)\n",
    "    assert sr == SAMPLE_RATE, f\"Expected sample rate {SAMPLE_RATE}, but got {sr}\"\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=data,\n",
    "        sr=sr, \n",
    "        hop_length=HOP_LENGTH, \n",
    "        fmin=30.0, \n",
    "        n_mels=NMELS, \n",
    "        htk=True\n",
    "    )\n",
    "    if log_enable:\n",
    "        mel = np.log(np.clip(mel, 1e-5, None))\n",
    "    mel = mel.T  # (Time steps, Features)\n",
    "\n",
    "    # Limit the length of the Mel spectrogram\n",
    "    if mel.shape[0] > max_frames:\n",
    "        mel = mel[:max_frames]\n",
    "\n",
    "    data_dic = {\"mel\": mel}\n",
    "\n",
    "    # Initialize presence labels and position_labels\n",
    "    presence_labels = np.zeros(mel.shape[0], dtype=int)  # Presence labels\n",
    "    position_labels = -1 * np.ones(mel.shape[0], dtype=int)  # -1 indicates no note\n",
    "\n",
    "    if bpm_info and note_info:\n",
    "        mel_length = mel.shape[0]\n",
    "        for note in note_info:\n",
    "            time_sec = note['note_time_microseconds'] / 1_000_000\n",
    "            frame_idx = int(time_sec * SAMPLE_RATE / HOP_LENGTH)\n",
    "            if 0 <= frame_idx < mel_length:  # Ensure frame_idx is non-negative and within range\n",
    "                presence_labels[frame_idx] = 1  # Presence\n",
    "                # Calculate relative position to window center (assuming window size of 40)\n",
    "                position = frame_idx  # Adjust based on specific requirements\n",
    "                position_labels[frame_idx] = position\n",
    "\n",
    "    data_dic[\"labels\"] = presence_labels  # shape: (mel_length,)\n",
    "    data_dic[\"position_labels\"] = position_labels  # shape: (mel_length,)\n",
    "\n",
    "    return data_dic\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Dataset and DataLoader\n",
    "\n",
    "class TimeUnit(enum.Enum):\n",
    "    milliseconds = \"milliseconds\"\n",
    "    frames = \"frames\"\n",
    "    seconds = \"seconds\"\n",
    "\n",
    "class OnsetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for loading and providing data.\n",
    "    Each sample includes the current frame and 40 frames before and after (total 81 frames).\n",
    "    \"\"\"\n",
    "    def __init__(self, data: Dict[str, Any], bpm_info: Dict[str, List[Dict[str, float]]], score_positions: Dict[str, List[Dict[str, Any]]], window_size: int = 40, transform=None):\n",
    "        self.data = data\n",
    "        self.bpm_info = bpm_info\n",
    "        self.score_positions = score_positions\n",
    "        self.transform = transform\n",
    "        self.window_size = window_size\n",
    "        self.samples = self.prepare_samples()\n",
    "        \n",
    "    def prepare_samples(self) -> List[Tuple[np.ndarray, np.ndarray, int]]:\n",
    "        \"\"\"\n",
    "        Prepare data samples, each containing 81 frames of Mel spectrogram and corresponding labels.\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for song_id, song in self.data.items():\n",
    "            mp3_path = song[\"mp3_path\"]\n",
    "            charts_path = song[\"charts_path\"]\n",
    "            difficulty = song['difficulty']\n",
    "            \n",
    "            mel_dict = generate_mel_spectrogram(\n",
    "                audio_path=Path(mp3_path),\n",
    "                log_enable=True,\n",
    "                bpm_info=self.bpm_info.get(song_id, None),\n",
    "                note_info=self.score_positions.get(song_id, None)\n",
    "            )\n",
    "            if \"labels\" in mel_dict:\n",
    "                mel = mel_dict[\"mel\"]  # shape: (num_frames, n_mels)\n",
    "                labels = mel_dict[\"labels\"]  # shape: (num_frames,)\n",
    "\n",
    "                num_frames = mel.shape[0]\n",
    "                for i in range(num_frames):\n",
    "                    start = max(i - self.window_size, 0)\n",
    "                    end = min(i + self.window_size + 1, num_frames)\n",
    "                    \n",
    "                    # Pad insufficient frames\n",
    "                    pad_before = self.window_size - i if i < self.window_size else 0\n",
    "                    pad_after = (i + self.window_size + 1) - num_frames if (i + self.window_size + 1) > num_frames else 0\n",
    "                    \n",
    "                    mel_window = mel[start:end]\n",
    "                    if pad_before > 0:\n",
    "                        mel_window = np.pad(mel_window, ((pad_before, 0), (0, 0)), mode='constant')\n",
    "                    if pad_after > 0:\n",
    "                        mel_window = np.pad(mel_window, ((0, pad_after), (0, 0)), mode='constant')\n",
    "                    \n",
    "                    label = labels[i]\n",
    "                    \n",
    "                    samples.append((mel_window, label, difficulty))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        mel_window, label, difficulty = self.samples[idx]\n",
    "        mel_window = torch.from_numpy(mel_window).float()  # shape: (81, n_mels)\n",
    "        label = torch.tensor(label).float()  # shape: ()\n",
    "        \n",
    "        if self.transform:\n",
    "            mel_window, label = self.transform(mel_window, label)\n",
    "\n",
    "        return mel_window, label, difficulty\n",
    "\n",
    "def collate_fn_padded(batch: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    Custom collate_fn for handling batch data.\n",
    "    \"\"\"\n",
    "    mel, labels, difficulties = zip(*batch)\n",
    "    \n",
    "    mel = torch.stack(mel, dim=0)  # (batch_size, 81, n_mels)\n",
    "    labels = torch.stack(labels, dim=0)  # (batch_size,)\n",
    "\n",
    "    return mel, labels, difficulties\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Presence Model Definition (Keeping Code Nearly Unchanged)\n",
    "\n",
    "class CNNOnsetDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network (CNN) based Onset Detection Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, num_classes: int = 1, dropout: float = 0.5):\n",
    "        super(CNNOnsetDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # Calculate pooled feature length\n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)  # Prevent feature length from being 0\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)  # Assuming three pooling layers\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 81, n_mels]\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # Convert to [batch_size, n_mels, 81]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 64, 40]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 128, 20]\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 256, 10]\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 2560]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CNNOnsetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels: int, dropout: float = 0.5):\n",
    "        super(CNNOnsetFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 81, n_mels)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, n_mels, 81)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 64, 40)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 128, 20)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 256, 10)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # (batch_size, 2560)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # (batch_size, 512)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Do not perform fc2, directly return 512-dimensional features\n",
    "        return x\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Type Model Definition (Modified to CNN)\n",
    "\n",
    "class CNNTypePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network (CNN) based Type Prediction Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, num_types: int = 5, dropout: float = 0.5):\n",
    "        super(CNNTypePredictor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # Calculate pooled feature length\n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)  # Prevent feature length from being 0\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)  # Assuming three pooling layers\n",
    "        self.fc_type = nn.Linear(512, num_types)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 81, n_mels]\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # Convert to [batch_size, n_mels, 81]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 64, 40]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 128, 20]\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 256, 10]\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 2560]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        type_out = self.fc_type(x)  # [batch_size, num_types]\n",
    "        \n",
    "        return type_out\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Visualization Functions\n",
    "\n",
    "def visualize_presence_predictions(mel: np.ndarray, labels: np.ndarray, preds: np.ndarray, start_time: float = 0, end_time: float = 5):\n",
    "    \"\"\"\n",
    "    Visualize the model's presence prediction results and true labels.\n",
    "\n",
    "    Args:\n",
    "        mel (np.ndarray): Mel spectrogram, shape (seq_len, feature_dim)\n",
    "        labels (np.ndarray): True labels, shape (seq_len,)\n",
    "        preds (np.ndarray): Model's presence scores, shape (seq_len,)\n",
    "        start_time (float): Start time for visualization (seconds)\n",
    "        end_time (float): End time for visualization (seconds)\n",
    "    \"\"\"\n",
    "    # Apply Sigmoid activation\n",
    "    presence_pred = 1 / (1 + np.exp(-preds))\n",
    "    \n",
    "    # Apply threshold of 0.5\n",
    "    presence_final = (presence_pred >= 0.5).astype(int)\n",
    "\n",
    "    # Calculate time axis\n",
    "    total_time = mel.shape[0] * HOP_LENGTH / SAMPLE_RATE\n",
    "    times = np.linspace(0, total_time, num=mel.shape[0])\n",
    "\n",
    "    # Determine frame range for visualization\n",
    "    start_frame = int(start_time * SAMPLE_RATE / HOP_LENGTH)\n",
    "    end_frame = int(end_time * SAMPLE_RATE / HOP_LENGTH)\n",
    "\n",
    "    # Ensure end_frame does not exceed sequence length\n",
    "    end_frame = min(end_frame, mel.shape[0])\n",
    "\n",
    "    # Crop data\n",
    "    mel_cropped = mel[start_frame:end_frame]\n",
    "    labels_cropped = labels[start_frame:end_frame]\n",
    "    presence_pred_cropped = presence_pred[start_frame:end_frame]\n",
    "    presence_final_cropped = presence_final[start_frame:end_frame]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    # Plot Mel spectrogram\n",
    "    img = librosa.display.specshow(\n",
    "        mel_cropped.T,\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        x_coords=times[start_frame:end_frame],\n",
    "        ax=axs[0],\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        fmax=8000\n",
    "    )\n",
    "    axs[0].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img, ax=axs[0], format='%+2.0f dB')\n",
    "\n",
    "    # Plot Presence predictions and true labels\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        presence_pred_cropped.flatten(),\n",
    "        label='Presence Prediction (Raw)',\n",
    "        color='red',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        presence_final_cropped,\n",
    "        label='Presence Prediction (Threshold=0.50)',\n",
    "        color='orange',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        labels_cropped.flatten(),\n",
    "        label='Presence Ground Truth',\n",
    "        color='blue',\n",
    "        linestyle='dashed'\n",
    "    )\n",
    "\n",
    "    axs[1].set_title('Presence Predictions vs Ground Truth (Threshold: 0.50)')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].set_xlabel('Time (s)')\n",
    "    axs[1].set_ylabel('Presence')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_presence_predictions_single(mel: np.ndarray, label: np.ndarray, pred: np.ndarray, start_time: float = 0, end_time: float = 5):\n",
    "    \"\"\"\n",
    "    Visualize the presence prediction results and true label for a single sample.\n",
    "    \n",
    "    Args:\n",
    "        mel (np.ndarray): Mel spectrogram, shape (81, n_mels)\n",
    "        label (np.ndarray): True label, shape (1,)\n",
    "        pred (np.ndarray): Model's presence score, shape (1,)\n",
    "        start_time (float): Start time for visualization (seconds)\n",
    "        end_time (float): End time for visualization (seconds)\n",
    "    \"\"\"\n",
    "    # Apply Sigmoid activation\n",
    "    presence_pred = 1 / (1 + np.exp(-pred))\n",
    "    \n",
    "    # Apply threshold of 0.5\n",
    "    presence_final = (presence_pred >= 0.5).astype(int)\n",
    "    \n",
    "    # Calculate time axis (assuming window center frame corresponds to current time)\n",
    "    total_time = WINDOW_SIZE * 2 * HOP_LENGTH / SAMPLE_RATE  # Total time for before and after frames\n",
    "    times = np.linspace(-WINDOW_SIZE * HOP_LENGTH / SAMPLE_RATE, WINDOW_SIZE * HOP_LENGTH / SAMPLE_RATE, num=mel.shape[0])\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # Plot Mel spectrogram\n",
    "    img = librosa.display.specshow(\n",
    "        mel.T,\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        x_coords=times,\n",
    "        ax=axs[0],\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        fmax=8000\n",
    "    )\n",
    "    axs[0].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img, ax=axs[0], format='%+2.0f dB')\n",
    "    \n",
    "    # Plot Presence predictions and true label\n",
    "    axs[1].bar(0, presence_pred, label='Presence Prediction (Raw)', color='red', alpha=0.6)\n",
    "    axs[1].bar(0, presence_final, label='Presence Prediction (Threshold=0.50)', color='orange', alpha=0.6)\n",
    "    axs[1].bar(0, label, label='Presence Ground Truth', color='blue', alpha=0.6)\n",
    "    \n",
    "    axs[1].set_title('Presence Predictions vs Ground Truth')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].set_xlabel('Current Frame')\n",
    "    axs[1].set_ylabel('Presence')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_type_predictions(mel: np.ndarray, labels: np.ndarray, preds: np.ndarray, start_time: float = 0, end_time: float = 5, hop_length: int = HOP_LENGTH, sample_rate: int = SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Visualize the model's type prediction results and true labels.\n",
    "\n",
    "    Args:\n",
    "        mel (np.ndarray): Mel spectrogram, shape (seq_len, feature_dim)\n",
    "        labels (np.ndarray): True labels, shape (seq_len,)\n",
    "        preds (np.ndarray): Model's type scores, shape (seq_len, num_types)\n",
    "        start_time (float): Start time for visualization (seconds)\n",
    "        end_time (float): End time for visualization (seconds)\n",
    "        hop_length (int): hop_length parameter\n",
    "        sample_rate (int): Sample rate\n",
    "    \"\"\"\n",
    "    # Apply Softmax activation\n",
    "    preds_prob = F.softmax(torch.tensor(preds), dim=-1).numpy()\n",
    "\n",
    "    # Calculate time axis\n",
    "    total_time = mel.shape[0] * hop_length / sample_rate\n",
    "    times = np.linspace(0, total_time, num=mel.shape[0])\n",
    "\n",
    "    # Determine frame range for visualization\n",
    "    start_frame = int(start_time * sample_rate / hop_length)\n",
    "    end_frame = int(end_time * sample_rate / hop_length)\n",
    "\n",
    "    # Crop data\n",
    "    labels_cropped = labels[start_frame:end_frame]\n",
    "    preds_cropped = preds_prob[start_frame:end_frame]\n",
    "    times_cropped = times[start_frame:end_frame]\n",
    "\n",
    "    # Define color mapping (using matplotlib's tab10 color set)\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    num_types = preds_cropped.shape[1]\n",
    "    colors = [cmap(i) for i in range(num_types)]\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    # Plot type probabilities\n",
    "    for type_idx in range(num_types):\n",
    "        plt.plot(\n",
    "            times_cropped,\n",
    "            preds_cropped[:, type_idx],\n",
    "            label=f'Type {type_idx}',\n",
    "            color=colors[type_idx],\n",
    "            alpha=0.6\n",
    "        )\n",
    "\n",
    "    # Plot true labels\n",
    "    for idx, label in enumerate(labels_cropped):\n",
    "        if label == 0:\n",
    "            continue  # Skip type 0 (assumed to be no event)\n",
    "        plt.scatter(\n",
    "            times_cropped[idx],\n",
    "            preds_cropped[idx, label],\n",
    "            color=colors[label],\n",
    "            marker='x',\n",
    "            s=50,\n",
    "            label=f'Ground Truth Type {label}' if idx == 0 else \"\",  # Add to legend only once\n",
    "            zorder=5\n",
    "        )\n",
    "        # Plot vertical lines\n",
    "        plt.axvline(\n",
    "            x=times_cropped[idx],\n",
    "            color=colors[label],\n",
    "            linestyle='--',\n",
    "            alpha=0.5,\n",
    "            linewidth=1\n",
    "        )\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Type Probabilities and Ground Truth', fontsize=14)\n",
    "    plt.xlabel('Time (s)', fontsize=12)\n",
    "    plt.ylabel('Probability', fontsize=12)\n",
    "\n",
    "    # Set legend, avoid duplicates\n",
    "    handles, labels_legend = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels_legend, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize='small')\n",
    "\n",
    "    # Set x-axis range\n",
    "    plt.xlim(start_time, end_time)\n",
    "\n",
    "    # Only show y-axis label on the right\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_label_coords(1.05, 0.5)\n",
    "\n",
    "    # Display plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_position_predictions(true_positions: List[int], pred_positions: List[int], num_samples: int = 100):\n",
    "    \"\"\"\n",
    "    Visualize the comparison between true positions and predicted positions.\n",
    "    \n",
    "    Args:\n",
    "        true_positions (List[int]): List of true positions.\n",
    "        pred_positions (List[int]): List of predicted positions.\n",
    "        num_samples (int): Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    if len(true_positions) < num_samples:\n",
    "        num_samples = len(true_positions)\n",
    "    indices = np.random.choice(len(true_positions), size=num_samples, replace=False)\n",
    "    true = np.array(true_positions)[indices]\n",
    "    pred = np.array(pred_positions)[indices]\n",
    "    \n",
    "    plt.scatter(range(num_samples), true, label='True Position', alpha=0.6, color='blue')\n",
    "    plt.scatter(range(num_samples), pred, label='Predicted Position', alpha=0.6, color='red')\n",
    "    plt.title('True vs Predicted Note Positions')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Position Index')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_position_distribution(true_positions: List[int], pred_positions: List[int]):\n",
    "    \"\"\"\n",
    "    Visualize the distribution of true positions and predicted positions.\n",
    "    \n",
    "    Args:\n",
    "        true_positions (List[int]): List of true positions.\n",
    "        pred_positions (List[int]): List of predicted positions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(true_positions, bins=81, alpha=0.5, label='True Positions', color='blue', density=True)\n",
    "    plt.hist(pred_positions, bins=81, alpha=0.5, label='Predicted Positions', color='red', density=True)\n",
    "    plt.title('Distribution of True and Predicted Positions')\n",
    "    plt.xlabel('Position Index')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training and Validation Functions\n",
    "\n",
    "# Presence Model Training Function\n",
    "def train_epoch_cnn(model: nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device, loss_fn: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    Train for one epoch (CNN version).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Presence\", leave=False)\n",
    "\n",
    "    for mel, labels, difficulties in progress_bar:\n",
    "        mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "        labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(mel)  # (batch_size, 1)\n",
    "        outputs = outputs.squeeze(1)  # (batch_size)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "# Presence Model Validation Function\n",
    "def validate_epoch_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module) -> Tuple[float, Dict[int, Dict[str, List[Any]]]]:\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    difficulty_preds = defaultdict(lambda: {'y_true': [], 'y_scores': []})\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validation Presence\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, difficulties in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(mel)  # (batch_size, 1)\n",
    "            outputs = outputs.squeeze(1)  # (batch_size)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            # Collect prediction scores and true labels, grouped by difficulty level\n",
    "            presence_pred_np = outputs.cpu().numpy()\n",
    "            presence_target_np = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(mel.size(0)):\n",
    "                difficulty = difficulties[i]\n",
    "                y_true = presence_target_np[i]\n",
    "                y_score = presence_pred_np[i]\n",
    "                difficulty_preds[difficulty]['y_true'].append(y_true)\n",
    "                difficulty_preds[difficulty]['y_scores'].append(y_score)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss, difficulty_preds\n",
    "\n",
    "# Type Model Training Function (CNN version)\n",
    "def train_epoch_cnn_type(model: nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device, loss_fn: nn.Module, num_types: int) -> float:\n",
    "    \"\"\"\n",
    "    Train for one epoch (Type CNN version).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Type CNN\", leave=False)\n",
    "\n",
    "    for mel, labels, lengths in progress_bar:\n",
    "        mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "        labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(type_pred, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1)\n",
    "        acc = (preds == labels).float().mean().item()\n",
    "        running_acc += acc\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Acc': f'{acc*100:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Type Model Validation Function (CNN version)\n",
    "def validate_epoch_cnn_type(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module, num_types: int) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set (CNN version).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validation Type CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, lengths in progress_bar:\n",
    "            mel = mel.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(type_pred, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1)\n",
    "            acc = (preds == labels).float().mean().item()\n",
    "            running_acc += acc\n",
    "\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Acc': f'{acc*100:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Model Evaluation Functions\n",
    "\n",
    "def evaluate_test_set_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluate the CNN model on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    difficulty_metrics = defaultdict(lambda: {'y_true': [], 'y_pred': []})\n",
    "    all_preds, all_labels = [], []\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Testing Presence CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, difficulties in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(mel)  # (batch_size, 1)\n",
    "            outputs = outputs.squeeze(1)  # (batch_size)\n",
    "            # Remove the following line as labels are already shape (batch_size,)\n",
    "            # labels = labels.squeeze(1)  # (batch_size)\n",
    "\n",
    "            # Compute loss (optional)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Collect predictions and labels\n",
    "            presence_pred_np = outputs.cpu().numpy()\n",
    "            presence_target_np = labels.cpu().numpy()\n",
    "\n",
    "            # Apply Sigmoid activation\n",
    "            presence_pred_sigmoid = 1 / (1 + np.exp(-presence_pred_np))\n",
    "\n",
    "            # Use threshold 0.5 for prediction\n",
    "            y_pred = (presence_pred_sigmoid >= 0.5).astype(int)\n",
    "            y_true = presence_target_np.astype(int)\n",
    "\n",
    "            # Collect all predictions and labels for distribution\n",
    "            all_preds.extend(presence_pred_sigmoid.tolist())\n",
    "            all_labels.extend(presence_target_np.tolist())\n",
    "\n",
    "            # Group by difficulty level\n",
    "            for i in range(mel.size(0)):\n",
    "                difficulty = difficulties[i]\n",
    "                difficulty_metrics[difficulty]['y_true'].append(y_true[i])\n",
    "                difficulty_metrics[difficulty]['y_pred'].append(y_pred[i])\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(all_preds, bins=50, alpha=0.7, label=\"Predictions\", color=\"blue\", density=True)\n",
    "    plt.hist(all_labels, bins=50, alpha=0.7, label=\"Ground Truth\", color=\"orange\", density=True)\n",
    "    plt.title(\"Frame-wise Prediction and Ground Truth Distribution\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate metrics for each difficulty level\n",
    "    final_metrics = {}\n",
    "    for diff, metrics in difficulty_metrics.items():\n",
    "        y_true = np.array(metrics['y_true'])\n",
    "        y_pred = np.array(metrics['y_pred'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        final_metrics[diff] = {\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        print(f\"Difficulty {diff}: Accuracy={acc:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1 Score={f1:.4f}\")\n",
    "\n",
    "    return final_metrics\n",
    "\n",
    "def evaluate_test_set_type_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module, num_types: int):\n",
    "    \"\"\"\n",
    "    Evaluate the Type CNN model on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Testing Type CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, lengths in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # Forward pass\n",
    "            type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(type_pred, labels)\n",
    "\n",
    "            # Collect predictions and labels\n",
    "            preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1).cpu().numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(true.tolist())\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Type Prediction - Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1_score': f1}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Preparation\n",
    "\n",
    "current_directory = Path().cwd()\n",
    "dataset_dirs = [\n",
    "    current_directory / \"../dataset/A\",\n",
    "    current_directory / \"../dataset/B\",\n",
    "    current_directory / \"../dataset/C\",\n",
    "    current_directory / \"../dataset/Z\"\n",
    "]\n",
    "data = extract_level_json_multiple(dataset_dirs, min_difficulty=15)\n",
    "print(f\"Filtered Data Count (Difficulty>=15): {len(data)}\")\n",
    "# data = dict(list(data.items())[:30])\n",
    "bpm_info_dict = {}\n",
    "score_positions_dict = {}\n",
    "\n",
    "for unique_id, song in data.items():\n",
    "    level_data = song['level']\n",
    "    song_id = unique_id  # Use unique ID\n",
    "    charts_data = extract_charts(song['charts_path'])\n",
    "    if charts_data:\n",
    "        bpm_info = charts_data.get('tempo_list', [])\n",
    "        bpm_info_dict[song_id] = bpm_info\n",
    "        note_time_map = map_note_to_time(charts_data) \n",
    "        # Detailed information for each note, including time, type, and position\n",
    "        score_positions = [] \n",
    "        for note in note_time_map:\n",
    "            score_positions.append({\n",
    "                'note_time_microseconds': note['note_time_microseconds'],\n",
    "                'note_type': note.get('note_type', 0),  # Ensure this field exists\n",
    "                'note_x': note.get('note_x', 0.0)      # Ensure this field exists\n",
    "            })\n",
    "        score_positions_dict[song_id] = score_positions\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Define Dataset and DataLoader\n",
    "\n",
    "# Define Presence dataset and DataLoader\n",
    "presence_dataset = OnsetDataset(\n",
    "    data=data, \n",
    "    bpm_info=bpm_info_dict, \n",
    "    score_positions=score_positions_dict,\n",
    "    window_size=WINDOW_SIZE  # 40 frames before and after\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(presence_dataset))\n",
    "val_size = len(presence_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(presence_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Presence Train Size: {len(train_dataset)}\")\n",
    "print(f\"Presence Validation Size: {len(val_dataset)}\")\n",
    "# Below is the training code ---------------------------------------------------------------------------------------------------\n",
    "# Create test set (using part of the validation set as test set)\n",
    "test_size = int(0.5 * len(val_dataset))\n",
    "val_size = len(val_dataset) - test_size\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "print(f\"Presence Validation Size after split: {len(val_dataset)}\")\n",
    "print(f\"Presence Test Size: {len(test_dataset)}\")\n",
    "\n",
    "presence_train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate_fn_padded)\n",
    "presence_val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded)\n",
    "presence_test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Presence Model Training and Evaluation\n",
    "\n",
    "# Initialize Presence model\n",
    "presence_model = CNNOnsetDetector(input_channels=NMELS, num_classes=1, dropout=DROPOUT)\n",
    "presence_model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "presence_optimizer = torch.optim.Adam(presence_model.parameters(), lr=LEARNING_RATE)\n",
    "presence_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train the best Presence model\n",
    "best_presence_val_loss = float('inf')\n",
    "best_presence_model_path = \"model/best_cnn_onset_model.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Training Presence Model\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_epoch_cnn(presence_model, presence_train_loader, presence_optimizer, device, presence_loss_fn)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_difficulty_preds = validate_epoch_cnn(presence_model, presence_val_loader, device, presence_loss_fn)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save the model if validation loss is lower\n",
    "    if val_loss < best_presence_val_loss:\n",
    "        best_presence_val_loss = val_loss\n",
    "        torch.save(presence_model.state_dict(), best_presence_model_path)\n",
    "        print(\"Saved Best Presence Model\")\n",
    "\n",
    "# Load the best Presence model\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()\n",
    "# Below is the training code ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Define Type Dataset and DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=2.0, gamma=2, reduction='mean'):\n",
    "        \"\"\"\n",
    "        alpha: Class balancing factor, can be used to give more weight to minority classes in imbalanced datasets\n",
    "        gamma: Modulation parameter, the larger gamma is, the more focus on hard-to-classify samples\n",
    "        reduction: Loss aggregation method, 'mean' or 'sum'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: [batch_size, num_classes]\n",
    "        # targets: [batch_size]\n",
    "\n",
    "        # Get predicted probability distribution\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        # Extract the predicted probability for the true class\n",
    "        pt = probs[range(len(targets)), targets]\n",
    "\n",
    "        # Focal loss formula\n",
    "        loss = -self.alpha * (1 - pt)**self.gamma * torch.log(pt)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# %% \n",
    "class TypeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for loading and providing data.\n",
    "    Each sample includes the current frame and 40 frames before and after (total 81 frames).\n",
    "    \"\"\"\n",
    "    def __init__(self, data: Dict[str, Any], bpm_info: Dict[str, List[Dict[str, float]]], score_positions: Dict[str, List[Dict[str, Any]]], window_size: int = 40, transform=None):\n",
    "        self.data = data\n",
    "        self.bpm_info = bpm_info\n",
    "        self.score_positions = score_positions\n",
    "        self.transform = transform\n",
    "        self.window_size = window_size\n",
    "        self.samples = self.prepare_samples()\n",
    "        \n",
    "    def prepare_samples(self) -> List[Tuple[np.ndarray, int, int]]:\n",
    "        \"\"\"\n",
    "        Prepare data samples, each containing 81 frames of Mel spectrogram and corresponding type labels.\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for song_id, song in self.data.items():\n",
    "            mp3_path = song[\"mp3_path\"]\n",
    "            charts_path = song[\"charts_path\"]\n",
    "            difficulty = song['difficulty']\n",
    "            \n",
    "            mel_dict = generate_mel_spectrogram(\n",
    "                audio_path=Path(mp3_path),\n",
    "                log_enable=True,\n",
    "                bpm_info=self.bpm_info.get(song_id, None),\n",
    "                note_info=self.score_positions.get(song_id, None)\n",
    "            )\n",
    "            if \"labels\" in mel_dict:\n",
    "                mel = mel_dict[\"mel\"]  # shape: (num_frames, n_mels)\n",
    "                labels = mel_dict[\"labels\"]  # shape: (num_frames,)\n",
    "\n",
    "                num_frames = mel.shape[0]\n",
    "                for i in range(num_frames):\n",
    "                    start = max(i - self.window_size, 0)\n",
    "                    end = min(i + self.window_size + 1, num_frames)\n",
    "                    \n",
    "                    # Pad insufficient frames\n",
    "                    pad_before = self.window_size - i if i < self.window_size else 0\n",
    "                    pad_after = (i + self.window_size + 1) - num_frames if (i + self.window_size + 1) > num_frames else 0\n",
    "                    \n",
    "                    mel_window = mel[start:end]\n",
    "                    if pad_before > 0:\n",
    "                        mel_window = np.pad(mel_window, ((pad_before, 0), (0, 0)), mode='constant')\n",
    "                    if pad_after > 0:\n",
    "                        mel_window = np.pad(mel_window, ((0, pad_after), (0, 0)), mode='constant')\n",
    "                    \n",
    "                    label = labels[i]\n",
    "                    \n",
    "                    samples.append((mel_window, label, difficulty))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        mel_window, label, difficulty = self.samples[idx]\n",
    "        mel_window = torch.from_numpy(mel_window).float()  # shape: (81, n_mels)\n",
    "        label = torch.tensor(label).long()  # shape: ()\n",
    "        \n",
    "        if self.transform:\n",
    "            mel_window, label = self.transform(mel_window, label)\n",
    "\n",
    "        return mel_window, label, difficulty\n",
    "\n",
    "def collate_fn_padded_type(batch: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    Custom collate_fn for handling batch data.\n",
    "    \"\"\"\n",
    "    mel, labels, difficulties = zip(*batch)\n",
    "    \n",
    "    mel = torch.stack(mel, dim=0)  # (batch_size, 81, n_mels)\n",
    "    labels = torch.stack(labels, dim=0)  # (batch_size,)\n",
    "\n",
    "    return mel, labels, difficulties\n",
    "\n",
    "type_dataset = TypeDataset(\n",
    "    data=data, \n",
    "    bpm_info=bpm_info_dict, \n",
    "    score_positions=score_positions_dict,\n",
    "    window_size=WINDOW_SIZE  # 40 frames before and after\n",
    ")\n",
    "\n",
    "# Below is the training code ---------------------------------------------------------------------------------------------------\n",
    "# # Split the dataset\n",
    "type_train_size = int(0.8 * len(type_dataset))\n",
    "type_val_size = len(type_dataset) - type_train_size\n",
    "type_train_dataset, type_val_dataset = random_split(type_dataset, [type_train_size, type_val_size])\n",
    "\n",
    "print(f\"Type Train Size: {len(type_train_dataset)}\")\n",
    "print(f\"Type Validation Size: {len(type_val_dataset)}\")\n",
    "\n",
    "# Create test set (using part of the validation set as test set)\n",
    "type_test_size = int(0.5 * len(type_val_dataset))\n",
    "type_val_size = len(type_val_dataset) - type_test_size\n",
    "type_val_dataset, type_test_dataset = random_split(type_val_dataset, [type_val_size, type_test_size])\n",
    "\n",
    "print(f\"Type Validation Size after split: {len(type_val_dataset)}\")\n",
    "print(f\"Type Test Size: {len(type_test_dataset)}\")\n",
    "\n",
    "type_train_loader = DataLoader(type_train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate_fn_padded_type)\n",
    "type_val_loader = DataLoader(type_val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded_type)\n",
    "type_test_loader = DataLoader(type_test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded_type)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Type Model Definition and Training\n",
    "\n",
    "# Initialize Type model\n",
    "num_types = 5  # Adjust based on requirements\n",
    "type_model = CNNTypePredictor(input_channels=NMELS, num_types=num_types, dropout=DROPOUT)\n",
    "type_model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "type_optimizer = torch.optim.Adam(type_model.parameters(), lr=LEARNING_RATE)\n",
    "type_loss_fn = FocalLoss(alpha=1.0, gamma=2, reduction='mean')\n",
    "\n",
    "\n",
    "# Train the best Type model\n",
    "best_type_val_loss = float('inf')\n",
    "best_type_model_path = \"model/best_cnn_type_model.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Training Type Model\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_acc = train_epoch_cnn_type(type_model, type_train_loader, type_optimizer, device, type_loss_fn, num_types)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc = validate_epoch_cnn_type(type_model, type_val_loader, device, type_loss_fn, num_types)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save the model if validation loss is lower\n",
    "    if val_loss < best_type_val_loss:\n",
    "        best_type_val_loss = val_loss\n",
    "        torch.save(type_model.state_dict(), best_type_model_path)\n",
    "        print(\"Saved Best Type Model\")\n",
    "\n",
    "# Load the best Type model\n",
    "type_model.load_state_dict(torch.load(best_type_model_path))\n",
    "type_model.to(device)\n",
    "type_model.eval()\n",
    "# Below is the training code ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "num_types = 5  # Adjust based on requirements\n",
    "best_presence_model_path = \"model/best_cnn_onset_model.pth\"\n",
    "best_type_model_path = \"model/best_cnn_type_model.pth\"\n",
    "\n",
    "presence_model = CNNOnsetDetector(input_channels=NMELS, num_classes=1, dropout=DROPOUT)\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path, map_location=device))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()  # Switch to evaluation mode\n",
    "\n",
    "type_model = CNNTypePredictor(input_channels=NMELS, num_types=num_types, dropout=DROPOUT)\n",
    "type_model.load_state_dict(torch.load(best_type_model_path, map_location=device))\n",
    "type_model.to(device)\n",
    "type_model.eval()\n",
    "\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.clouddiver.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/arwtdydhqhfa.helamind.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/andogaru.fumiko.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.summernight.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.cereris.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.alone.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ï¿½TAKUMIÂ³ï¿½OÐ¯DIN -Apocalyptic War-(Re Mastering).mp3 å¯¹åº”äºŽ song ID ant.ordin-tc åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/ant.ordin-tc.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anthony.lolk_muricaaaaa.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Langley_D - deli.+é§„ã€…å­ - æœ€æžœã¦ã®å‹‡è€…ã«ãƒ©ãƒ–ã‚½ãƒ³ã‚°ã‚’.ogg å¯¹åº”äºŽ song ID anoppo.furiy åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.furiy.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/aboal.43201.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Vicetoneã€Kat Nestel - Angels (Radio Edit).wav å¯¹åº”äºŽ song ID asuna_37 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/asuna_37.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.rainbow.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ self-dissociation - Lidelleã€Sobremã€Sennzai.ogg å¯¹åº”äºŽ song ID anoppo.selfdissociation åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.selfdissociation.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.rainmaker.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã‚³ãƒ³ã‚¦ã‚§ã‚¤ã®å­ - sta.ogg å¯¹åº”äºŽ song ID anoppo.conwayschild åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.conwayschild.cytoidlevel\n",
      "æœªæ‰¾åˆ° charts æ–‡ä»¶ ARo.txt å¯¹åº”äºŽ song ID enteraname6 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/AR-1.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ é»’é­” - Banbard (Chroma Remix).ogg å¯¹åº”äºŽ song ID anoppo.banbard åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.banbard.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å‰Šé™¤ (Sakuzyo) - Amateras.ogg å¯¹åº”äºŽ song ID anoppo.amateras åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.amateras.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã‹ã‚ã‚Šã‚_åˆéŸ³ãƒŸã‚¯-ãƒ’ã‚¢ã‚½ãƒ“-_feat.-åˆéŸ³ãƒŸã‚¯_(2).ogg å¯¹åº”äºŽ song ID aniloid.hiasobi åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/aniloid.hiasobi.cytoidlevel\n",
      "æœªæ‰¾åˆ° charts æ–‡ä»¶ ä¿—ç‰©ãƒ•ã‚§ã‚¹ãƒ†ã‚£ãƒãƒ«.json å¯¹åº”äºŽ song ID anoppo.su åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.su.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Sta _ B - ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚·ãƒ³ãƒ¡ãƒˆãƒªãƒ¼(1).mp3 å¯¹åº”äºŽ song ID anoppo.super åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.super.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å‰Šé™¤ - PANDORA PARADOXXX.ogg å¯¹åº”äºŽ song ID anoppo.pandora åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.pandora.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/ant.future.dominators.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.cord.reborn.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ With a Billion Worldful of 3 - Miliã€DE DE MOUSE.ogg å¯¹åº”äºŽ song ID anoppo.withabillionworldfulofthree åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.withabillionworldfulofthree.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å¤©hshsP.mp3 å¯¹åº”äºŽ song ID angelll.theweak åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/angelll.theweak.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã€Hardcoreã€‘Requillio _ Dopam!ne ðŸ‘»Free DLðŸ‘».mp3 å¯¹åº”äºŽ song ID ant.requillio-t3 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/ant.requillio-t3.cytoidlevel\n",
      "æ— æ³•è¯»å– /data1/yuchen/cytoid/final_code/../dataset/A/archore.lnd.lnyh.cytoidlevel/level.json: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/ap_mumayoru.ely.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ kei_iwata - ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢â†‘â†‘ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼.ogg å¯¹åº”äºŽ song ID amaneku.frontier_exploler åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/amaneku.frontier_exploler.cytoidlevel\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/ap_megalice.ely.cytoidlevel/level.json\n",
      "JSON è§£æžé”™è¯¯: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.wwp.cytoidlevel/level.json\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ (éŸ³æº) ã€SDVXã€‘ ãã—ã¦é»„é‡‘éƒ·ã¸ ã€NOFXã€‘ - 1.(éŸ³æº) [SDVX] ãã—ã¦é»„é‡‘éƒ·ã¸ [NOFX](Av29726758,P1).mp3 å¯¹åº”äºŽ song ID anoppo.golden åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.golden.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ é›²è½kyuuå¤© - Chapter.Qï¼šEuphoric World - Rabbit House.ogg å¯¹åº”äºŽ song ID anoppo.euphoricworld åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.euphoricworld.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Sta,bqã‚¹ã‚¿ãƒ‚ã‚ª - ã‚¢ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ãƒ³ãƒ¡ãƒˆãƒªãƒ¼.ogg å¯¹åº”äºŽ song ID anoppo.ink2 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.ink2.cytoidlevel\n",
      "ç›®å½•ä¸å­˜åœ¨: /data1/yuchen/cytoid/final_code/../dataset/C\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ kanone,Sennzai - èŠ±ã¨ã€é›ªã¨ã€ãƒ‰ãƒ©ãƒ ãƒ³ãƒ™ãƒ¼ã‚¹.ogg å¯¹åº”äºŽ song ID ztz.huayilun åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.huayilun.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ç”³ä¸œè¾‰ - NB Blast.mp3 å¯¹åº”äºŽ song ID zeng.nbblast åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.nbblast.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã‚¤ãƒ­ãƒ‰ãƒªãƒŸãƒ‰ãƒª - conflict (æ–‰å”±).ogg å¯¹åº”äºŽ song ID ztz.conflictcover åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.conflictcover.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Rintaro Soma - sÃ¸lips.ogg å¯¹åº”äºŽ song ID ztz.solips åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.solips.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ¢ãƒªãƒ¢ãƒªã‚ã¤ã— - Grand-Guignol.mp3 å¯¹åº”äºŽ song ID zeng.grandguignol åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.grandguignol.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ æ˜Ÿæ²³ä¸€å¤©.mp3 å¯¹åº”äºŽ song ID zirei.st åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.st.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ“ãƒ¼ãƒˆã¾ã‚ŠãŠ,ã‚ã¾ã­ - ã‚¦ã‚µãƒ†ã‚¤20XX.ogg å¯¹åº”äºŽ song ID ztz.usatei20xxre åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.usatei20xxre.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã‹ã‚ã‚Šã‚ - Hello (BPM) 2021.mp3 å¯¹åº”äºŽ song ID zeng.hellobpm åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.hellobpm.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Î£vreka.mp3 å¯¹åº”äºŽ song ID zirei.evreka åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.evreka.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ¢ãƒªãƒ¢ãƒªã‚ã¤ã— - Grand-Guignol.mp3 å¯¹åº”äºŽ song ID zeng.grand åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.grand.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ¢ãƒ³ãƒ€ã‚¤ãƒŠã‚¤ãƒˆãƒªãƒƒãƒ‘ãƒ¼ï¼.mp3 å¯¹åº”äºŽ song ID zirei.mondai åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.mondai.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å¢æ–‡éŸ¬ - å¥‡è½®ï¼æˆ‘çš„è‹±é›„ï¼ˆã€Šæ¿€æˆ˜å¥‡è½®2ã€‹OPï¼‰.mp3 å¯¹åº”äºŽ song ID zeng.qilunmyhero åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.qilunmyhero.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å…­å…†å¹´ã¨ä¸€å¤œç‰©èªžï¼Œï¼Œ.mp3 å¯¹åº”äºŽ song ID zhong_yu_six åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zhong_yu_six.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ç´°æ±Ÿæ…Žæ²» - Kattobi KEIKYU Rider.ogg å¯¹åº”äºŽ song ID ztz.kattobikeikyurider åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.kattobikeikyurider.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Team Grimoire - Excalibur ï½žRevived resolutionï½ž.ogg å¯¹åº”äºŽ song ID ztz.excalibur åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.excalibur.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãºã®ã‚Œã‚Š - Desperado Waltz.ogg å¯¹åº”äºŽ song ID ztz.desperadowaltz åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.desperadowaltz.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ miko - æ‚£éƒ¨ã§æ­¢ã¾ã£ã¦ã™ãæº¶ã‘ã‚‹ - ç‹‚æ°—ã®ä¼˜æ˜™åŽé™¢.ogg å¯¹åº”äºŽ song ID ztz.huanbu åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.huanbu.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Vâˆ…rstia.mp3 å¯¹åº”äºŽ song ID zirei.vo åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.vo.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ã²ã¨ã‚Šãã‚Šã®ã‚¨ãƒ‡ãƒ³.mp3 å¯¹åº”äºŽ song ID zirei.d36 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.d36.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ æœ§æœˆ.mp3 å¯¹åº”äºŽ song ID zirei.ml åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.ml.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ“ãƒ¼ãƒˆã¾ã‚ŠãŠ,ã‚ã¾ã­ - ã‚¦ã‚µãƒ†ã‚¤20XX.mp3 å¯¹åº”äºŽ song ID ztz.usatei20xx åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.usatei20xx.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ”ãƒŽã‚­ã‚ªãƒ”ãƒ¼,åˆéŸ³ãƒŸã‚¯ - è…ã‚Œå¤–é“ã¨ãƒãƒ§ã‚³ãƒ¬ã‚ãƒˆ.ogg å¯¹åº”äºŽ song ID ztz.heterodoxusandchocolate åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.heterodoxusandchocolate.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ åˆéŸ³ - åƒæœ¬æ¡œã€åä¼¶è¨ˆç•« F ä¸­æ–‡å­—å¹•ã€‘.mp3 å¯¹åº”äºŽ song ID zhong_yu_1219 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zhong_yu_1219.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Se-U-Ra - ãƒã‚¸ãƒžã‚­ã‚»ã‚«ã‚¤ã®ç‹‚é¨’æ›².mp3 å¯¹åº”äºŽ song ID zeng.kuangsao åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.kuangsao.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ è¶…ç†Šè²“çš„å‘¨éŠè¨˜.mp3 å¯¹åº”äºŽ song ID zirei.fanta åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.fanta.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Taikes - ä¸–ç•Œå‡½æ•°~WorldÂ Function~.mp3 å¯¹åº”äºŽ song ID zeng.worldfunction åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.worldfunction.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ Ponchi,æ‰“æ‰“ã ã„ãš - æ˜Ÿæ²³ä¸€å¤© (Ponchiâ™ªRemix).ogg å¯¹åº”äºŽ song ID ztz.xhytrmx åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.xhytrmx.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ãƒ‡ãƒ«ã‚¿ãƒ©ã‚¤ã‚ºã‚¯ãƒ­ãƒ¼ã®ãƒ†ãƒ¼ãƒž-å®‰æ¿‘åœ£.mp3 å¯¹åº”äºŽ song ID ztz.delta åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.delta.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ ç›Ÿæœˆ.mp3 å¯¹åº”äºŽ song ID zirei.ddd åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.ddd.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ å°é‡Žç§€å¹¸ - Prophesy One.ogg å¯¹åº”äºŽ song ID ztz.prophesy1 åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.prophesy1.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ stÎµganography.mp3 å¯¹åº”äºŽ song ID zirei.steganography åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.steganography.cytoidlevel\n",
      "æœªæ‰¾åˆ° charts æ–‡ä»¶ loveand - å‰¯æœ¬.txt å¯¹åº”äºŽ song ID zeng.loveandj åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.loveandj.cytoidlevel\n",
      "æœªæ‰¾åˆ° charts æ–‡ä»¶ emp - å‰¯æœ¬.txt å¯¹åº”äºŽ song ID zeng.emp åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.emp.cytoidlevel\n",
      "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ æ¸…æ°´é”ä¹Ÿ - IMAGE-MATERIAL-.mp3 å¯¹åº”äºŽ song ID zeng.image åœ¨ /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.image.cytoidlevel\n",
      "æ€»å…±è·³è¿‡çš„æ›²å­æ•°é‡: 69\n",
      "è·³è¿‡åŽŸå›  'json_decode_error': 15 ä¸ªæ›²å­\n",
      "è·³è¿‡åŽŸå›  'missing_audio_file': 49 ä¸ªæ›²å­\n",
      "è·³è¿‡åŽŸå›  'missing_charts_file': 4 ä¸ªæ›²å­\n",
      "è·³è¿‡åŽŸå›  'read_error': 1 ä¸ªæ›²å­\n",
      "è·³è¿‡åŽŸå›  'missing_directory': 1 ä¸ªæ›²å­\n",
      "Filtered Data Count (Difficulty>=15): 217\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/artzumaru.asunoyozorashoukanhen.cytoidlevel/AsunoYozora.hard.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.miracleallextracoremix.cytoidlevel/ex.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.pandora06.cytoidlevel/ex.Tag.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.pandora01.cytoidlevel/exnewnew.Tag.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.calamityfortune.cytoidlevel/hard.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.intensesinging.cytoidlevel/intense.Tag.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence Train Size: 858862\n",
      "Presence Validation Size: 214716\n",
      "Presence Validation Size after split: 107358\n",
      "Presence Test Size: 107358\n",
      "Epoch 1/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3996\n",
      "Saved Best Presence Model\n",
      "Epoch 2/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3695\n",
      "Saved Best Presence Model\n",
      "Epoch 3/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3430\n",
      "Saved Best Presence Model\n",
      "Epoch 4/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Saved Best Presence Model\n",
      "Epoch 5/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3150\n",
      "Saved Best Presence Model\n",
      "Epoch 6/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3057\n",
      "Saved Best Presence Model\n",
      "Epoch 7/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2988\n",
      "Saved Best Presence Model\n",
      "Epoch 8/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2934\n",
      "Saved Best Presence Model\n",
      "Epoch 9/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2872\n",
      "Saved Best Presence Model\n",
      "Epoch 10/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2834\n",
      "Saved Best Presence Model\n",
      "Epoch 11/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2771\n",
      "Saved Best Presence Model\n",
      "Epoch 12/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2765\n",
      "Saved Best Presence Model\n",
      "Epoch 13/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2746\n",
      "Saved Best Presence Model\n",
      "Epoch 14/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2748\n",
      "Epoch 15/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2700\n",
      "Saved Best Presence Model\n",
      "Epoch 16/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2707\n",
      "Epoch 17/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2649\n",
      "Saved Best Presence Model\n",
      "Epoch 18/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2646\n",
      "Saved Best Presence Model\n",
      "Epoch 19/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2626\n",
      "Saved Best Presence Model\n",
      "Epoch 20/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2617\n",
      "Saved Best Presence Model\n",
      "Epoch 21/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2600\n",
      "Saved Best Presence Model\n",
      "Epoch 22/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2579\n",
      "Saved Best Presence Model\n",
      "Epoch 23/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2619\n",
      "Epoch 24/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2576\n",
      "Saved Best Presence Model\n",
      "Epoch 25/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2602\n",
      "Epoch 26/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2557\n",
      "Saved Best Presence Model\n",
      "Epoch 27/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2583\n",
      "Epoch 28/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2545\n",
      "Saved Best Presence Model\n",
      "Epoch 29/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2545\n",
      "Saved Best Presence Model\n",
      "Epoch 30/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2543\n",
      "Saved Best Presence Model\n",
      "Epoch 31/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2520\n",
      "Saved Best Presence Model\n",
      "Epoch 32/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2531\n",
      "Epoch 33/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2526\n",
      "Epoch 34/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2506\n",
      "Saved Best Presence Model\n",
      "Epoch 35/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2528\n",
      "Epoch 36/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2504\n",
      "Saved Best Presence Model\n",
      "Epoch 37/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2506\n",
      "Epoch 38/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2498\n",
      "Saved Best Presence Model\n",
      "Epoch 39/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2491\n",
      "Saved Best Presence Model\n",
      "Epoch 40/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2503\n",
      "Epoch 41/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2486\n",
      "Saved Best Presence Model\n",
      "Epoch 42/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2474\n",
      "Saved Best Presence Model\n",
      "Epoch 43/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2475\n",
      "Epoch 44/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2479\n",
      "Epoch 45/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2472\n",
      "Saved Best Presence Model\n",
      "Epoch 46/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2492\n",
      "Epoch 47/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2457\n",
      "Saved Best Presence Model\n",
      "Epoch 48/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2474\n",
      "Epoch 49/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2457\n",
      "Epoch 50/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205621/3220993348.py:1229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Train Size: 858862\n",
      "Type Validation Size: 214716\n",
      "Type Validation Size after split: 107358\n",
      "Type Test Size: 107358\n",
      "Epoch 1/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1162, Train Acc: 83.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1110, Validation Acc: 83.77%\n",
      "Saved Best Type Model\n",
      "Epoch 2/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1107, Train Acc: 83.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1060, Validation Acc: 83.95%\n",
      "Saved Best Type Model\n",
      "Epoch 3/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1071, Train Acc: 83.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1023, Validation Acc: 84.24%\n",
      "Saved Best Type Model\n",
      "Epoch 4/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1041, Train Acc: 84.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0988, Validation Acc: 84.75%\n",
      "Saved Best Type Model\n",
      "Epoch 5/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1021, Train Acc: 84.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0965, Validation Acc: 85.04%\n",
      "Saved Best Type Model\n",
      "Epoch 6/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1002, Train Acc: 84.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0944, Validation Acc: 85.43%\n",
      "Saved Best Type Model\n",
      "Epoch 7/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0987, Train Acc: 84.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0936, Validation Acc: 85.50%\n",
      "Saved Best Type Model\n",
      "Epoch 8/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0976, Train Acc: 85.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0915, Validation Acc: 85.89%\n",
      "Saved Best Type Model\n",
      "Epoch 9/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0966, Train Acc: 85.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0907, Validation Acc: 86.11%\n",
      "Saved Best Type Model\n",
      "Epoch 10/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0957, Train Acc: 85.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0899, Validation Acc: 86.11%\n",
      "Saved Best Type Model\n",
      "Epoch 11/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0947, Train Acc: 85.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0896, Validation Acc: 86.29%\n",
      "Saved Best Type Model\n",
      "Epoch 12/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0940, Train Acc: 85.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0880, Validation Acc: 86.39%\n",
      "Saved Best Type Model\n",
      "Epoch 13/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0934, Train Acc: 85.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0887, Validation Acc: 86.56%\n",
      "Epoch 14/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0930, Train Acc: 85.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0894, Validation Acc: 86.34%\n",
      "Epoch 15/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0925, Train Acc: 85.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0875, Validation Acc: 86.56%\n",
      "Saved Best Type Model\n",
      "Epoch 16/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0919, Train Acc: 85.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0867, Validation Acc: 86.64%\n",
      "Saved Best Type Model\n",
      "Epoch 17/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0916, Train Acc: 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0861, Validation Acc: 86.79%\n",
      "Saved Best Type Model\n",
      "Epoch 18/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0911, Train Acc: 86.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0856, Validation Acc: 86.66%\n",
      "Saved Best Type Model\n",
      "Epoch 19/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0907, Train Acc: 86.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0855, Validation Acc: 86.73%\n",
      "Saved Best Type Model\n",
      "Epoch 20/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0905, Train Acc: 86.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0858, Validation Acc: 86.91%\n",
      "Epoch 21/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0901, Train Acc: 86.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0850, Validation Acc: 86.90%\n",
      "Saved Best Type Model\n",
      "Epoch 22/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0900, Train Acc: 86.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0841, Validation Acc: 86.98%\n",
      "Saved Best Type Model\n",
      "Epoch 23/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0897, Train Acc: 86.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0848, Validation Acc: 86.78%\n",
      "Epoch 24/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0895, Train Acc: 86.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0846, Validation Acc: 86.98%\n",
      "Epoch 25/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0891, Train Acc: 86.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0838, Validation Acc: 86.91%\n",
      "Saved Best Type Model\n",
      "Epoch 26/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0892, Train Acc: 86.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0845, Validation Acc: 87.06%\n",
      "Epoch 27/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0889, Train Acc: 86.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0826, Validation Acc: 87.28%\n",
      "Saved Best Type Model\n",
      "Epoch 28/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0886, Train Acc: 86.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0834, Validation Acc: 87.16%\n",
      "Epoch 29/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 85.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 30/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 31/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 32/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 33/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 34/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 35/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 36/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 37/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 38/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 39/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 40/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 41/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 42/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 43/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 44/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 45/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 46/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 47/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 48/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 49/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 50/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205621/3220993348.py:1415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  type_model.load_state_dict(torch.load(best_type_model_path))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1426: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path, map_location=device))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1431: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  type_model.load_state_dict(torch.load(best_type_model_path, map_location=device))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1435: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNOnsetDetector(\n",
       "  (conv1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2560, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the result of both model\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # ç§»åŠ¨åˆ°æœ€é¡¶éƒ¨\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import enum\n",
    "import tqdm\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# %% [markdown]\n",
    "# ## å¸¸é‡å®šä¹‰\n",
    "\n",
    "# %%\n",
    "# STFT å¸¸é‡\n",
    "SAMPLE_RATE = 22050  \n",
    "HOP_LENGTH = 512     \n",
    "NMELS = 128        \n",
    "WINDOW_SIZE = 40  # å‰åŽå¸§æ•°\n",
    "NUM_EPOCHS = 50    # è®­ç»ƒè½®æ•°\n",
    "BATCH_SIZE = 64    # æ‰¹å¤§å°\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT = 0.5      # DropoutçŽ‡\n",
    "\n",
    "# æ£€æŸ¥ GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## æ•°æ®é¢„å¤„ç†å‡½æ•°\n",
    "\n",
    "# %%\n",
    "def contains_non_ascii(s: str) -> bool:\n",
    "    \"\"\"æ£€æŸ¥å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å«éžASCIIå­—ç¬¦ã€‚\"\"\"\n",
    "    return any(ord(c) > 127 for c in s)\n",
    "\n",
    "def extract_level_json_multiple(directories: List[Path], min_difficulty: int = 15) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ä»Žå¤šä¸ªç›®å½•ä¸­æå–level.jsonæ–‡ä»¶ï¼Œæ•´ç†ç›¸å…³ä¿¡æ¯ï¼Œå¹¶ç­›é€‰å‡ºæŒ‡å®šéš¾åº¦çš„æ›²ç›®ã€‚\n",
    "    å¦‚æžœé‡åˆ°æ— æ³•è§£æžçš„åå­—æˆ–å…¶ä»–é—®é¢˜ï¼Œç›´æŽ¥è·³è¿‡è¯¥æ›²å­ã€‚\n",
    "\n",
    "    Args:\n",
    "        directories (List[Path]): åŒ…å«å¤šä¸ªå­æ–‡ä»¶å¤¹çš„ä¸»ç›®å½•åˆ—è¡¨ã€‚\n",
    "        min_difficulty (int): æœ€ä½Žéš¾åº¦çº§åˆ«ã€‚\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: åŒ…å«æ¯ä¸ªçº§åˆ«çš„ç›¸å…³ä¿¡æ¯ï¼Œé™å®šä¸º difficulty>=min_difficulty çš„æ›²ç›®ã€‚\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    skipped_songs = 0\n",
    "    skipped_reasons = defaultdict(int)\n",
    "\n",
    "    for directory in directories:\n",
    "        if not directory.exists():\n",
    "            print(f\"ç›®å½•ä¸å­˜åœ¨: {directory}\")\n",
    "            skipped_reasons['missing_directory'] += 1\n",
    "            continue\n",
    "        for folder_path in directory.iterdir():\n",
    "            if not folder_path.is_dir():\n",
    "                continue\n",
    "            json_file_path = folder_path / 'level.json'\n",
    "            if not json_file_path.is_file():\n",
    "                print(f\"ç¼ºå°‘ level.json æ–‡ä»¶åœ¨ {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_level_json'] += 1\n",
    "                continue\n",
    "            try:\n",
    "                with json_file_path.open('r', encoding='utf-8') as json_file:\n",
    "                    level_data = json.load(json_file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"JSON è§£æžé”™è¯¯: {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['json_decode_error'] += 1\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"æ— æ³•è¯»å– {json_file_path}: {e}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['read_error'] += 1\n",
    "                continue\n",
    "\n",
    "            # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„å­—æ®µå­˜åœ¨\n",
    "            try:\n",
    "                level_id = level_data['id']\n",
    "                charts = level_data['charts']\n",
    "                music = level_data['music']\n",
    "            except KeyError as e:\n",
    "                print(f\"ç¼ºå°‘é”® {e} åœ¨æ–‡ä»¶: {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_keys'] += 1\n",
    "                continue\n",
    "\n",
    "            if not charts:\n",
    "                print(f\"åœ¨æ–‡ä»¶ {json_file_path} ä¸­æœªæ‰¾åˆ°ä»»ä½• charts\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['empty_charts'] += 1\n",
    "                continue\n",
    "\n",
    "            chart_difficulty = charts[0].get('difficulty', 0)\n",
    "            if chart_difficulty < min_difficulty:\n",
    "                continue\n",
    "\n",
    "            audio_file_name = music.get('path', '')\n",
    "            if not audio_file_name:\n",
    "                print(f\"åœ¨æ–‡ä»¶ {json_file_path} ä¸­æœªæŒ‡å®š music path\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_music_path'] += 1\n",
    "                continue\n",
    "\n",
    "            audio_file_extensions = ['.mp3', '.ogg', '.wav']\n",
    "            audio_file_path = None\n",
    "            for ext in audio_file_extensions:\n",
    "                aud_path = folder_path / audio_file_name\n",
    "                if aud_path.suffix.lower() == ext and aud_path.is_file():\n",
    "                    audio_file_path = aud_path\n",
    "                    break\n",
    "            if audio_file_path is None:\n",
    "                print(f\"æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ {audio_file_name} å¯¹åº”äºŽ song ID {level_id} åœ¨ {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_audio_file'] += 1\n",
    "                continue\n",
    "\n",
    "            charts_path = folder_path / charts[0].get('path', '')\n",
    "            if not charts_path.is_file():\n",
    "                print(f\"æœªæ‰¾åˆ° charts æ–‡ä»¶ {charts[0].get('path', '')} å¯¹åº”äºŽ song ID {level_id} åœ¨ {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_charts_file'] += 1\n",
    "                continue\n",
    "\n",
    "            # åˆ›å»ºå”¯ä¸€çš„IDï¼Œç¡®ä¿åç§°å¯è§£æž\n",
    "            unique_id = f\"{directory.name}_{level_id}\"\n",
    "            try:\n",
    "                unique_id.encode('ascii')  # æ£€æŸ¥æ˜¯å¦ä¸ºASCII\n",
    "            except UnicodeEncodeError:\n",
    "                print(f\"æ— æ³•è§£æžçš„ unique_id: {unique_id}ï¼Œè·³è¿‡è¯¥æ›²å­\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['unparseable_unique_id'] += 1\n",
    "                continue\n",
    "\n",
    "            # æ·»åŠ åˆ°ç»“æžœ\n",
    "            result[unique_id] = {\n",
    "                'level': level_data,\n",
    "                'mp3_path': str(audio_file_path),\n",
    "                'charts_path': str(charts_path),\n",
    "                'charter': level_data.get('charter', ''),\n",
    "                'type': charts[0].get('type', ''),\n",
    "                'difficulty': chart_difficulty\n",
    "            }\n",
    "\n",
    "    print(f\"æ€»å…±è·³è¿‡çš„æ›²å­æ•°é‡: {skipped_songs}\")\n",
    "    for reason, count in skipped_reasons.items():\n",
    "        print(f\"è·³è¿‡åŽŸå›  '{reason}': {count} ä¸ªæ›²å­\")\n",
    "    return result\n",
    "\n",
    "def extract_charts(path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ä»ŽJSONæ–‡ä»¶ä¸­æå–å›¾è¡¨æ•°æ®ã€‚\n",
    "\n",
    "    Args:\n",
    "        path (str): å›¾è¡¨JSONæ–‡ä»¶çš„è·¯å¾„ã€‚\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: å›¾è¡¨æ•°æ®ã€‚\n",
    "    \"\"\"\n",
    "    file_path = Path(path)\n",
    "    if file_path.exists() and file_path.is_file():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return data\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"JSON decode error for file: {path}\")\n",
    "    return {}\n",
    "\n",
    "def find_single_tempo_songs(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    ç­›é€‰å‡ºBPMä¸å˜çš„æ­Œæ›²ã€‚\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): åŒ…å«æ‰€æœ‰æ­Œæ›²ä¿¡æ¯çš„å­—å…¸ã€‚\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: BPMä¸å˜çš„æ­Œæ›²åˆ—è¡¨ã€‚\n",
    "    \"\"\"\n",
    "    single_tempo_songs = []\n",
    "    for song_id, song in data.items():\n",
    "        charts_data = extract_charts(song['charts_path'])\n",
    "        if charts_data and 'tempo_list' in charts_data:\n",
    "            if len(charts_data['tempo_list']) == 1:\n",
    "                single_tempo_songs.append(song)\n",
    "    return single_tempo_songs\n",
    "\n",
    "def map_note_to_time(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    å°†éŸ³ç¬¦æ˜ å°„åˆ°æ—¶é—´ã€‚\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): å›¾è¡¨æ•°æ®ã€‚\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: æ¯ä¸ªéŸ³ç¬¦çš„æ—¶é—´æ˜ å°„ä¿¡æ¯ã€‚\n",
    "    \"\"\"\n",
    "    time_base = data.get('time_base', 1000) \n",
    "    offset_universal = 0.033 \n",
    "    offset = data.get('music_offset', 0) - offset_universal\n",
    "    tempo_list = sorted(data.get('tempo_list', []), key=lambda x: x['tick'])  \n",
    "    note_list = data.get('note_list', [])\n",
    "    \n",
    "    note_time_map = []\n",
    "    accumulated_time = 0 \n",
    "    last_tick = 0  \n",
    "    if not tempo_list:\n",
    "        return note_time_map\n",
    "    current_tempo = tempo_list[0]['value']  \n",
    "    tempo_index = 0  \n",
    "\n",
    "    for note in note_list:\n",
    "        note_tick = note['tick']\n",
    "        while tempo_index < len(tempo_list) - 1 and tempo_list[tempo_index + 1]['tick'] <= note_tick:\n",
    "            next_tempo_tick = tempo_list[tempo_index + 1]['tick']\n",
    "            ticks_in_interval = next_tempo_tick - last_tick\n",
    "            tick_duration = (current_tempo / time_base) \n",
    "            accumulated_time += ticks_in_interval * tick_duration\n",
    "            last_tick = next_tempo_tick\n",
    "            tempo_index += 1\n",
    "            current_tempo = tempo_list[tempo_index]['value']\n",
    "\n",
    "        ticks_in_interval = note_tick - last_tick\n",
    "        tick_duration = (current_tempo / time_base) \n",
    "        note_time = accumulated_time + ticks_in_interval * tick_duration\n",
    "        note_time_map.append({\n",
    "            'note_id': note.get('id', 0),\n",
    "            'note_tick': note_tick,\n",
    "            'note_time_microseconds': note_time - offset * 1_000_000,\n",
    "            'note_type': note.get('type', 0),\n",
    "            'note_x': note.get('x', 0.0)\n",
    "        })\n",
    "\n",
    "    return note_time_map\n",
    "\n",
    "def generate_mel_spectrogram(\n",
    "    audio_path: Path,\n",
    "    log_enable: bool = True,\n",
    "    bpm_info: List[Dict[str, float]] = None,\n",
    "    note_info: List[Dict[str, Any]] = None,\n",
    "    max_frames: int = 5000  # æ–°å¢žå‚æ•°ï¼Œé™åˆ¶æœ€å¤§å¸§æ•°\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    ç”ŸæˆMelé¢‘è°±å›¾åŠç›¸åº”çš„æ ‡ç­¾ï¼Œå¹¶é™åˆ¶å…¶é•¿åº¦ä¸è¶…è¿‡max_framesã€‚\n",
    "    \n",
    "    Args:\n",
    "        audio_path (Path): éŸ³é¢‘æ–‡ä»¶è·¯å¾„ã€‚\n",
    "        log_enable (bool): æ˜¯å¦è¿›è¡Œå¯¹æ•°å˜æ¢ã€‚\n",
    "        bpm_info (List[Dict[str, float]]): BPMä¿¡æ¯ã€‚\n",
    "        note_info (List[Dict[str, Any]]): éŸ³ç¬¦ä¿¡æ¯ã€‚\n",
    "        max_frames (int): æœ€å¤§å¸§æ•°ã€‚\n",
    "    \n",
    "    Returns:\n",
    "        dict: åŒ…å«Melé¢‘è°±å›¾ã€presenceæ ‡ç­¾å’Œposition_labelsçš„å­—å…¸ã€‚\n",
    "    \"\"\"\n",
    "    data, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE)\n",
    "    assert sr == SAMPLE_RATE, f\"Expected sample rate {SAMPLE_RATE}, but got {sr}\"\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=data,\n",
    "        sr=sr, \n",
    "        hop_length=HOP_LENGTH, \n",
    "        fmin=30.0, \n",
    "        n_mels=NMELS, \n",
    "        htk=True\n",
    "    )\n",
    "    if log_enable:\n",
    "        mel = np.log(np.clip(mel, 1e-5, None))\n",
    "    mel = mel.T  # (æ—¶é—´æ­¥, ç‰¹å¾)\n",
    "\n",
    "    # é™åˆ¶Melé¢‘è°±å›¾çš„é•¿åº¦\n",
    "    if mel.shape[0] > max_frames:\n",
    "        mel = mel[:max_frames]\n",
    "\n",
    "    data_dic = {\"mel\": mel}\n",
    "\n",
    "    # åˆå§‹åŒ–presenceæ ‡ç­¾å’Œposition_labels\n",
    "    presence_labels = np.zeros(mel.shape[0], dtype=int)  # presenceæ ‡ç­¾\n",
    "    position_labels = -1 * np.ones(mel.shape[0], dtype=int)  # -1è¡¨ç¤ºæ— éŸ³ç¬¦\n",
    "\n",
    "    if bpm_info and note_info:\n",
    "        mel_length = mel.shape[0]\n",
    "        for note in note_info:\n",
    "            time_sec = note['note_time_microseconds'] / 1_000_000\n",
    "            frame_idx = int(time_sec * SAMPLE_RATE / HOP_LENGTH)\n",
    "            if 0 <= frame_idx < mel_length:  # ç¡®ä¿ frame_idx éžè´Ÿä¸”ä¸è¶…å‡º\n",
    "                presence_labels[frame_idx] = 1  # Presence\n",
    "                # è®¡ç®—ç›¸å¯¹äºŽçª—å£ä¸­å¿ƒçš„ç›¸å¯¹ä½ç½®ï¼ˆå‡è®¾çª—å£å¤§å°ä¸º40ï¼‰\n",
    "                position = frame_idx  # æ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´\n",
    "                position_labels[frame_idx] = position\n",
    "\n",
    "    data_dic[\"labels\"] = presence_labels  # shape: (mel_length,)\n",
    "    data_dic[\"position_labels\"] = position_labels  # shape: (mel_length,)\n",
    "\n",
    "    return data_dic\n",
    "\n",
    "# %% [markdown]\n",
    "# ## æ•°æ®é›†ä¸Žæ•°æ®åŠ è½½\n",
    "\n",
    "# %%\n",
    "class TimeUnit(enum.Enum):\n",
    "    milliseconds = \"milliseconds\"\n",
    "    frames = \"frames\"\n",
    "    seconds = \"seconds\"\n",
    "\n",
    "class OnsetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset ç±»ï¼Œç”¨äºŽåŠ è½½å’Œæä¾›æ•°æ®ã€‚\n",
    "    æ¯ä¸ªæ ·æœ¬åŒ…å«å½“å‰å¸§åŠå…¶å‰åŽ40ä¸ªå¸§ï¼ˆå…±81å¸§ï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, data: Dict[str, Any], bpm_info: Dict[str, List[Dict[str, float]]], score_positions: Dict[str, List[Dict[str, Any]]], window_size: int = 40, transform=None):\n",
    "        self.data = data\n",
    "        self.bpm_info = bpm_info\n",
    "        self.score_positions = score_positions\n",
    "        self.transform = transform\n",
    "        self.window_size = window_size\n",
    "        self.samples = self.prepare_samples()\n",
    "        \n",
    "    def prepare_samples(self) -> List[Tuple[np.ndarray, np.ndarray, int]]:\n",
    "        \"\"\"\n",
    "        å‡†å¤‡æ•°æ®æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«81å¸§çš„Melé¢‘è°±å›¾å’Œå¯¹åº”çš„æ ‡ç­¾ã€‚\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for song_id, song in self.data.items():\n",
    "            mp3_path = song[\"mp3_path\"]\n",
    "            charts_path = song[\"charts_path\"]\n",
    "            difficulty = song['difficulty']\n",
    "            \n",
    "            mel_dict = generate_mel_spectrogram(\n",
    "                audio_path=Path(mp3_path),\n",
    "                log_enable=True,\n",
    "                bpm_info=self.bpm_info.get(song_id, None),\n",
    "                note_info=self.score_positions.get(song_id, None)\n",
    "            )\n",
    "            if \"labels\" in mel_dict:\n",
    "                mel = mel_dict[\"mel\"]  # shape: (num_frames, n_mels)\n",
    "                labels = mel_dict[\"labels\"]  # shape: (num_frames,)\n",
    "\n",
    "                num_frames = mel.shape[0]\n",
    "                for i in range(num_frames):\n",
    "                    start = max(i - self.window_size, 0)\n",
    "                    end = min(i + self.window_size + 1, num_frames)\n",
    "                    \n",
    "                    # å¡«å……ä¸è¶³çš„å¸§\n",
    "                    pad_before = self.window_size - i if i < self.window_size else 0\n",
    "                    pad_after = (i + self.window_size + 1) - num_frames if (i + self.window_size + 1) > num_frames else 0\n",
    "                    \n",
    "                    mel_window = mel[start:end]\n",
    "                    if pad_before > 0:\n",
    "                        mel_window = np.pad(mel_window, ((pad_before, 0), (0, 0)), mode='constant')\n",
    "                    if pad_after > 0:\n",
    "                        mel_window = np.pad(mel_window, ((0, pad_after), (0, 0)), mode='constant')\n",
    "                    \n",
    "                    label = labels[i]\n",
    "                    \n",
    "                    samples.append((mel_window, label, difficulty))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        mel_window, label, difficulty = self.samples[idx]\n",
    "        mel_window = torch.from_numpy(mel_window).float()  # shape: (81, n_mels)\n",
    "        label = torch.tensor(label).float()  # shape: ()\n",
    "        \n",
    "        if self.transform:\n",
    "            mel_window, label = self.transform(mel_window, label)\n",
    "\n",
    "        return mel_window, label, difficulty\n",
    "\n",
    "def collate_fn_padded(batch: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    è‡ªå®šä¹‰çš„collate_fnï¼Œç”¨äºŽå¤„ç†æ‰¹æ¬¡æ•°æ®ã€‚\n",
    "    \"\"\"\n",
    "    mel, labels, difficulties = zip(*batch)\n",
    "    \n",
    "    mel = torch.stack(mel, dim=0)  # (batch_size, 81, n_mels)\n",
    "    labels = torch.stack(labels, dim=0)  # (batch_size,)\n",
    "\n",
    "    return mel, labels, difficulties\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Presenceæ¨¡åž‹å®šä¹‰ï¼ˆä¿æŒä»£ç 2å‡ ä¹Žä¸å˜ï¼‰\n",
    "\n",
    "# %%\n",
    "class CNNOnsetDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    åŸºäºŽå·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰çš„Onsetæ£€æµ‹æ¨¡åž‹ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, num_classes: int = 1, dropout: float = 0.5):\n",
    "        super(CNNOnsetDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # è®¡ç®—æ± åŒ–åŽçš„ç‰¹å¾é•¿åº¦\n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)  # é˜²æ­¢ç‰¹å¾é•¿åº¦ä¸º0\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)  # å‡è®¾ç»è¿‡ä¸‰æ¬¡æ± åŒ–\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 81, n_mels]\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # è½¬æ¢ä¸º [batch_size, n_mels, 81]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 64, 40]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 128, 20]\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 256, 10]\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 2560]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CNNOnsetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels: int, dropout: float = 0.5):\n",
    "        super(CNNOnsetFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 81, n_mels)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, n_mels, 81)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 64, 40)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 128, 20)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 256, 10)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # (batch_size, 2560)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # (batch_size, 512)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # ä¸å†æ‰§è¡Œfc2ï¼Œç›´æŽ¥è¿”å›ž512ç»´ç‰¹å¾\n",
    "        return x\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Typeæ¨¡åž‹å®šä¹‰ï¼ˆä¿®æ”¹ä¸ºCNNï¼‰\n",
    "\n",
    "# %%\n",
    "class CNNTypePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    åŸºäºŽå·ç§¯ç¥žç»ç½‘ç»œï¼ˆCNNï¼‰çš„Typeé¢„æµ‹æ¨¡åž‹ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, num_types: int = 5, dropout: float = 0.5):\n",
    "        super(CNNTypePredictor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # è®¡ç®—æ± åŒ–åŽçš„ç‰¹å¾é•¿åº¦\n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)  # é˜²æ­¢ç‰¹å¾é•¿åº¦ä¸º0\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)  # å‡è®¾ç»è¿‡ä¸‰æ¬¡æ± åŒ–\n",
    "        self.fc_type = nn.Linear(512, num_types)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 81, n_mels]\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # è½¬æ¢ä¸º [batch_size, n_mels, 81]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 64, 40]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 128, 20]\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 256, 10]\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 2560]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        type_out = self.fc_type(x)  # [batch_size, num_types]\n",
    "        \n",
    "        return type_out\n",
    "\n",
    "# %% [markdown]\n",
    "# ## å¯è§†åŒ–å‡½æ•°\n",
    "\n",
    "# %%\n",
    "def visualize_presence_predictions(mel: np.ndarray, labels: np.ndarray, preds: np.ndarray, start_time: float = 0, end_time: float = 5):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–æ¨¡åž‹çš„presenceé¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾ã€‚\n",
    "\n",
    "    Args:\n",
    "        mel (np.ndarray): Melé¢‘è°±å›¾ï¼Œå½¢çŠ¶ä¸º (seq_len, feature_dim)\n",
    "        labels (np.ndarray): çœŸå®žlabelsï¼Œå½¢çŠ¶ä¸º (seq_len,)\n",
    "        preds (np.ndarray): æ¨¡åž‹é¢„æµ‹çš„presenceåˆ†æ•°ï¼Œå½¢çŠ¶ä¸º (seq_len,)\n",
    "        start_time (float): å¯è§†åŒ–çš„å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "        end_time (float): å¯è§†åŒ–çš„ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰\n",
    "    \"\"\"\n",
    "    # åº”ç”¨ Sigmoid æ¿€æ´»\n",
    "    presence_pred = 1 / (1 + np.exp(-preds))\n",
    "    \n",
    "    # åº”ç”¨é˜ˆå€¼ä¸º0.5\n",
    "    presence_final = (presence_pred >= 0.5).astype(int)\n",
    "\n",
    "    # è®¡ç®—æ—¶é—´è½´\n",
    "    total_time = mel.shape[0] * HOP_LENGTH / SAMPLE_RATE\n",
    "    times = np.linspace(0, total_time, num=mel.shape[0])\n",
    "\n",
    "    # ç¡®å®šå¯è§†åŒ–çš„å¸§èŒƒå›´\n",
    "    start_frame = int(start_time * SAMPLE_RATE / HOP_LENGTH)\n",
    "    end_frame = int(end_time * SAMPLE_RATE / HOP_LENGTH)\n",
    "\n",
    "    # ç¡®ä¿end_frameä¸è¶…è¿‡åºåˆ—é•¿åº¦\n",
    "    end_frame = min(end_frame, mel.shape[0])\n",
    "\n",
    "    # è£å‰ªæ•°æ®\n",
    "    mel_cropped = mel[start_frame:end_frame]\n",
    "    labels_cropped = labels[start_frame:end_frame]\n",
    "    presence_pred_cropped = presence_pred[start_frame:end_frame]\n",
    "    presence_final_cropped = presence_final[start_frame:end_frame]\n",
    "\n",
    "    # åˆ›å»ºå­å›¾\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    # ç»˜åˆ¶Melé¢‘è°±å›¾\n",
    "    img = librosa.display.specshow(\n",
    "        mel_cropped.T,\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        x_coords=times[start_frame:end_frame],\n",
    "        ax=axs[0],\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        fmax=8000\n",
    "    )\n",
    "    axs[0].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img, ax=axs[0], format='%+2.0f dB')\n",
    "\n",
    "    # ç»˜åˆ¶Presenceé¢„æµ‹ä¸ŽçœŸå®žæ ‡ç­¾\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        presence_pred_cropped.flatten(),\n",
    "        label='Presence Prediction (Raw)',\n",
    "        color='red',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        presence_final_cropped,\n",
    "        label='Presence Prediction (Threshold=0.50)',\n",
    "        color='orange',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        labels_cropped.flatten(),\n",
    "        label='Presence Ground Truth',\n",
    "        color='blue',\n",
    "        linestyle='dashed'\n",
    "    )\n",
    "\n",
    "    axs[1].set_title('Presence Predictions vs Ground Truth (Threshold: 0.50)')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].set_xlabel('Time (s)')\n",
    "    axs[1].set_ylabel('Presence')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_presence_predictions_single(mel: np.ndarray, label: np.ndarray, pred: np.ndarray, start_time: float = 0, end_time: float = 5):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–å•ä¸ªæ ·æœ¬çš„presenceé¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾ã€‚\n",
    "    \n",
    "    Args:\n",
    "        mel (np.ndarray): Melé¢‘è°±å›¾ï¼Œå½¢çŠ¶ä¸º (81, n_mels)\n",
    "        label (np.ndarray): çœŸå®žlabelsï¼Œå½¢çŠ¶ä¸º (1,)\n",
    "        pred (np.ndarray): æ¨¡åž‹é¢„æµ‹çš„presenceåˆ†æ•°ï¼Œå½¢çŠ¶ä¸º (1,)\n",
    "        start_time (float): å¯è§†åŒ–çš„å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "        end_time (float): å¯è§†åŒ–çš„ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰\n",
    "    \"\"\"\n",
    "    # åº”ç”¨ Sigmoid æ¿€æ´»\n",
    "    presence_pred = 1 / (1 + np.exp(-pred))\n",
    "    \n",
    "    # åº”ç”¨é˜ˆå€¼ä¸º0.5\n",
    "    presence_final = (presence_pred >= 0.5).astype(int)\n",
    "    \n",
    "    # è®¡ç®—æ—¶é—´è½´ï¼ˆå‡è®¾çª—å£ä¸­å¿ƒå¸§å¯¹åº”å½“å‰æ—¶é—´ï¼‰\n",
    "    total_time = WINDOW_SIZE * 2 * HOP_LENGTH / SAMPLE_RATE  # å‰åŽå¸§æ€»æ—¶é—´\n",
    "    times = np.linspace(-WINDOW_SIZE * HOP_LENGTH / SAMPLE_RATE, WINDOW_SIZE * HOP_LENGTH / SAMPLE_RATE, num=mel.shape[0])\n",
    "    \n",
    "    # åˆ›å»ºå­å›¾\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # ç»˜åˆ¶Melé¢‘è°±å›¾\n",
    "    img = librosa.display.specshow(\n",
    "        mel.T,\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        x_coords=times,\n",
    "        ax=axs[0],\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        fmax=8000\n",
    "    )\n",
    "    axs[0].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img, ax=axs[0], format='%+2.0f dB')\n",
    "    \n",
    "    # ç»˜åˆ¶Presenceé¢„æµ‹ä¸ŽçœŸå®žæ ‡ç­¾\n",
    "    axs[1].bar(0, presence_pred, label='Presence Prediction (Raw)', color='red', alpha=0.6)\n",
    "    axs[1].bar(0, presence_final, label='Presence Prediction (Threshold=0.50)', color='orange', alpha=0.6)\n",
    "    axs[1].bar(0, label, label='Presence Ground Truth', color='blue', alpha=0.6)\n",
    "    \n",
    "    axs[1].set_title('Presence Predictions vs Ground Truth')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].set_xlabel('Current Frame')\n",
    "    axs[1].set_ylabel('Presence')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_type_predictions(mel: np.ndarray, labels: np.ndarray, preds: np.ndarray, start_time: float = 0, end_time: float = 5, hop_length: int = HOP_LENGTH, sample_rate: int = SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–æ¨¡åž‹çš„Typeé¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾ã€‚\n",
    "\n",
    "    Args:\n",
    "        mel (np.ndarray): Melé¢‘è°±å›¾ï¼Œå½¢çŠ¶ä¸º (seq_len, feature_dim)\n",
    "        labels (np.ndarray): çœŸå®žlabelsï¼Œå½¢çŠ¶ä¸º (seq_len,)\n",
    "        preds (np.ndarray): æ¨¡åž‹é¢„æµ‹çš„typeåˆ†æ•°ï¼Œå½¢çŠ¶ä¸º (seq_len, num_types)\n",
    "        start_time (float): å¯è§†åŒ–çš„å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "        end_time (float): å¯è§†åŒ–çš„ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰\n",
    "        hop_length (int): hop_lengthå‚æ•°\n",
    "        sample_rate (int): é‡‡æ ·çŽ‡\n",
    "    \"\"\"\n",
    "    # åº”ç”¨ Softmax æ¿€æ´»\n",
    "    preds_prob = F.softmax(torch.tensor(preds), dim=-1).numpy()\n",
    "\n",
    "    # è®¡ç®—æ—¶é—´è½´\n",
    "    total_time = mel.shape[0] * hop_length / sample_rate\n",
    "    times = np.linspace(0, total_time, num=mel.shape[0])\n",
    "\n",
    "    # ç¡®å®šå¯è§†åŒ–çš„å¸§èŒƒå›´\n",
    "    start_frame = int(start_time * sample_rate / hop_length)\n",
    "    end_frame = int(end_time * sample_rate / hop_length)\n",
    "\n",
    "    # è£å‰ªæ•°æ®\n",
    "    labels_cropped = labels[start_frame:end_frame]\n",
    "    preds_cropped = preds_prob[start_frame:end_frame]\n",
    "    times_cropped = times[start_frame:end_frame]\n",
    "\n",
    "    # å®šä¹‰é¢œè‰²æ˜ å°„ï¼ˆä½¿ç”¨matplotlibçš„tab10é¢œè‰²é›†ï¼‰\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    num_types = preds_cropped.shape[1]\n",
    "    colors = [cmap(i) for i in range(num_types)]\n",
    "\n",
    "    # åˆ›å»ºå›¾è¡¨\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    # ç»˜åˆ¶ç±»åž‹æ¦‚çŽ‡\n",
    "    for type_idx in range(num_types):\n",
    "        plt.plot(\n",
    "            times_cropped,\n",
    "            preds_cropped[:, type_idx],\n",
    "            label=f'Type {type_idx}',\n",
    "            color=colors[type_idx],\n",
    "            alpha=0.6\n",
    "        )\n",
    "\n",
    "    # ç»˜åˆ¶çœŸå®žæ ‡ç­¾\n",
    "    for idx, label in enumerate(labels_cropped):\n",
    "        if label == 0:\n",
    "            continue  # è·³è¿‡ç±»åž‹0ï¼ˆå‡è®¾ä¸ºæ— äº‹ä»¶ï¼‰\n",
    "        plt.scatter(\n",
    "            times_cropped[idx],\n",
    "            preds_cropped[idx, label],\n",
    "            color=colors[label],\n",
    "            marker='x',\n",
    "            s=50,\n",
    "            label=f'Ground Truth Type {label}' if idx == 0 else \"\",  # åªä¸ºå›¾ä¾‹æ·»åŠ ä¸€æ¬¡\n",
    "            zorder=5\n",
    "        )\n",
    "        # ç»˜åˆ¶ç«–çº¿\n",
    "        plt.axvline(\n",
    "            x=times_cropped[idx],\n",
    "            color=colors[label],\n",
    "            linestyle='--',\n",
    "            alpha=0.5,\n",
    "            linewidth=1\n",
    "        )\n",
    "\n",
    "    # æ·»åŠ æ ‡é¢˜å’Œæ ‡ç­¾\n",
    "    plt.title('Type Probabilities and Ground Truth', fontsize=14)\n",
    "    plt.xlabel('Time (s)', fontsize=12)\n",
    "    plt.ylabel('Probability', fontsize=12)\n",
    "\n",
    "    # è®¾ç½®å›¾ä¾‹ï¼Œé¿å…é‡å¤\n",
    "    handles, labels_legend = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels_legend, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize='small')\n",
    "\n",
    "    # è®¾ç½® x è½´èŒƒå›´\n",
    "    plt.xlim(start_time, end_time)\n",
    "\n",
    "    # åªåœ¨åº•éƒ¨æ˜¾ç¤º y è½´æ ‡ç­¾\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_label_coords(1.05, 0.5)\n",
    "\n",
    "    # æ˜¾ç¤ºå›¾è¡¨\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_position_predictions(true_positions: List[int], pred_positions: List[int], num_samples: int = 100):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–çœŸå®žä½ç½®ä¸Žé¢„æµ‹ä½ç½®çš„å¯¹æ¯”ã€‚\n",
    "    \n",
    "    Args:\n",
    "        true_positions (List[int]): çœŸå®žä½ç½®åˆ—è¡¨ã€‚\n",
    "        pred_positions (List[int]): é¢„æµ‹ä½ç½®åˆ—è¡¨ã€‚\n",
    "        num_samples (int): å¯è§†åŒ–çš„æ ·æœ¬æ•°é‡ã€‚\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    if len(true_positions) < num_samples:\n",
    "        num_samples = len(true_positions)\n",
    "    indices = np.random.choice(len(true_positions), size=num_samples, replace=False)\n",
    "    true = np.array(true_positions)[indices]\n",
    "    pred = np.array(pred_positions)[indices]\n",
    "    \n",
    "    plt.scatter(range(num_samples), true, label='True Position', alpha=0.6, color='blue')\n",
    "    plt.scatter(range(num_samples), pred, label='Predicted Position', alpha=0.6, color='red')\n",
    "    plt.title('True vs Predicted Note Positions')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Position Index')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_position_distribution(true_positions: List[int], pred_positions: List[int]):\n",
    "    \"\"\"\n",
    "    å¯è§†åŒ–çœŸå®žä½ç½®ä¸Žé¢„æµ‹ä½ç½®çš„åˆ†å¸ƒã€‚\n",
    "    \n",
    "    Args:\n",
    "        true_positions (List[int]): çœŸå®žä½ç½®åˆ—è¡¨ã€‚\n",
    "        pred_positions (List[int]): é¢„æµ‹ä½ç½®åˆ—è¡¨ã€‚\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(true_positions, bins=81, alpha=0.5, label='True Positions', color='blue', density=True)\n",
    "    plt.hist(pred_positions, bins=81, alpha=0.5, label='Predicted Positions', color='red', density=True)\n",
    "    plt.title('Distribution of True and Predicted Positions')\n",
    "    plt.xlabel('Position Index')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## è®­ç»ƒä¸ŽéªŒè¯å‡½æ•°\n",
    "\n",
    "# %%\n",
    "# Presenceæ¨¡åž‹è®­ç»ƒå‡½æ•°\n",
    "def train_epoch_cnn(model: nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device, loss_fn: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    è®­ç»ƒä¸€ä¸ªepochï¼ˆCNNç‰ˆï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Presence\", leave=False)\n",
    "\n",
    "    for mel, labels, difficulties in progress_bar:\n",
    "        mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "        labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # å‰å‘ä¼ æ’­\n",
    "        outputs = model(mel)  # (batch_size, 1)\n",
    "        outputs = outputs.squeeze(1)  # (batch_size)\n",
    "\n",
    "        # è®¡ç®—æŸå¤±\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "\n",
    "        # æ¢¯åº¦è£å‰ª\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "# Presenceæ¨¡åž‹éªŒè¯å‡½æ•°\n",
    "def validate_epoch_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module) -> Tuple[float, Dict[int, Dict[str, List[Any]]]]:\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    difficulty_preds = defaultdict(lambda: {'y_true': [], 'y_scores': []})\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validation Presence\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, difficulties in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            outputs = model(mel)  # (batch_size, 1)\n",
    "            outputs = outputs.squeeze(1)  # (batch_size)\n",
    "            # ç§»é™¤ä»¥ä¸‹è¡Œï¼Œå› ä¸ºlabelså·²ç»æ˜¯ (batch_size,) å½¢çŠ¶\n",
    "            # labels = labels.squeeze(1)  # (batch_size)\n",
    "\n",
    "            # è®¡ç®—æŸå¤±\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            # æ”¶é›†é¢„æµ‹åˆ†æ•°å’ŒçœŸå®žæ ‡ç­¾ï¼ŒæŒ‰éš¾åº¦çº§åˆ«åˆ†ç»„\n",
    "            presence_pred_np = outputs.cpu().numpy()\n",
    "            presence_target_np = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(mel.size(0)):\n",
    "                difficulty = difficulties[i]\n",
    "                y_true = presence_target_np[i]\n",
    "                y_score = presence_pred_np[i]\n",
    "                difficulty_preds[difficulty]['y_true'].append(y_true)\n",
    "                difficulty_preds[difficulty]['y_scores'].append(y_score)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss, difficulty_preds\n",
    "\n",
    "# Typeæ¨¡åž‹è®­ç»ƒå‡½æ•°ï¼ˆCNNç‰ˆï¼‰\n",
    "def train_epoch_cnn_type(model: nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device, loss_fn: nn.Module, num_types: int) -> float:\n",
    "    \"\"\"\n",
    "    è®­ç»ƒä¸€ä¸ªepochï¼ˆType CNNç‰ˆï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Type CNN\", leave=False)\n",
    "\n",
    "    for mel, labels, lengths in progress_bar:\n",
    "        mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "        labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # å‰å‘ä¼ æ’­\n",
    "        type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "        # è®¡ç®—æŸå¤±\n",
    "        loss = loss_fn(type_pred, labels)\n",
    "\n",
    "        # åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "\n",
    "        # æ¢¯åº¦è£å‰ª\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # è®¡ç®—å‡†ç¡®çŽ‡\n",
    "        preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1)\n",
    "        acc = (preds == labels).float().mean().item()\n",
    "        running_acc += acc\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Acc': f'{acc*100:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Typeæ¨¡åž‹éªŒè¯å‡½æ•°ï¼ˆCNNç‰ˆï¼‰\n",
    "def validate_epoch_cnn_type(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module, num_types: int) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡åž‹ï¼ˆCNNç‰ˆï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validation Type CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, lengths in progress_bar:\n",
    "            mel = mel.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "            # è®¡ç®—æŸå¤±\n",
    "            loss = loss_fn(type_pred, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # è®¡ç®—å‡†ç¡®çŽ‡\n",
    "            preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1)\n",
    "            acc = (preds == labels).float().mean().item()\n",
    "            running_acc += acc\n",
    "\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Acc': f'{acc*100:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# %% [markdown]\n",
    "# ## æ¨¡åž‹è¯„ä¼°å‡½æ•°\n",
    "\n",
    "# %%\n",
    "def evaluate_test_set_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module):\n",
    "    \"\"\"\n",
    "    åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°CNNæ¨¡åž‹ã€‚\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    difficulty_metrics = defaultdict(lambda: {'y_true': [], 'y_pred': []})\n",
    "    all_preds, all_labels = [], []\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Testing Presence CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, difficulties in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            outputs = model(mel)  # (batch_size, 1)\n",
    "            outputs = outputs.squeeze(1)  # (batch_size)\n",
    "            labels = labels.squeeze(1)  # (batch_size)\n",
    "\n",
    "            # è®¡ç®—æŸå¤±ï¼ˆå¯é€‰ï¼‰\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾\n",
    "            presence_pred_np = outputs.cpu().numpy()\n",
    "            presence_target_np = labels.cpu().numpy()\n",
    "\n",
    "            # åº”ç”¨ Sigmoid æ¿€æ´»\n",
    "            presence_pred_sigmoid = 1 / (1 + np.exp(-presence_pred_np))\n",
    "\n",
    "            # ä½¿ç”¨é˜ˆå€¼0.5è¿›è¡Œé¢„æµ‹\n",
    "            y_pred = (presence_pred_sigmoid >= 0.5).astype(int)\n",
    "            y_true = presence_target_np.astype(int)\n",
    "\n",
    "            # æ”¶é›†æ‰€æœ‰é¢„æµ‹å’Œæ ‡ç­¾ç”¨äºŽåˆ†å¸ƒ\n",
    "            all_preds.extend(presence_pred_sigmoid.tolist())\n",
    "            all_labels.extend(presence_target_np.tolist())\n",
    "\n",
    "            # æŒ‰éš¾åº¦çº§åˆ«åˆ†ç»„\n",
    "            for i in range(mel.size(0)):\n",
    "                difficulty = difficulties[i]\n",
    "                difficulty_metrics[difficulty]['y_true'].append(y_true[i])\n",
    "                difficulty_metrics[difficulty]['y_pred'].append(y_pred[i])\n",
    "\n",
    "    # è½¬æ¢ä¸º NumPy æ•°ç»„\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # ç»˜åˆ¶åˆ†å¸ƒ\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(all_preds, bins=50, alpha=0.7, label=\"Predictions\", color=\"blue\", density=True)\n",
    "    plt.hist(all_labels, bins=50, alpha=0.7, label=\"Ground Truth\", color=\"orange\", density=True)\n",
    "    plt.title(\"Frame-wise Prediction and Ground Truth Distribution\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # è®¡ç®—æ¯ä¸ªéš¾åº¦çº§åˆ«çš„æŒ‡æ ‡\n",
    "    final_metrics = {}\n",
    "    for diff, metrics in difficulty_metrics.items():\n",
    "        y_true = np.array(metrics['y_true'])\n",
    "        y_pred = np.array(metrics['y_pred'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        final_metrics[diff] = {\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        print(f\"Difficulty {diff}: Accuracy={acc:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1 Score={f1:.4f}\")\n",
    "\n",
    "    return final_metrics\n",
    "\n",
    "def evaluate_test_set_type_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module, num_types: int):\n",
    "    \"\"\"\n",
    "    åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°Type CNNæ¨¡åž‹ã€‚\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Testing Type CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, lengths in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # å‰å‘ä¼ æ’­\n",
    "            type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "            # è®¡ç®—æŸå¤±\n",
    "            loss = loss_fn(type_pred, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # æ”¶é›†é¢„æµ‹å’Œæ ‡ç­¾\n",
    "            preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1).cpu().numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(true.tolist())\n",
    "\n",
    "    # è®¡ç®—æŒ‡æ ‡\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Type Prediction - Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1_score': f1}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## æ•°æ®å‡†å¤‡\n",
    "\n",
    "# %%\n",
    "current_directory = Path().cwd()\n",
    "dataset_dirs = [\n",
    "    current_directory / \"../dataset/A\",\n",
    "    current_directory / \"../dataset/B\",\n",
    "    current_directory / \"../dataset/C\",\n",
    "    current_directory / \"../dataset/Z\"\n",
    "]\n",
    "data = extract_level_json_multiple(dataset_dirs, min_difficulty=15)\n",
    "print(f\"Filtered Data Count (Difficulty>=15): {len(data)}\")\n",
    "# data = dict(list(data.items())[:30])\n",
    "bpm_info_dict = {}\n",
    "score_positions_dict = {}\n",
    "\n",
    "for unique_id, song in data.items():\n",
    "    level_data = song['level']\n",
    "    song_id = unique_id  # ä½¿ç”¨å”¯ä¸€ID\n",
    "    charts_data = extract_charts(song['charts_path'])\n",
    "    if charts_data:\n",
    "        bpm_info = charts_data.get('tempo_list', [])\n",
    "        bpm_info_dict[song_id] = bpm_info\n",
    "        note_time_map = map_note_to_time(charts_data) \n",
    "        # æ¯ä¸ªéŸ³ç¬¦çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ—¶é—´ã€ç±»åž‹å’Œä½ç½®\n",
    "        score_positions = [] \n",
    "        for note in note_time_map:\n",
    "            score_positions.append({\n",
    "                'note_time_microseconds': note['note_time_microseconds'],\n",
    "                'note_type': note.get('note_type', 0),  # ç¡®ä¿æ­¤å­—æ®µå­˜åœ¨\n",
    "                'note_x': note.get('note_x', 0.0)      # ç¡®ä¿æ­¤å­—æ®µå­˜åœ¨\n",
    "            })\n",
    "        score_positions_dict[song_id] = score_positions\n",
    "\n",
    "# %% [markdown]\n",
    "# ## å®šä¹‰æ•°æ®é›†å’Œ DataLoader\n",
    "\n",
    "# %%\n",
    "# å®šä¹‰Presenceæ•°æ®é›†å’Œ DataLoader\n",
    "presence_dataset = OnsetDataset(\n",
    "    data=data, \n",
    "    bpm_info=bpm_info_dict, \n",
    "    score_positions=score_positions_dict,\n",
    "    window_size=WINDOW_SIZE  # å‰åŽ40å¸§\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(presence_dataset))\n",
    "val_size = len(presence_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(presence_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Presence Train Size: {len(train_dataset)}\")\n",
    "print(f\"Presence Validation Size: {len(val_dataset)}\")\n",
    "# ä¸€ä¸‹æ˜¯train çš„ä»£ç ---------------------------------------------------------------------------------------------------\n",
    "# åˆ›å»ºæµ‹è¯•é›†ï¼ˆä½¿ç”¨éªŒè¯é›†çš„ä¸€éƒ¨åˆ†ä½œä¸ºæµ‹è¯•é›†ï¼‰\n",
    "test_size = int(0.5 * len(val_dataset))\n",
    "val_size = len(val_dataset) - test_size\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "print(f\"Presence Validation Size after split: {len(val_dataset)}\")\n",
    "print(f\"Presence Test Size: {len(test_dataset)}\")\n",
    "\n",
    "presence_train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate_fn_padded)\n",
    "presence_val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded)\n",
    "presence_test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Presenceæ¨¡åž‹è®­ç»ƒä¸Žè¯„ä¼°\n",
    "\n",
    "# %%\n",
    "# åˆå§‹åŒ–Presenceæ¨¡åž‹\n",
    "presence_model = CNNOnsetDetector(input_channels=NMELS, num_classes=1, dropout=DROPOUT)\n",
    "presence_model.to(device)\n",
    "\n",
    "# å®šä¹‰ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°\n",
    "presence_optimizer = torch.optim.Adam(presence_model.parameters(), lr=LEARNING_RATE)\n",
    "presence_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# è®­ç»ƒæœ€ä½³Presenceæ¨¡åž‹\n",
    "best_presence_val_loss = float('inf')\n",
    "best_presence_model_path = \"model/best_cnn_onset_model.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Training Presence Model\")\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    train_loss = train_epoch_cnn(presence_model, presence_train_loader, presence_optimizer, device, presence_loss_fn)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # éªŒè¯\n",
    "    val_loss, val_difficulty_preds = validate_epoch_cnn(presence_model, presence_val_loader, device, presence_loss_fn)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # å¦‚æžœéªŒè¯æŸå¤±æ›´ä½Žï¼Œåˆ™ä¿å­˜æ¨¡åž‹\n",
    "    if val_loss < best_presence_val_loss:\n",
    "        best_presence_val_loss = val_loss\n",
    "        torch.save(presence_model.state_dict(), best_presence_model_path)\n",
    "        print(\"Saved Best Presence Model\")\n",
    "\n",
    "# åŠ è½½æœ€ä½³Presenceæ¨¡åž‹\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()\n",
    "# ä¸€ä¸‹æ˜¯train çš„ä»£ç ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## å®šä¹‰Typeæ•°æ®é›†å’Œ DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=2.0, gamma=2, reduction='mean'):\n",
    "        \"\"\"\n",
    "        alpha: ç±»åˆ«å¹³è¡¡å› å­ï¼Œå¯ç”¨äºŽåœ¨ç±»ä¸å¹³è¡¡æ—¶å¯¹å°‘æ•°ç±»è¿›è¡Œé‡æƒé‡\n",
    "        gamma: éš¾æ˜“åº¦è°ƒæŽ§å‚æ•°ï¼Œgammaè¶Šå¤§ï¼Œè¶Šä¸“æ³¨åœ¨éš¾åˆ†ç±»çš„æ ·æœ¬ä¸Š\n",
    "        reduction: æŸå¤±èšåˆæ–¹å¼ï¼Œ'mean'æˆ–'sum'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: [batch_size, num_classes]\n",
    "        # targets: [batch_size]\n",
    "\n",
    "        # èŽ·å–é¢„æµ‹çš„æ¦‚çŽ‡åˆ†å¸ƒ\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        # å–å‡ºå¯¹åº”çœŸå®žç±»åˆ«çš„é¢„æµ‹æ¦‚çŽ‡\n",
    "        pt = probs[range(len(targets)), targets]\n",
    "\n",
    "        # focal losså…¬å¼\n",
    "        loss = -self.alpha * (1 - pt)**self.gamma * torch.log(pt)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# %%\n",
    "class TypeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset ç±»ï¼Œç”¨äºŽåŠ è½½å’Œæä¾›æ•°æ®ã€‚\n",
    "    æ¯ä¸ªæ ·æœ¬åŒ…å«å½“å‰å¸§åŠå…¶å‰åŽ40ä¸ªå¸§ï¼ˆå…±81å¸§ï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, data: Dict[str, Any], bpm_info: Dict[str, List[Dict[str, float]]], score_positions: Dict[str, List[Dict[str, Any]]], window_size: int = 40, transform=None):\n",
    "        self.data = data\n",
    "        self.bpm_info = bpm_info\n",
    "        self.score_positions = score_positions\n",
    "        self.transform = transform\n",
    "        self.window_size = window_size\n",
    "        self.samples = self.prepare_samples()\n",
    "        \n",
    "    def prepare_samples(self) -> List[Tuple[np.ndarray, int, int]]:\n",
    "        \"\"\"\n",
    "        å‡†å¤‡æ•°æ®æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«81å¸§çš„Melé¢‘è°±å›¾å’Œå¯¹åº”çš„ç±»åž‹æ ‡ç­¾ã€‚\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for song_id, song in self.data.items():\n",
    "            mp3_path = song[\"mp3_path\"]\n",
    "            charts_path = song[\"charts_path\"]\n",
    "            difficulty = song['difficulty']\n",
    "            \n",
    "            mel_dict = generate_mel_spectrogram(\n",
    "                audio_path=Path(mp3_path),\n",
    "                log_enable=True,\n",
    "                bpm_info=self.bpm_info.get(song_id, None),\n",
    "                note_info=self.score_positions.get(song_id, None)\n",
    "            )\n",
    "            if \"labels\" in mel_dict:\n",
    "                mel = mel_dict[\"mel\"]  # shape: (num_frames, n_mels)\n",
    "                labels = mel_dict[\"labels\"]  # shape: (num_frames,)\n",
    "\n",
    "                num_frames = mel.shape[0]\n",
    "                for i in range(num_frames):\n",
    "                    start = max(i - self.window_size, 0)\n",
    "                    end = min(i + self.window_size + 1, num_frames)\n",
    "                    \n",
    "                    # å¡«å……ä¸è¶³çš„å¸§\n",
    "                    pad_before = self.window_size - i if i < self.window_size else 0\n",
    "                    pad_after = (i + self.window_size + 1) - num_frames if (i + self.window_size + 1) > num_frames else 0\n",
    "                    \n",
    "                    mel_window = mel[start:end]\n",
    "                    if pad_before > 0:\n",
    "                        mel_window = np.pad(mel_window, ((pad_before, 0), (0, 0)), mode='constant')\n",
    "                    if pad_after > 0:\n",
    "                        mel_window = np.pad(mel_window, ((0, pad_after), (0, 0)), mode='constant')\n",
    "                    \n",
    "                    label = labels[i]\n",
    "                    \n",
    "                    samples.append((mel_window, label, difficulty))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        mel_window, label, difficulty = self.samples[idx]\n",
    "        mel_window = torch.from_numpy(mel_window).float()  # shape: (81, n_mels)\n",
    "        label = torch.tensor(label).long()  # shape: ()\n",
    "        \n",
    "        if self.transform:\n",
    "            mel_window, label = self.transform(mel_window, label)\n",
    "\n",
    "        return mel_window, label, difficulty\n",
    "\n",
    "def collate_fn_padded_type(batch: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    è‡ªå®šä¹‰çš„collate_fnï¼Œç”¨äºŽå¤„ç†æ‰¹æ¬¡æ•°æ®ã€‚\n",
    "    \"\"\"\n",
    "    mel, labels, difficulties = zip(*batch)\n",
    "    \n",
    "    mel = torch.stack(mel, dim=0)  # (batch_size, 81, n_mels)\n",
    "    labels = torch.stack(labels, dim=0)  # (batch_size,)\n",
    "\n",
    "    return mel, labels, difficulties\n",
    "\n",
    "type_dataset = TypeDataset(\n",
    "    data=data, \n",
    "    bpm_info=bpm_info_dict, \n",
    "    score_positions=score_positions_dict,\n",
    "    window_size=WINDOW_SIZE  # å‰åŽ40å¸§\n",
    ")\n",
    "\n",
    "# ä¸€ä¸‹æ˜¯train çš„ä»£ç ---------------------------------------------------------------------------------------------------\n",
    "# # åˆ’åˆ†æ•°æ®é›†\n",
    "type_train_size = int(0.8 * len(type_dataset))\n",
    "type_val_size = len(type_dataset) - type_train_size\n",
    "type_train_dataset, type_val_dataset = random_split(type_dataset, [type_train_size, type_val_size])\n",
    "\n",
    "print(f\"Type Train Size: {len(type_train_dataset)}\")\n",
    "print(f\"Type Validation Size: {len(type_val_dataset)}\")\n",
    "\n",
    "# åˆ›å»ºæµ‹è¯•é›†ï¼ˆä½¿ç”¨éªŒè¯é›†çš„ä¸€éƒ¨åˆ†ä½œä¸ºæµ‹è¯•é›†ï¼‰\n",
    "type_test_size = int(0.5 * len(type_val_dataset))\n",
    "type_val_size = len(type_val_dataset) - type_test_size\n",
    "type_val_dataset, type_test_dataset = random_split(type_val_dataset, [type_val_size, type_test_size])\n",
    "\n",
    "print(f\"Type Validation Size after split: {len(type_val_dataset)}\")\n",
    "print(f\"Type Test Size: {len(type_test_dataset)}\")\n",
    "\n",
    "type_train_loader = DataLoader(type_train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate_fn_padded_type)\n",
    "type_val_loader = DataLoader(type_val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded_type)\n",
    "type_test_loader = DataLoader(type_test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded_type)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Typeæ¨¡åž‹å®šä¹‰ä¸Žè®­ç»ƒ\n",
    "\n",
    "# %%\n",
    "# åˆå§‹åŒ–Typeæ¨¡åž‹\n",
    "num_types = 5  # æ ¹æ®éœ€æ±‚è°ƒæ•´\n",
    "type_model = CNNTypePredictor(input_channels=NMELS, num_types=num_types, dropout=DROPOUT)\n",
    "type_model.to(device)\n",
    "\n",
    "# å®šä¹‰ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°\n",
    "type_optimizer = torch.optim.Adam(type_model.parameters(), lr=LEARNING_RATE)\n",
    "type_loss_fn = FocalLoss(alpha=1.0, gamma=2, reduction='mean')\n",
    "\n",
    "\n",
    "# è®­ç»ƒæœ€ä½³Typeæ¨¡åž‹\n",
    "best_type_val_loss = float('inf')\n",
    "best_type_model_path = \"model/best_cnn_type_model.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Training Type Model\")\n",
    "    \n",
    "    # è®­ç»ƒ\n",
    "    train_loss, train_acc = train_epoch_cnn_type(type_model, type_train_loader, type_optimizer, device, type_loss_fn, num_types)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
    "    \n",
    "    # éªŒè¯\n",
    "    val_loss, val_acc = validate_epoch_cnn_type(type_model, type_val_loader, device, type_loss_fn, num_types)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # å¦‚æžœéªŒè¯æŸå¤±æ›´ä½Žï¼Œåˆ™ä¿å­˜æ¨¡åž‹\n",
    "    if val_loss < best_type_val_loss:\n",
    "        best_type_val_loss = val_loss\n",
    "        torch.save(type_model.state_dict(), best_type_model_path)\n",
    "        print(\"Saved Best Type Model\")\n",
    "\n",
    "# åŠ è½½æœ€ä½³Typeæ¨¡åž‹\n",
    "type_model.load_state_dict(torch.load(best_type_model_path))\n",
    "type_model.to(device)\n",
    "type_model.eval()\n",
    "# æ˜¯train çš„ä»£ç ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "num_types = 5  # æ ¹æ®éœ€æ±‚è°ƒæ•´\n",
    "best_presence_model_path = \"model/best_cnn_onset_model.pth\"\n",
    "best_type_model_path = \"model/best_cnn_type_model.pth\"\n",
    "\n",
    "presence_model = CNNOnsetDetector(input_channels=NMELS, num_classes=1, dropout=DROPOUT)\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path, map_location=device))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼\n",
    "\n",
    "type_model = CNNTypePredictor(input_channels=NMELS, num_types=num_types, dropout=DROPOUT)\n",
    "type_model.load_state_dict(torch.load(best_type_model_path, map_location=device))\n",
    "type_model.to(device)\n",
    "type_model.eval()\n",
    "\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
