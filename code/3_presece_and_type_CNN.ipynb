{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.clouddiver.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/arwtdydhqhfa.helamind.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/andogaru.fumiko.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.summernight.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.cereris.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.alone.cytoidlevel/level.json\n",
      "未找到音频文件 �TAKUMI³�OЯDIN -Apocalyptic War-(Re Mastering).mp3 对应于 song ID ant.ordin-tc 在 /data1/yuchen/cytoid/final_code/../dataset/A/ant.ordin-tc.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anthony.lolk_muricaaaaa.cytoidlevel/level.json\n",
      "未找到音频文件 Langley_D - deli.+駄々子 - 最果ての勇者にラブソングを.ogg 对应于 song ID anoppo.furiy 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.furiy.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/aboal.43201.cytoidlevel/level.json\n",
      "未找到音频文件 Vicetone、Kat Nestel - Angels (Radio Edit).wav 对应于 song ID asuna_37 在 /data1/yuchen/cytoid/final_code/../dataset/A/asuna_37.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.rainbow.cytoidlevel/level.json\n",
      "未找到音频文件 self-dissociation - Lidelle、Sobrem、Sennzai.ogg 对应于 song ID anoppo.selfdissociation 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.selfdissociation.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.rainmaker.cytoidlevel/level.json\n",
      "未找到音频文件 コンウェイの子 - sta.ogg 对应于 song ID anoppo.conwayschild 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.conwayschild.cytoidlevel\n",
      "未找到 charts 文件 ARo.txt 对应于 song ID enteraname6 在 /data1/yuchen/cytoid/final_code/../dataset/A/AR-1.cytoidlevel\n",
      "未找到音频文件 黒魔 - Banbard (Chroma Remix).ogg 对应于 song ID anoppo.banbard 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.banbard.cytoidlevel\n",
      "未找到音频文件 削除 (Sakuzyo) - Amateras.ogg 对应于 song ID anoppo.amateras 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.amateras.cytoidlevel\n",
      "未找到音频文件 かめりあ_初音ミク-ヒアソビ-_feat.-初音ミク_(2).ogg 对应于 song ID aniloid.hiasobi 在 /data1/yuchen/cytoid/final_code/../dataset/A/aniloid.hiasobi.cytoidlevel\n",
      "未找到 charts 文件 俗物フェスティバル.json 对应于 song ID anoppo.su 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.su.cytoidlevel\n",
      "未找到音频文件 Sta _ B - スーパーシンメトリー(1).mp3 对应于 song ID anoppo.super 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.super.cytoidlevel\n",
      "未找到音频文件 削除 - PANDORA PARADOXXX.ogg 对应于 song ID anoppo.pandora 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.pandora.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/ant.future.dominators.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.cord.reborn.cytoidlevel/level.json\n",
      "未找到音频文件 With a Billion Worldful of 3 - Mili、DE DE MOUSE.ogg 对应于 song ID anoppo.withabillionworldfulofthree 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.withabillionworldfulofthree.cytoidlevel\n",
      "未找到音频文件 天hshsP.mp3 对应于 song ID angelll.theweak 在 /data1/yuchen/cytoid/final_code/../dataset/A/angelll.theweak.cytoidlevel\n",
      "未找到音频文件 【Hardcore】Requillio _ Dopam!ne 👻Free DL👻.mp3 对应于 song ID ant.requillio-t3 在 /data1/yuchen/cytoid/final_code/../dataset/A/ant.requillio-t3.cytoidlevel\n",
      "无法读取 /data1/yuchen/cytoid/final_code/../dataset/A/archore.lnd.lnyh.cytoidlevel/level.json: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/ap_mumayoru.ely.cytoidlevel/level.json\n",
      "未找到音频文件 kei_iwata - フロンティア↑↑エクスプローラー.ogg 对应于 song ID amaneku.frontier_exploler 在 /data1/yuchen/cytoid/final_code/../dataset/A/amaneku.frontier_exploler.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/ap_megalice.ely.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.wwp.cytoidlevel/level.json\n",
      "未找到音频文件 (音源) 【SDVX】 そして黄金郷へ 【NOFX】 - 1.(音源) [SDVX] そして黄金郷へ [NOFX](Av29726758,P1).mp3 对应于 song ID anoppo.golden 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.golden.cytoidlevel\n",
      "未找到音频文件 雲落kyuu天 - Chapter.Q：Euphoric World - Rabbit House.ogg 对应于 song ID anoppo.euphoricworld 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.euphoricworld.cytoidlevel\n",
      "未找到音频文件 Sta,bqスタヂオ - アージェントシンメトリー.ogg 对应于 song ID anoppo.ink2 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.ink2.cytoidlevel\n",
      "目录不存在: /data1/yuchen/cytoid/final_code/../dataset/C\n",
      "未找到音频文件 kanone,Sennzai - 花と、雪と、ドラムンベース.ogg 对应于 song ID ztz.huayilun 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.huayilun.cytoidlevel\n",
      "未找到音频文件 申东辉 - NB Blast.mp3 对应于 song ID zeng.nbblast 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.nbblast.cytoidlevel\n",
      "未找到音频文件 イロドリミドリ - conflict (斉唱).ogg 对应于 song ID ztz.conflictcover 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.conflictcover.cytoidlevel\n",
      "未找到音频文件 Rintaro Soma - sølips.ogg 对应于 song ID ztz.solips 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.solips.cytoidlevel\n",
      "未找到音频文件 モリモリあつし - Grand-Guignol.mp3 对应于 song ID zeng.grandguignol 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.grandguignol.cytoidlevel\n",
      "未找到音频文件 星河一天.mp3 对应于 song ID zirei.st 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.st.cytoidlevel\n",
      "未找到音频文件 ビートまりお,あまね - ウサテイ20XX.ogg 对应于 song ID ztz.usatei20xxre 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.usatei20xxre.cytoidlevel\n",
      "未找到音频文件 かめりあ - Hello (BPM) 2021.mp3 对应于 song ID zeng.hellobpm 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.hellobpm.cytoidlevel\n",
      "未找到音频文件 Σvreka.mp3 对应于 song ID zirei.evreka 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.evreka.cytoidlevel\n",
      "未找到音频文件 モリモリあつし - Grand-Guignol.mp3 对应于 song ID zeng.grand 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.grand.cytoidlevel\n",
      "未找到音频文件 モンダイナイトリッパー！.mp3 对应于 song ID zirei.mondai 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.mondai.cytoidlevel\n",
      "未找到音频文件 卢文韬 - 奇轮！我的英雄（《激战奇轮2》OP）.mp3 对应于 song ID zeng.qilunmyhero 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.qilunmyhero.cytoidlevel\n",
      "未找到音频文件 六兆年と一夜物語，，.mp3 对应于 song ID zhong_yu_six 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zhong_yu_six.cytoidlevel\n",
      "未找到音频文件 細江慎治 - Kattobi KEIKYU Rider.ogg 对应于 song ID ztz.kattobikeikyurider 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.kattobikeikyurider.cytoidlevel\n",
      "未找到音频文件 Team Grimoire - Excalibur ～Revived resolution～.ogg 对应于 song ID ztz.excalibur 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.excalibur.cytoidlevel\n",
      "未找到音频文件 ぺのれり - Desperado Waltz.ogg 对应于 song ID ztz.desperadowaltz 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.desperadowaltz.cytoidlevel\n",
      "未找到音频文件 miko - 患部で止まってすぐ溶ける - 狂気の优昙华院.ogg 对应于 song ID ztz.huanbu 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.huanbu.cytoidlevel\n",
      "未找到音频文件 V∅rstia.mp3 对应于 song ID zirei.vo 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.vo.cytoidlevel\n",
      "未找到音频文件 ひとりきりのエデン.mp3 对应于 song ID zirei.d36 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.d36.cytoidlevel\n",
      "未找到音频文件 朧月.mp3 对应于 song ID zirei.ml 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.ml.cytoidlevel\n",
      "未找到音频文件 ビートまりお,あまね - ウサテイ20XX.mp3 对应于 song ID ztz.usatei20xx 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.usatei20xx.cytoidlevel\n",
      "未找到音频文件 ピノキオピー,初音ミク - 腐れ外道とチョコレゐト.ogg 对应于 song ID ztz.heterodoxusandchocolate 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.heterodoxusandchocolate.cytoidlevel\n",
      "未找到音频文件 初音 - 千本桜【名伶計畫 F 中文字幕】.mp3 对应于 song ID zhong_yu_1219 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zhong_yu_1219.cytoidlevel\n",
      "未找到音频文件 Se-U-Ra - ネジマキセカイの狂騒曲.mp3 对应于 song ID zeng.kuangsao 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.kuangsao.cytoidlevel\n",
      "未找到音频文件 超熊貓的周遊記.mp3 对应于 song ID zirei.fanta 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.fanta.cytoidlevel\n",
      "未找到音频文件 Taikes - 世界函数~World Function~.mp3 对应于 song ID zeng.worldfunction 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.worldfunction.cytoidlevel\n",
      "未找到音频文件 Ponchi,打打だいず - 星河一天 (Ponchi♪Remix).ogg 对应于 song ID ztz.xhytrmx 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.xhytrmx.cytoidlevel\n",
      "未找到音频文件 デルタライズクローのテーマ-安濑圣.mp3 对应于 song ID ztz.delta 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.delta.cytoidlevel\n",
      "未找到音频文件 盟月.mp3 对应于 song ID zirei.ddd 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.ddd.cytoidlevel\n",
      "未找到音频文件 小野秀幸 - Prophesy One.ogg 对应于 song ID ztz.prophesy1 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.prophesy1.cytoidlevel\n",
      "未找到音频文件 stεganography.mp3 对应于 song ID zirei.steganography 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.steganography.cytoidlevel\n",
      "未找到 charts 文件 loveand - 副本.txt 对应于 song ID zeng.loveandj 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.loveandj.cytoidlevel\n",
      "未找到 charts 文件 emp - 副本.txt 对应于 song ID zeng.emp 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.emp.cytoidlevel\n",
      "未找到音频文件 清水達也 - IMAGE-MATERIAL-.mp3 对应于 song ID zeng.image 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.image.cytoidlevel\n",
      "总共跳过的曲子数量: 69\n",
      "跳过原因 'json_decode_error': 15 个曲子\n",
      "跳过原因 'missing_audio_file': 49 个曲子\n",
      "跳过原因 'missing_charts_file': 4 个曲子\n",
      "跳过原因 'read_error': 1 个曲子\n",
      "跳过原因 'missing_directory': 1 个曲子\n",
      "Filtered Data Count (Difficulty>=15): 217\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/artzumaru.asunoyozorashoukanhen.cytoidlevel/AsunoYozora.hard.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.miracleallextracoremix.cytoidlevel/ex.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.pandora06.cytoidlevel/ex.Tag.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.pandora01.cytoidlevel/exnewnew.Tag.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.calamityfortune.cytoidlevel/hard.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.intensesinging.cytoidlevel/intense.Tag.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence Train Size: 858862\n",
      "Presence Validation Size: 214716\n",
      "Presence Validation Size after split: 107358\n",
      "Presence Test Size: 107358\n",
      "Epoch 1/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3996\n",
      "Saved Best Presence Model\n",
      "Epoch 2/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3695\n",
      "Saved Best Presence Model\n",
      "Epoch 3/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3430\n",
      "Saved Best Presence Model\n",
      "Epoch 4/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Saved Best Presence Model\n",
      "Epoch 5/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3150\n",
      "Saved Best Presence Model\n",
      "Epoch 6/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3057\n",
      "Saved Best Presence Model\n",
      "Epoch 7/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2988\n",
      "Saved Best Presence Model\n",
      "Epoch 8/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2934\n",
      "Saved Best Presence Model\n",
      "Epoch 9/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2872\n",
      "Saved Best Presence Model\n",
      "Epoch 10/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2834\n",
      "Saved Best Presence Model\n",
      "Epoch 11/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2771\n",
      "Saved Best Presence Model\n",
      "Epoch 12/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2765\n",
      "Saved Best Presence Model\n",
      "Epoch 13/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2746\n",
      "Saved Best Presence Model\n",
      "Epoch 14/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2748\n",
      "Epoch 15/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2700\n",
      "Saved Best Presence Model\n",
      "Epoch 16/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2707\n",
      "Epoch 17/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2649\n",
      "Saved Best Presence Model\n",
      "Epoch 18/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2646\n",
      "Saved Best Presence Model\n",
      "Epoch 19/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2626\n",
      "Saved Best Presence Model\n",
      "Epoch 20/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2617\n",
      "Saved Best Presence Model\n",
      "Epoch 21/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2600\n",
      "Saved Best Presence Model\n",
      "Epoch 22/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2579\n",
      "Saved Best Presence Model\n",
      "Epoch 23/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2619\n",
      "Epoch 24/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2576\n",
      "Saved Best Presence Model\n",
      "Epoch 25/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2602\n",
      "Epoch 26/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2557\n",
      "Saved Best Presence Model\n",
      "Epoch 27/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2583\n",
      "Epoch 28/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2545\n",
      "Saved Best Presence Model\n",
      "Epoch 29/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2545\n",
      "Saved Best Presence Model\n",
      "Epoch 30/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2543\n",
      "Saved Best Presence Model\n",
      "Epoch 31/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2520\n",
      "Saved Best Presence Model\n",
      "Epoch 32/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2531\n",
      "Epoch 33/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2526\n",
      "Epoch 34/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2506\n",
      "Saved Best Presence Model\n",
      "Epoch 35/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2528\n",
      "Epoch 36/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2504\n",
      "Saved Best Presence Model\n",
      "Epoch 37/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2506\n",
      "Epoch 38/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2498\n",
      "Saved Best Presence Model\n",
      "Epoch 39/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2491\n",
      "Saved Best Presence Model\n",
      "Epoch 40/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2503\n",
      "Epoch 41/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2486\n",
      "Saved Best Presence Model\n",
      "Epoch 42/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2474\n",
      "Saved Best Presence Model\n",
      "Epoch 43/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2475\n",
      "Epoch 44/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2479\n",
      "Epoch 45/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2472\n",
      "Saved Best Presence Model\n",
      "Epoch 46/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2492\n",
      "Epoch 47/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2457\n",
      "Saved Best Presence Model\n",
      "Epoch 48/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2474\n",
      "Epoch 49/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2457\n",
      "Epoch 50/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205621/3220993348.py:1229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Train Size: 858862\n",
      "Type Validation Size: 214716\n",
      "Type Validation Size after split: 107358\n",
      "Type Test Size: 107358\n",
      "Epoch 1/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1162, Train Acc: 83.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1110, Validation Acc: 83.77%\n",
      "Saved Best Type Model\n",
      "Epoch 2/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1107, Train Acc: 83.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1060, Validation Acc: 83.95%\n",
      "Saved Best Type Model\n",
      "Epoch 3/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1071, Train Acc: 83.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1023, Validation Acc: 84.24%\n",
      "Saved Best Type Model\n",
      "Epoch 4/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1041, Train Acc: 84.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0988, Validation Acc: 84.75%\n",
      "Saved Best Type Model\n",
      "Epoch 5/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1021, Train Acc: 84.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0965, Validation Acc: 85.04%\n",
      "Saved Best Type Model\n",
      "Epoch 6/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1002, Train Acc: 84.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0944, Validation Acc: 85.43%\n",
      "Saved Best Type Model\n",
      "Epoch 7/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0987, Train Acc: 84.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0936, Validation Acc: 85.50%\n",
      "Saved Best Type Model\n",
      "Epoch 8/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0976, Train Acc: 85.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0915, Validation Acc: 85.89%\n",
      "Saved Best Type Model\n",
      "Epoch 9/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0966, Train Acc: 85.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0907, Validation Acc: 86.11%\n",
      "Saved Best Type Model\n",
      "Epoch 10/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0957, Train Acc: 85.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0899, Validation Acc: 86.11%\n",
      "Saved Best Type Model\n",
      "Epoch 11/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0947, Train Acc: 85.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0896, Validation Acc: 86.29%\n",
      "Saved Best Type Model\n",
      "Epoch 12/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0940, Train Acc: 85.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0880, Validation Acc: 86.39%\n",
      "Saved Best Type Model\n",
      "Epoch 13/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0934, Train Acc: 85.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0887, Validation Acc: 86.56%\n",
      "Epoch 14/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0930, Train Acc: 85.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0894, Validation Acc: 86.34%\n",
      "Epoch 15/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0925, Train Acc: 85.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0875, Validation Acc: 86.56%\n",
      "Saved Best Type Model\n",
      "Epoch 16/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0919, Train Acc: 85.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0867, Validation Acc: 86.64%\n",
      "Saved Best Type Model\n",
      "Epoch 17/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0916, Train Acc: 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0861, Validation Acc: 86.79%\n",
      "Saved Best Type Model\n",
      "Epoch 18/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0911, Train Acc: 86.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0856, Validation Acc: 86.66%\n",
      "Saved Best Type Model\n",
      "Epoch 19/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0907, Train Acc: 86.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0855, Validation Acc: 86.73%\n",
      "Saved Best Type Model\n",
      "Epoch 20/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0905, Train Acc: 86.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0858, Validation Acc: 86.91%\n",
      "Epoch 21/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0901, Train Acc: 86.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0850, Validation Acc: 86.90%\n",
      "Saved Best Type Model\n",
      "Epoch 22/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0900, Train Acc: 86.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0841, Validation Acc: 86.98%\n",
      "Saved Best Type Model\n",
      "Epoch 23/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0897, Train Acc: 86.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0848, Validation Acc: 86.78%\n",
      "Epoch 24/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0895, Train Acc: 86.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0846, Validation Acc: 86.98%\n",
      "Epoch 25/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0891, Train Acc: 86.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0838, Validation Acc: 86.91%\n",
      "Saved Best Type Model\n",
      "Epoch 26/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0892, Train Acc: 86.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0845, Validation Acc: 87.06%\n",
      "Epoch 27/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0889, Train Acc: 86.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0826, Validation Acc: 87.28%\n",
      "Saved Best Type Model\n",
      "Epoch 28/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0886, Train Acc: 86.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0834, Validation Acc: 87.16%\n",
      "Epoch 29/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 85.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 30/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 31/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 32/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 33/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 34/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 35/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 36/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 37/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 38/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 39/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 40/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 41/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 42/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 43/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 44/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 45/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 46/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 47/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 48/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 49/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 50/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205621/3220993348.py:1415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  type_model.load_state_dict(torch.load(best_type_model_path))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1426: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path, map_location=device))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1431: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  type_model.load_state_dict(torch.load(best_type_model_path, map_location=device))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1435: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNOnsetDetector(\n",
       "  (conv1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2560, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Integrated Pipeline Example with LSTM Model\n",
    "# This Notebook integrates the training and evaluation of Presence and Type models across two stages and adds a note position prediction model based on LSTM.\n",
    "# \n",
    "# Please ensure to create a `model` folder before running to save the model files.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Import Necessary Libraries\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # Move to the top\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import enum\n",
    "import tqdm\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Constants Definition\n",
    "\n",
    "# STFT constants\n",
    "SAMPLE_RATE = 22050  \n",
    "HOP_LENGTH = 512     \n",
    "NMELS = 128        \n",
    "WINDOW_SIZE = 40  # Number of frames before and after\n",
    "NUM_EPOCHS = 50    # Number of training epochs\n",
    "BATCH_SIZE = 64    # Batch size\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT = 0.5      # Dropout rate\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Preprocessing Functions\n",
    "\n",
    "def contains_non_ascii(s: str) -> bool:\n",
    "    \"\"\"Check if the string contains non-ASCII characters.\"\"\"\n",
    "    return any(ord(c) > 127 for c in s)\n",
    "\n",
    "def extract_level_json_multiple(directories: List[Path], min_difficulty: int = 15) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract level.json files from multiple directories, organize relevant information, and filter songs by specified difficulty.\n",
    "    If an unparseable name or other issue is encountered, skip the song.\n",
    "\n",
    "    Args:\n",
    "        directories (List[Path]): List of main directories containing multiple subfolders.\n",
    "        min_difficulty (int): Minimum difficulty level.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Contains relevant information for each level, limited to songs with difficulty >= min_difficulty.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    skipped_songs = 0\n",
    "    skipped_reasons = defaultdict(int)\n",
    "\n",
    "    for directory in directories:\n",
    "        if not directory.exists():\n",
    "            print(f\"Directory does not exist: {directory}\")\n",
    "            skipped_reasons['missing_directory'] += 1\n",
    "            continue\n",
    "        for folder_path in directory.iterdir():\n",
    "            if not folder_path.is_dir():\n",
    "                continue\n",
    "            json_file_path = folder_path / 'level.json'\n",
    "            if not json_file_path.is_file():\n",
    "                print(f\"Missing level.json file in {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_level_json'] += 1\n",
    "                continue\n",
    "            try:\n",
    "                with json_file_path.open('r', encoding='utf-8') as json_file:\n",
    "                    level_data = json.load(json_file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"JSON parse error: {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['json_decode_error'] += 1\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Unable to read {json_file_path}: {e}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['read_error'] += 1\n",
    "                continue\n",
    "\n",
    "            # Ensure all necessary fields exist\n",
    "            try:\n",
    "                level_id = level_data['id']\n",
    "                charts = level_data['charts']\n",
    "                music = level_data['music']\n",
    "            except KeyError as e:\n",
    "                print(f\"Missing key {e} in file: {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_keys'] += 1\n",
    "                continue\n",
    "\n",
    "            if not charts:\n",
    "                print(f\"No charts found in file {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['empty_charts'] += 1\n",
    "                continue\n",
    "\n",
    "            chart_difficulty = charts[0].get('difficulty', 0)\n",
    "            if chart_difficulty < min_difficulty:\n",
    "                continue\n",
    "\n",
    "            audio_file_name = music.get('path', '')\n",
    "            if not audio_file_name:\n",
    "                print(f\"No music path specified in file {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_music_path'] += 1\n",
    "                continue\n",
    "\n",
    "            audio_file_extensions = ['.mp3', '.ogg', '.wav']\n",
    "            audio_file_path = None\n",
    "            for ext in audio_file_extensions:\n",
    "                aud_path = folder_path / audio_file_name\n",
    "                if aud_path.suffix.lower() == ext and aud_path.is_file():\n",
    "                    audio_file_path = aud_path\n",
    "                    break\n",
    "            if audio_file_path is None:\n",
    "                print(f\"Audio file {audio_file_name} for song ID {level_id} not found in {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_audio_file'] += 1\n",
    "                continue\n",
    "\n",
    "            charts_path = folder_path / charts[0].get('path', '')\n",
    "            if not charts_path.is_file():\n",
    "                print(f\"Charts file {charts[0].get('path', '')} for song ID {level_id} not found in {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_charts_file'] += 1\n",
    "                continue\n",
    "\n",
    "            # Create unique ID, ensure name is parseable\n",
    "            unique_id = f\"{directory.name}_{level_id}\"\n",
    "            try:\n",
    "                unique_id.encode('ascii')  # Check if ASCII\n",
    "            except UnicodeEncodeError:\n",
    "                print(f\"Unparseable unique_id: {unique_id}, skipping song\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['unparseable_unique_id'] += 1\n",
    "                continue\n",
    "\n",
    "            # Add to result\n",
    "            result[unique_id] = {\n",
    "                'level': level_data,\n",
    "                'mp3_path': str(audio_file_path),\n",
    "                'charts_path': str(charts_path),\n",
    "                'charter': level_data.get('charter', ''),\n",
    "                'type': charts[0].get('type', ''),\n",
    "                'difficulty': chart_difficulty\n",
    "            }\n",
    "\n",
    "    print(f\"Total number of skipped songs: {skipped_songs}\")\n",
    "    for reason, count in skipped_reasons.items():\n",
    "        print(f\"Skipped reason '{reason}': {count} songs\")\n",
    "    return result\n",
    "\n",
    "def extract_charts(path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract chart data from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the chart JSON file.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Chart data.\n",
    "    \"\"\"\n",
    "    file_path = Path(path)\n",
    "    if file_path.exists() and file_path.is_file():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return data\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"JSON decode error for file: {path}\")\n",
    "    return {}\n",
    "\n",
    "def find_single_tempo_songs(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Filter songs with constant BPM.\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): Dictionary containing all song information.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: List of songs with constant BPM.\n",
    "    \"\"\"\n",
    "    single_tempo_songs = []\n",
    "    for song_id, song in data.items():\n",
    "        charts_data = extract_charts(song['charts_path'])\n",
    "        if charts_data and 'tempo_list' in charts_data:\n",
    "            if len(charts_data['tempo_list']) == 1:\n",
    "                single_tempo_songs.append(song)\n",
    "    return single_tempo_songs\n",
    "\n",
    "def map_note_to_time(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Map notes to time.\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): Chart data.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: Time mapping information for each note.\n",
    "    \"\"\"\n",
    "    time_base = data.get('time_base', 1000) \n",
    "    offset_universal = 0.033 \n",
    "    offset = data.get('music_offset', 0) - offset_universal\n",
    "    tempo_list = sorted(data.get('tempo_list', []), key=lambda x: x['tick'])  \n",
    "    note_list = data.get('note_list', [])\n",
    "    \n",
    "    note_time_map = []\n",
    "    accumulated_time = 0 \n",
    "    last_tick = 0  \n",
    "    if not tempo_list:\n",
    "        return note_time_map\n",
    "    current_tempo = tempo_list[0]['value']  \n",
    "    tempo_index = 0  \n",
    "\n",
    "    for note in note_list:\n",
    "        note_tick = note['tick']\n",
    "        while tempo_index < len(tempo_list) - 1 and tempo_list[tempo_index + 1]['tick'] <= note_tick:\n",
    "            next_tempo_tick = tempo_list[tempo_index + 1]['tick']\n",
    "            ticks_in_interval = next_tempo_tick - last_tick\n",
    "            tick_duration = (current_tempo / time_base) \n",
    "            accumulated_time += ticks_in_interval * tick_duration\n",
    "            last_tick = next_tempo_tick\n",
    "            tempo_index += 1\n",
    "            current_tempo = tempo_list[tempo_index]['value']\n",
    "\n",
    "        ticks_in_interval = note_tick - last_tick\n",
    "        tick_duration = (current_tempo / time_base) \n",
    "        note_time = accumulated_time + ticks_in_interval * tick_duration\n",
    "        note_time_map.append({\n",
    "            'note_id': note.get('id', 0),\n",
    "            'note_tick': note_tick,\n",
    "            'note_time_microseconds': note_time - offset * 1_000_000,\n",
    "            'note_type': note.get('type', 0),\n",
    "            'note_x': note.get('x', 0.0)\n",
    "        })\n",
    "\n",
    "    return note_time_map\n",
    "\n",
    "def generate_mel_spectrogram(\n",
    "    audio_path: Path,\n",
    "    log_enable: bool = True,\n",
    "    bpm_info: List[Dict[str, float]] = None,\n",
    "    note_info: List[Dict[str, Any]] = None,\n",
    "    max_frames: int = 5000  # New parameter to limit maximum frames\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Generate Mel spectrogram and corresponding labels, limiting its length to a maximum of max_frames.\n",
    "    \n",
    "    Args:\n",
    "        audio_path (Path): Path to the audio file.\n",
    "        log_enable (bool): Whether to apply logarithmic transformation.\n",
    "        bpm_info (List[Dict[str, float]]): BPM information.\n",
    "        note_info (List[Dict[str, Any]]): Note information.\n",
    "        max_frames (int): Maximum number of frames.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing Mel spectrogram, presence labels, and position_labels.\n",
    "    \"\"\"\n",
    "    data, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE)\n",
    "    assert sr == SAMPLE_RATE, f\"Expected sample rate {SAMPLE_RATE}, but got {sr}\"\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=data,\n",
    "        sr=sr, \n",
    "        hop_length=HOP_LENGTH, \n",
    "        fmin=30.0, \n",
    "        n_mels=NMELS, \n",
    "        htk=True\n",
    "    )\n",
    "    if log_enable:\n",
    "        mel = np.log(np.clip(mel, 1e-5, None))\n",
    "    mel = mel.T  # (Time steps, Features)\n",
    "\n",
    "    # Limit the length of the Mel spectrogram\n",
    "    if mel.shape[0] > max_frames:\n",
    "        mel = mel[:max_frames]\n",
    "\n",
    "    data_dic = {\"mel\": mel}\n",
    "\n",
    "    # Initialize presence labels and position_labels\n",
    "    presence_labels = np.zeros(mel.shape[0], dtype=int)  # Presence labels\n",
    "    position_labels = -1 * np.ones(mel.shape[0], dtype=int)  # -1 indicates no note\n",
    "\n",
    "    if bpm_info and note_info:\n",
    "        mel_length = mel.shape[0]\n",
    "        for note in note_info:\n",
    "            time_sec = note['note_time_microseconds'] / 1_000_000\n",
    "            frame_idx = int(time_sec * SAMPLE_RATE / HOP_LENGTH)\n",
    "            if 0 <= frame_idx < mel_length:  # Ensure frame_idx is non-negative and within range\n",
    "                presence_labels[frame_idx] = 1  # Presence\n",
    "                # Calculate relative position to window center (assuming window size of 40)\n",
    "                position = frame_idx  # Adjust based on specific requirements\n",
    "                position_labels[frame_idx] = position\n",
    "\n",
    "    data_dic[\"labels\"] = presence_labels  # shape: (mel_length,)\n",
    "    data_dic[\"position_labels\"] = position_labels  # shape: (mel_length,)\n",
    "\n",
    "    return data_dic\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Dataset and DataLoader\n",
    "\n",
    "class TimeUnit(enum.Enum):\n",
    "    milliseconds = \"milliseconds\"\n",
    "    frames = \"frames\"\n",
    "    seconds = \"seconds\"\n",
    "\n",
    "class OnsetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for loading and providing data.\n",
    "    Each sample includes the current frame and 40 frames before and after (total 81 frames).\n",
    "    \"\"\"\n",
    "    def __init__(self, data: Dict[str, Any], bpm_info: Dict[str, List[Dict[str, float]]], score_positions: Dict[str, List[Dict[str, Any]]], window_size: int = 40, transform=None):\n",
    "        self.data = data\n",
    "        self.bpm_info = bpm_info\n",
    "        self.score_positions = score_positions\n",
    "        self.transform = transform\n",
    "        self.window_size = window_size\n",
    "        self.samples = self.prepare_samples()\n",
    "        \n",
    "    def prepare_samples(self) -> List[Tuple[np.ndarray, np.ndarray, int]]:\n",
    "        \"\"\"\n",
    "        Prepare data samples, each containing 81 frames of Mel spectrogram and corresponding labels.\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for song_id, song in self.data.items():\n",
    "            mp3_path = song[\"mp3_path\"]\n",
    "            charts_path = song[\"charts_path\"]\n",
    "            difficulty = song['difficulty']\n",
    "            \n",
    "            mel_dict = generate_mel_spectrogram(\n",
    "                audio_path=Path(mp3_path),\n",
    "                log_enable=True,\n",
    "                bpm_info=self.bpm_info.get(song_id, None),\n",
    "                note_info=self.score_positions.get(song_id, None)\n",
    "            )\n",
    "            if \"labels\" in mel_dict:\n",
    "                mel = mel_dict[\"mel\"]  # shape: (num_frames, n_mels)\n",
    "                labels = mel_dict[\"labels\"]  # shape: (num_frames,)\n",
    "\n",
    "                num_frames = mel.shape[0]\n",
    "                for i in range(num_frames):\n",
    "                    start = max(i - self.window_size, 0)\n",
    "                    end = min(i + self.window_size + 1, num_frames)\n",
    "                    \n",
    "                    # Pad insufficient frames\n",
    "                    pad_before = self.window_size - i if i < self.window_size else 0\n",
    "                    pad_after = (i + self.window_size + 1) - num_frames if (i + self.window_size + 1) > num_frames else 0\n",
    "                    \n",
    "                    mel_window = mel[start:end]\n",
    "                    if pad_before > 0:\n",
    "                        mel_window = np.pad(mel_window, ((pad_before, 0), (0, 0)), mode='constant')\n",
    "                    if pad_after > 0:\n",
    "                        mel_window = np.pad(mel_window, ((0, pad_after), (0, 0)), mode='constant')\n",
    "                    \n",
    "                    label = labels[i]\n",
    "                    \n",
    "                    samples.append((mel_window, label, difficulty))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        mel_window, label, difficulty = self.samples[idx]\n",
    "        mel_window = torch.from_numpy(mel_window).float()  # shape: (81, n_mels)\n",
    "        label = torch.tensor(label).float()  # shape: ()\n",
    "        \n",
    "        if self.transform:\n",
    "            mel_window, label = self.transform(mel_window, label)\n",
    "\n",
    "        return mel_window, label, difficulty\n",
    "\n",
    "def collate_fn_padded(batch: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    Custom collate_fn for handling batch data.\n",
    "    \"\"\"\n",
    "    mel, labels, difficulties = zip(*batch)\n",
    "    \n",
    "    mel = torch.stack(mel, dim=0)  # (batch_size, 81, n_mels)\n",
    "    labels = torch.stack(labels, dim=0)  # (batch_size,)\n",
    "\n",
    "    return mel, labels, difficulties\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Presence Model Definition (Keeping Code Nearly Unchanged)\n",
    "\n",
    "class CNNOnsetDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network (CNN) based Onset Detection Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, num_classes: int = 1, dropout: float = 0.5):\n",
    "        super(CNNOnsetDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # Calculate pooled feature length\n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)  # Prevent feature length from being 0\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)  # Assuming three pooling layers\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 81, n_mels]\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # Convert to [batch_size, n_mels, 81]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 64, 40]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 128, 20]\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 256, 10]\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 2560]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CNNOnsetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels: int, dropout: float = 0.5):\n",
    "        super(CNNOnsetFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 81, n_mels)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, n_mels, 81)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 64, 40)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 128, 20)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 256, 10)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # (batch_size, 2560)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # (batch_size, 512)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Do not perform fc2, directly return 512-dimensional features\n",
    "        return x\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Type Model Definition (Modified to CNN)\n",
    "\n",
    "class CNNTypePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network (CNN) based Type Prediction Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, num_types: int = 5, dropout: float = 0.5):\n",
    "        super(CNNTypePredictor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # Calculate pooled feature length\n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)  # Prevent feature length from being 0\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)  # Assuming three pooling layers\n",
    "        self.fc_type = nn.Linear(512, num_types)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 81, n_mels]\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # Convert to [batch_size, n_mels, 81]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 64, 40]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 128, 20]\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 256, 10]\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 2560]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        type_out = self.fc_type(x)  # [batch_size, num_types]\n",
    "        \n",
    "        return type_out\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Visualization Functions\n",
    "\n",
    "def visualize_presence_predictions(mel: np.ndarray, labels: np.ndarray, preds: np.ndarray, start_time: float = 0, end_time: float = 5):\n",
    "    \"\"\"\n",
    "    Visualize the model's presence prediction results and true labels.\n",
    "\n",
    "    Args:\n",
    "        mel (np.ndarray): Mel spectrogram, shape (seq_len, feature_dim)\n",
    "        labels (np.ndarray): True labels, shape (seq_len,)\n",
    "        preds (np.ndarray): Model's presence scores, shape (seq_len,)\n",
    "        start_time (float): Start time for visualization (seconds)\n",
    "        end_time (float): End time for visualization (seconds)\n",
    "    \"\"\"\n",
    "    # Apply Sigmoid activation\n",
    "    presence_pred = 1 / (1 + np.exp(-preds))\n",
    "    \n",
    "    # Apply threshold of 0.5\n",
    "    presence_final = (presence_pred >= 0.5).astype(int)\n",
    "\n",
    "    # Calculate time axis\n",
    "    total_time = mel.shape[0] * HOP_LENGTH / SAMPLE_RATE\n",
    "    times = np.linspace(0, total_time, num=mel.shape[0])\n",
    "\n",
    "    # Determine frame range for visualization\n",
    "    start_frame = int(start_time * SAMPLE_RATE / HOP_LENGTH)\n",
    "    end_frame = int(end_time * SAMPLE_RATE / HOP_LENGTH)\n",
    "\n",
    "    # Ensure end_frame does not exceed sequence length\n",
    "    end_frame = min(end_frame, mel.shape[0])\n",
    "\n",
    "    # Crop data\n",
    "    mel_cropped = mel[start_frame:end_frame]\n",
    "    labels_cropped = labels[start_frame:end_frame]\n",
    "    presence_pred_cropped = presence_pred[start_frame:end_frame]\n",
    "    presence_final_cropped = presence_final[start_frame:end_frame]\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    # Plot Mel spectrogram\n",
    "    img = librosa.display.specshow(\n",
    "        mel_cropped.T,\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        x_coords=times[start_frame:end_frame],\n",
    "        ax=axs[0],\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        fmax=8000\n",
    "    )\n",
    "    axs[0].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img, ax=axs[0], format='%+2.0f dB')\n",
    "\n",
    "    # Plot Presence predictions and true labels\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        presence_pred_cropped.flatten(),\n",
    "        label='Presence Prediction (Raw)',\n",
    "        color='red',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        presence_final_cropped,\n",
    "        label='Presence Prediction (Threshold=0.50)',\n",
    "        color='orange',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        labels_cropped.flatten(),\n",
    "        label='Presence Ground Truth',\n",
    "        color='blue',\n",
    "        linestyle='dashed'\n",
    "    )\n",
    "\n",
    "    axs[1].set_title('Presence Predictions vs Ground Truth (Threshold: 0.50)')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].set_xlabel('Time (s)')\n",
    "    axs[1].set_ylabel('Presence')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_presence_predictions_single(mel: np.ndarray, label: np.ndarray, pred: np.ndarray, start_time: float = 0, end_time: float = 5):\n",
    "    \"\"\"\n",
    "    Visualize the presence prediction results and true label for a single sample.\n",
    "    \n",
    "    Args:\n",
    "        mel (np.ndarray): Mel spectrogram, shape (81, n_mels)\n",
    "        label (np.ndarray): True label, shape (1,)\n",
    "        pred (np.ndarray): Model's presence score, shape (1,)\n",
    "        start_time (float): Start time for visualization (seconds)\n",
    "        end_time (float): End time for visualization (seconds)\n",
    "    \"\"\"\n",
    "    # Apply Sigmoid activation\n",
    "    presence_pred = 1 / (1 + np.exp(-pred))\n",
    "    \n",
    "    # Apply threshold of 0.5\n",
    "    presence_final = (presence_pred >= 0.5).astype(int)\n",
    "    \n",
    "    # Calculate time axis (assuming window center frame corresponds to current time)\n",
    "    total_time = WINDOW_SIZE * 2 * HOP_LENGTH / SAMPLE_RATE  # Total time for before and after frames\n",
    "    times = np.linspace(-WINDOW_SIZE * HOP_LENGTH / SAMPLE_RATE, WINDOW_SIZE * HOP_LENGTH / SAMPLE_RATE, num=mel.shape[0])\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # Plot Mel spectrogram\n",
    "    img = librosa.display.specshow(\n",
    "        mel.T,\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        x_coords=times,\n",
    "        ax=axs[0],\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        fmax=8000\n",
    "    )\n",
    "    axs[0].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img, ax=axs[0], format='%+2.0f dB')\n",
    "    \n",
    "    # Plot Presence predictions and true label\n",
    "    axs[1].bar(0, presence_pred, label='Presence Prediction (Raw)', color='red', alpha=0.6)\n",
    "    axs[1].bar(0, presence_final, label='Presence Prediction (Threshold=0.50)', color='orange', alpha=0.6)\n",
    "    axs[1].bar(0, label, label='Presence Ground Truth', color='blue', alpha=0.6)\n",
    "    \n",
    "    axs[1].set_title('Presence Predictions vs Ground Truth')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].set_xlabel('Current Frame')\n",
    "    axs[1].set_ylabel('Presence')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_type_predictions(mel: np.ndarray, labels: np.ndarray, preds: np.ndarray, start_time: float = 0, end_time: float = 5, hop_length: int = HOP_LENGTH, sample_rate: int = SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Visualize the model's type prediction results and true labels.\n",
    "\n",
    "    Args:\n",
    "        mel (np.ndarray): Mel spectrogram, shape (seq_len, feature_dim)\n",
    "        labels (np.ndarray): True labels, shape (seq_len,)\n",
    "        preds (np.ndarray): Model's type scores, shape (seq_len, num_types)\n",
    "        start_time (float): Start time for visualization (seconds)\n",
    "        end_time (float): End time for visualization (seconds)\n",
    "        hop_length (int): hop_length parameter\n",
    "        sample_rate (int): Sample rate\n",
    "    \"\"\"\n",
    "    # Apply Softmax activation\n",
    "    preds_prob = F.softmax(torch.tensor(preds), dim=-1).numpy()\n",
    "\n",
    "    # Calculate time axis\n",
    "    total_time = mel.shape[0] * hop_length / sample_rate\n",
    "    times = np.linspace(0, total_time, num=mel.shape[0])\n",
    "\n",
    "    # Determine frame range for visualization\n",
    "    start_frame = int(start_time * sample_rate / hop_length)\n",
    "    end_frame = int(end_time * sample_rate / hop_length)\n",
    "\n",
    "    # Crop data\n",
    "    labels_cropped = labels[start_frame:end_frame]\n",
    "    preds_cropped = preds_prob[start_frame:end_frame]\n",
    "    times_cropped = times[start_frame:end_frame]\n",
    "\n",
    "    # Define color mapping (using matplotlib's tab10 color set)\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    num_types = preds_cropped.shape[1]\n",
    "    colors = [cmap(i) for i in range(num_types)]\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    # Plot type probabilities\n",
    "    for type_idx in range(num_types):\n",
    "        plt.plot(\n",
    "            times_cropped,\n",
    "            preds_cropped[:, type_idx],\n",
    "            label=f'Type {type_idx}',\n",
    "            color=colors[type_idx],\n",
    "            alpha=0.6\n",
    "        )\n",
    "\n",
    "    # Plot true labels\n",
    "    for idx, label in enumerate(labels_cropped):\n",
    "        if label == 0:\n",
    "            continue  # Skip type 0 (assumed to be no event)\n",
    "        plt.scatter(\n",
    "            times_cropped[idx],\n",
    "            preds_cropped[idx, label],\n",
    "            color=colors[label],\n",
    "            marker='x',\n",
    "            s=50,\n",
    "            label=f'Ground Truth Type {label}' if idx == 0 else \"\",  # Add to legend only once\n",
    "            zorder=5\n",
    "        )\n",
    "        # Plot vertical lines\n",
    "        plt.axvline(\n",
    "            x=times_cropped[idx],\n",
    "            color=colors[label],\n",
    "            linestyle='--',\n",
    "            alpha=0.5,\n",
    "            linewidth=1\n",
    "        )\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title('Type Probabilities and Ground Truth', fontsize=14)\n",
    "    plt.xlabel('Time (s)', fontsize=12)\n",
    "    plt.ylabel('Probability', fontsize=12)\n",
    "\n",
    "    # Set legend, avoid duplicates\n",
    "    handles, labels_legend = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels_legend, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize='small')\n",
    "\n",
    "    # Set x-axis range\n",
    "    plt.xlim(start_time, end_time)\n",
    "\n",
    "    # Only show y-axis label on the right\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_label_coords(1.05, 0.5)\n",
    "\n",
    "    # Display plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_position_predictions(true_positions: List[int], pred_positions: List[int], num_samples: int = 100):\n",
    "    \"\"\"\n",
    "    Visualize the comparison between true positions and predicted positions.\n",
    "    \n",
    "    Args:\n",
    "        true_positions (List[int]): List of true positions.\n",
    "        pred_positions (List[int]): List of predicted positions.\n",
    "        num_samples (int): Number of samples to visualize.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    if len(true_positions) < num_samples:\n",
    "        num_samples = len(true_positions)\n",
    "    indices = np.random.choice(len(true_positions), size=num_samples, replace=False)\n",
    "    true = np.array(true_positions)[indices]\n",
    "    pred = np.array(pred_positions)[indices]\n",
    "    \n",
    "    plt.scatter(range(num_samples), true, label='True Position', alpha=0.6, color='blue')\n",
    "    plt.scatter(range(num_samples), pred, label='Predicted Position', alpha=0.6, color='red')\n",
    "    plt.title('True vs Predicted Note Positions')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Position Index')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_position_distribution(true_positions: List[int], pred_positions: List[int]):\n",
    "    \"\"\"\n",
    "    Visualize the distribution of true positions and predicted positions.\n",
    "    \n",
    "    Args:\n",
    "        true_positions (List[int]): List of true positions.\n",
    "        pred_positions (List[int]): List of predicted positions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(true_positions, bins=81, alpha=0.5, label='True Positions', color='blue', density=True)\n",
    "    plt.hist(pred_positions, bins=81, alpha=0.5, label='Predicted Positions', color='red', density=True)\n",
    "    plt.title('Distribution of True and Predicted Positions')\n",
    "    plt.xlabel('Position Index')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training and Validation Functions\n",
    "\n",
    "# Presence Model Training Function\n",
    "def train_epoch_cnn(model: nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device, loss_fn: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    Train for one epoch (CNN version).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Presence\", leave=False)\n",
    "\n",
    "    for mel, labels, difficulties in progress_bar:\n",
    "        mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "        labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(mel)  # (batch_size, 1)\n",
    "        outputs = outputs.squeeze(1)  # (batch_size)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "# Presence Model Validation Function\n",
    "def validate_epoch_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module) -> Tuple[float, Dict[int, Dict[str, List[Any]]]]:\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    difficulty_preds = defaultdict(lambda: {'y_true': [], 'y_scores': []})\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validation Presence\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, difficulties in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(mel)  # (batch_size, 1)\n",
    "            outputs = outputs.squeeze(1)  # (batch_size)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            # Collect prediction scores and true labels, grouped by difficulty level\n",
    "            presence_pred_np = outputs.cpu().numpy()\n",
    "            presence_target_np = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(mel.size(0)):\n",
    "                difficulty = difficulties[i]\n",
    "                y_true = presence_target_np[i]\n",
    "                y_score = presence_pred_np[i]\n",
    "                difficulty_preds[difficulty]['y_true'].append(y_true)\n",
    "                difficulty_preds[difficulty]['y_scores'].append(y_score)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss, difficulty_preds\n",
    "\n",
    "# Type Model Training Function (CNN version)\n",
    "def train_epoch_cnn_type(model: nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device, loss_fn: nn.Module, num_types: int) -> float:\n",
    "    \"\"\"\n",
    "    Train for one epoch (Type CNN version).\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Type CNN\", leave=False)\n",
    "\n",
    "    for mel, labels, lengths in progress_bar:\n",
    "        mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "        labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(type_pred, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1)\n",
    "        acc = (preds == labels).float().mean().item()\n",
    "        running_acc += acc\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Acc': f'{acc*100:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Type Model Validation Function (CNN version)\n",
    "def validate_epoch_cnn_type(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module, num_types: int) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set (CNN version).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validation Type CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, lengths in progress_bar:\n",
    "            mel = mel.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(type_pred, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1)\n",
    "            acc = (preds == labels).float().mean().item()\n",
    "            running_acc += acc\n",
    "\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Acc': f'{acc*100:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Model Evaluation Functions\n",
    "\n",
    "def evaluate_test_set_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module):\n",
    "    \"\"\"\n",
    "    Evaluate the CNN model on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    difficulty_metrics = defaultdict(lambda: {'y_true': [], 'y_pred': []})\n",
    "    all_preds, all_labels = [], []\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Testing Presence CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, difficulties in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(mel)  # (batch_size, 1)\n",
    "            outputs = outputs.squeeze(1)  # (batch_size)\n",
    "            # Remove the following line as labels are already shape (batch_size,)\n",
    "            # labels = labels.squeeze(1)  # (batch_size)\n",
    "\n",
    "            # Compute loss (optional)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Collect predictions and labels\n",
    "            presence_pred_np = outputs.cpu().numpy()\n",
    "            presence_target_np = labels.cpu().numpy()\n",
    "\n",
    "            # Apply Sigmoid activation\n",
    "            presence_pred_sigmoid = 1 / (1 + np.exp(-presence_pred_np))\n",
    "\n",
    "            # Use threshold 0.5 for prediction\n",
    "            y_pred = (presence_pred_sigmoid >= 0.5).astype(int)\n",
    "            y_true = presence_target_np.astype(int)\n",
    "\n",
    "            # Collect all predictions and labels for distribution\n",
    "            all_preds.extend(presence_pred_sigmoid.tolist())\n",
    "            all_labels.extend(presence_target_np.tolist())\n",
    "\n",
    "            # Group by difficulty level\n",
    "            for i in range(mel.size(0)):\n",
    "                difficulty = difficulties[i]\n",
    "                difficulty_metrics[difficulty]['y_true'].append(y_true[i])\n",
    "                difficulty_metrics[difficulty]['y_pred'].append(y_pred[i])\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Plot distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(all_preds, bins=50, alpha=0.7, label=\"Predictions\", color=\"blue\", density=True)\n",
    "    plt.hist(all_labels, bins=50, alpha=0.7, label=\"Ground Truth\", color=\"orange\", density=True)\n",
    "    plt.title(\"Frame-wise Prediction and Ground Truth Distribution\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate metrics for each difficulty level\n",
    "    final_metrics = {}\n",
    "    for diff, metrics in difficulty_metrics.items():\n",
    "        y_true = np.array(metrics['y_true'])\n",
    "        y_pred = np.array(metrics['y_pred'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        final_metrics[diff] = {\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        print(f\"Difficulty {diff}: Accuracy={acc:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1 Score={f1:.4f}\")\n",
    "\n",
    "    return final_metrics\n",
    "\n",
    "def evaluate_test_set_type_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module, num_types: int):\n",
    "    \"\"\"\n",
    "    Evaluate the Type CNN model on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Testing Type CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, lengths in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # Forward pass\n",
    "            type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(type_pred, labels)\n",
    "\n",
    "            # Collect predictions and labels\n",
    "            preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1).cpu().numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(true.tolist())\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Type Prediction - Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1_score': f1}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Data Preparation\n",
    "\n",
    "current_directory = Path().cwd()\n",
    "dataset_dirs = [\n",
    "    current_directory / \"../dataset/A\",\n",
    "    current_directory / \"../dataset/B\",\n",
    "    current_directory / \"../dataset/C\",\n",
    "    current_directory / \"../dataset/Z\"\n",
    "]\n",
    "data = extract_level_json_multiple(dataset_dirs, min_difficulty=15)\n",
    "print(f\"Filtered Data Count (Difficulty>=15): {len(data)}\")\n",
    "# data = dict(list(data.items())[:30])\n",
    "bpm_info_dict = {}\n",
    "score_positions_dict = {}\n",
    "\n",
    "for unique_id, song in data.items():\n",
    "    level_data = song['level']\n",
    "    song_id = unique_id  # Use unique ID\n",
    "    charts_data = extract_charts(song['charts_path'])\n",
    "    if charts_data:\n",
    "        bpm_info = charts_data.get('tempo_list', [])\n",
    "        bpm_info_dict[song_id] = bpm_info\n",
    "        note_time_map = map_note_to_time(charts_data) \n",
    "        # Detailed information for each note, including time, type, and position\n",
    "        score_positions = [] \n",
    "        for note in note_time_map:\n",
    "            score_positions.append({\n",
    "                'note_time_microseconds': note['note_time_microseconds'],\n",
    "                'note_type': note.get('note_type', 0),  # Ensure this field exists\n",
    "                'note_x': note.get('note_x', 0.0)      # Ensure this field exists\n",
    "            })\n",
    "        score_positions_dict[song_id] = score_positions\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Define Dataset and DataLoader\n",
    "\n",
    "# Define Presence dataset and DataLoader\n",
    "presence_dataset = OnsetDataset(\n",
    "    data=data, \n",
    "    bpm_info=bpm_info_dict, \n",
    "    score_positions=score_positions_dict,\n",
    "    window_size=WINDOW_SIZE  # 40 frames before and after\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(presence_dataset))\n",
    "val_size = len(presence_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(presence_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Presence Train Size: {len(train_dataset)}\")\n",
    "print(f\"Presence Validation Size: {len(val_dataset)}\")\n",
    "# Below is the training code ---------------------------------------------------------------------------------------------------\n",
    "# Create test set (using part of the validation set as test set)\n",
    "test_size = int(0.5 * len(val_dataset))\n",
    "val_size = len(val_dataset) - test_size\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "print(f\"Presence Validation Size after split: {len(val_dataset)}\")\n",
    "print(f\"Presence Test Size: {len(test_dataset)}\")\n",
    "\n",
    "presence_train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate_fn_padded)\n",
    "presence_val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded)\n",
    "presence_test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Presence Model Training and Evaluation\n",
    "\n",
    "# Initialize Presence model\n",
    "presence_model = CNNOnsetDetector(input_channels=NMELS, num_classes=1, dropout=DROPOUT)\n",
    "presence_model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "presence_optimizer = torch.optim.Adam(presence_model.parameters(), lr=LEARNING_RATE)\n",
    "presence_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train the best Presence model\n",
    "best_presence_val_loss = float('inf')\n",
    "best_presence_model_path = \"model/best_cnn_onset_model.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Training Presence Model\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_epoch_cnn(presence_model, presence_train_loader, presence_optimizer, device, presence_loss_fn)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_difficulty_preds = validate_epoch_cnn(presence_model, presence_val_loader, device, presence_loss_fn)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save the model if validation loss is lower\n",
    "    if val_loss < best_presence_val_loss:\n",
    "        best_presence_val_loss = val_loss\n",
    "        torch.save(presence_model.state_dict(), best_presence_model_path)\n",
    "        print(\"Saved Best Presence Model\")\n",
    "\n",
    "# Load the best Presence model\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()\n",
    "# Below is the training code ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Define Type Dataset and DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=2.0, gamma=2, reduction='mean'):\n",
    "        \"\"\"\n",
    "        alpha: Class balancing factor, can be used to give more weight to minority classes in imbalanced datasets\n",
    "        gamma: Modulation parameter, the larger gamma is, the more focus on hard-to-classify samples\n",
    "        reduction: Loss aggregation method, 'mean' or 'sum'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: [batch_size, num_classes]\n",
    "        # targets: [batch_size]\n",
    "\n",
    "        # Get predicted probability distribution\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        # Extract the predicted probability for the true class\n",
    "        pt = probs[range(len(targets)), targets]\n",
    "\n",
    "        # Focal loss formula\n",
    "        loss = -self.alpha * (1 - pt)**self.gamma * torch.log(pt)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# %% \n",
    "class TypeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset class for loading and providing data.\n",
    "    Each sample includes the current frame and 40 frames before and after (total 81 frames).\n",
    "    \"\"\"\n",
    "    def __init__(self, data: Dict[str, Any], bpm_info: Dict[str, List[Dict[str, float]]], score_positions: Dict[str, List[Dict[str, Any]]], window_size: int = 40, transform=None):\n",
    "        self.data = data\n",
    "        self.bpm_info = bpm_info\n",
    "        self.score_positions = score_positions\n",
    "        self.transform = transform\n",
    "        self.window_size = window_size\n",
    "        self.samples = self.prepare_samples()\n",
    "        \n",
    "    def prepare_samples(self) -> List[Tuple[np.ndarray, int, int]]:\n",
    "        \"\"\"\n",
    "        Prepare data samples, each containing 81 frames of Mel spectrogram and corresponding type labels.\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for song_id, song in self.data.items():\n",
    "            mp3_path = song[\"mp3_path\"]\n",
    "            charts_path = song[\"charts_path\"]\n",
    "            difficulty = song['difficulty']\n",
    "            \n",
    "            mel_dict = generate_mel_spectrogram(\n",
    "                audio_path=Path(mp3_path),\n",
    "                log_enable=True,\n",
    "                bpm_info=self.bpm_info.get(song_id, None),\n",
    "                note_info=self.score_positions.get(song_id, None)\n",
    "            )\n",
    "            if \"labels\" in mel_dict:\n",
    "                mel = mel_dict[\"mel\"]  # shape: (num_frames, n_mels)\n",
    "                labels = mel_dict[\"labels\"]  # shape: (num_frames,)\n",
    "\n",
    "                num_frames = mel.shape[0]\n",
    "                for i in range(num_frames):\n",
    "                    start = max(i - self.window_size, 0)\n",
    "                    end = min(i + self.window_size + 1, num_frames)\n",
    "                    \n",
    "                    # Pad insufficient frames\n",
    "                    pad_before = self.window_size - i if i < self.window_size else 0\n",
    "                    pad_after = (i + self.window_size + 1) - num_frames if (i + self.window_size + 1) > num_frames else 0\n",
    "                    \n",
    "                    mel_window = mel[start:end]\n",
    "                    if pad_before > 0:\n",
    "                        mel_window = np.pad(mel_window, ((pad_before, 0), (0, 0)), mode='constant')\n",
    "                    if pad_after > 0:\n",
    "                        mel_window = np.pad(mel_window, ((0, pad_after), (0, 0)), mode='constant')\n",
    "                    \n",
    "                    label = labels[i]\n",
    "                    \n",
    "                    samples.append((mel_window, label, difficulty))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        mel_window, label, difficulty = self.samples[idx]\n",
    "        mel_window = torch.from_numpy(mel_window).float()  # shape: (81, n_mels)\n",
    "        label = torch.tensor(label).long()  # shape: ()\n",
    "        \n",
    "        if self.transform:\n",
    "            mel_window, label = self.transform(mel_window, label)\n",
    "\n",
    "        return mel_window, label, difficulty\n",
    "\n",
    "def collate_fn_padded_type(batch: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    Custom collate_fn for handling batch data.\n",
    "    \"\"\"\n",
    "    mel, labels, difficulties = zip(*batch)\n",
    "    \n",
    "    mel = torch.stack(mel, dim=0)  # (batch_size, 81, n_mels)\n",
    "    labels = torch.stack(labels, dim=0)  # (batch_size,)\n",
    "\n",
    "    return mel, labels, difficulties\n",
    "\n",
    "type_dataset = TypeDataset(\n",
    "    data=data, \n",
    "    bpm_info=bpm_info_dict, \n",
    "    score_positions=score_positions_dict,\n",
    "    window_size=WINDOW_SIZE  # 40 frames before and after\n",
    ")\n",
    "\n",
    "# Below is the training code ---------------------------------------------------------------------------------------------------\n",
    "# # Split the dataset\n",
    "type_train_size = int(0.8 * len(type_dataset))\n",
    "type_val_size = len(type_dataset) - type_train_size\n",
    "type_train_dataset, type_val_dataset = random_split(type_dataset, [type_train_size, type_val_size])\n",
    "\n",
    "print(f\"Type Train Size: {len(type_train_dataset)}\")\n",
    "print(f\"Type Validation Size: {len(type_val_dataset)}\")\n",
    "\n",
    "# Create test set (using part of the validation set as test set)\n",
    "type_test_size = int(0.5 * len(type_val_dataset))\n",
    "type_val_size = len(type_val_dataset) - type_test_size\n",
    "type_val_dataset, type_test_dataset = random_split(type_val_dataset, [type_val_size, type_test_size])\n",
    "\n",
    "print(f\"Type Validation Size after split: {len(type_val_dataset)}\")\n",
    "print(f\"Type Test Size: {len(type_test_dataset)}\")\n",
    "\n",
    "type_train_loader = DataLoader(type_train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate_fn_padded_type)\n",
    "type_val_loader = DataLoader(type_val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded_type)\n",
    "type_test_loader = DataLoader(type_test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded_type)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Type Model Definition and Training\n",
    "\n",
    "# Initialize Type model\n",
    "num_types = 5  # Adjust based on requirements\n",
    "type_model = CNNTypePredictor(input_channels=NMELS, num_types=num_types, dropout=DROPOUT)\n",
    "type_model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "type_optimizer = torch.optim.Adam(type_model.parameters(), lr=LEARNING_RATE)\n",
    "type_loss_fn = FocalLoss(alpha=1.0, gamma=2, reduction='mean')\n",
    "\n",
    "\n",
    "# Train the best Type model\n",
    "best_type_val_loss = float('inf')\n",
    "best_type_model_path = \"model/best_cnn_type_model.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Training Type Model\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss, train_acc = train_epoch_cnn_type(type_model, type_train_loader, type_optimizer, device, type_loss_fn, num_types)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc = validate_epoch_cnn_type(type_model, type_val_loader, device, type_loss_fn, num_types)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save the model if validation loss is lower\n",
    "    if val_loss < best_type_val_loss:\n",
    "        best_type_val_loss = val_loss\n",
    "        torch.save(type_model.state_dict(), best_type_model_path)\n",
    "        print(\"Saved Best Type Model\")\n",
    "\n",
    "# Load the best Type model\n",
    "type_model.load_state_dict(torch.load(best_type_model_path))\n",
    "type_model.to(device)\n",
    "type_model.eval()\n",
    "# Below is the training code ---------------------------------------------------------------------------------------------------\n",
    "\n",
    "num_types = 5  # Adjust based on requirements\n",
    "best_presence_model_path = \"model/best_cnn_onset_model.pth\"\n",
    "best_type_model_path = \"model/best_cnn_type_model.pth\"\n",
    "\n",
    "presence_model = CNNOnsetDetector(input_channels=NMELS, num_classes=1, dropout=DROPOUT)\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path, map_location=device))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()  # Switch to evaluation mode\n",
    "\n",
    "type_model = CNNTypePredictor(input_channels=NMELS, num_types=num_types, dropout=DROPOUT)\n",
    "type_model.load_state_dict(torch.load(best_type_model_path, map_location=device))\n",
    "type_model.to(device)\n",
    "type_model.eval()\n",
    "\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.clouddiver.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/arwtdydhqhfa.helamind.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/andogaru.fumiko.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.summernight.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.cereris.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.alone.cytoidlevel/level.json\n",
      "未找到音频文件 �TAKUMI³�OЯDIN -Apocalyptic War-(Re Mastering).mp3 对应于 song ID ant.ordin-tc 在 /data1/yuchen/cytoid/final_code/../dataset/A/ant.ordin-tc.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anthony.lolk_muricaaaaa.cytoidlevel/level.json\n",
      "未找到音频文件 Langley_D - deli.+駄々子 - 最果ての勇者にラブソングを.ogg 对应于 song ID anoppo.furiy 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.furiy.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/aboal.43201.cytoidlevel/level.json\n",
      "未找到音频文件 Vicetone、Kat Nestel - Angels (Radio Edit).wav 对应于 song ID asuna_37 在 /data1/yuchen/cytoid/final_code/../dataset/A/asuna_37.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.rainbow.cytoidlevel/level.json\n",
      "未找到音频文件 self-dissociation - Lidelle、Sobrem、Sennzai.ogg 对应于 song ID anoppo.selfdissociation 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.selfdissociation.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.rainmaker.cytoidlevel/level.json\n",
      "未找到音频文件 コンウェイの子 - sta.ogg 对应于 song ID anoppo.conwayschild 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.conwayschild.cytoidlevel\n",
      "未找到 charts 文件 ARo.txt 对应于 song ID enteraname6 在 /data1/yuchen/cytoid/final_code/../dataset/A/AR-1.cytoidlevel\n",
      "未找到音频文件 黒魔 - Banbard (Chroma Remix).ogg 对应于 song ID anoppo.banbard 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.banbard.cytoidlevel\n",
      "未找到音频文件 削除 (Sakuzyo) - Amateras.ogg 对应于 song ID anoppo.amateras 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.amateras.cytoidlevel\n",
      "未找到音频文件 かめりあ_初音ミク-ヒアソビ-_feat.-初音ミク_(2).ogg 对应于 song ID aniloid.hiasobi 在 /data1/yuchen/cytoid/final_code/../dataset/A/aniloid.hiasobi.cytoidlevel\n",
      "未找到 charts 文件 俗物フェスティバル.json 对应于 song ID anoppo.su 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.su.cytoidlevel\n",
      "未找到音频文件 Sta _ B - スーパーシンメトリー(1).mp3 对应于 song ID anoppo.super 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.super.cytoidlevel\n",
      "未找到音频文件 削除 - PANDORA PARADOXXX.ogg 对应于 song ID anoppo.pandora 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.pandora.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/ant.future.dominators.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.cord.reborn.cytoidlevel/level.json\n",
      "未找到音频文件 With a Billion Worldful of 3 - Mili、DE DE MOUSE.ogg 对应于 song ID anoppo.withabillionworldfulofthree 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.withabillionworldfulofthree.cytoidlevel\n",
      "未找到音频文件 天hshsP.mp3 对应于 song ID angelll.theweak 在 /data1/yuchen/cytoid/final_code/../dataset/A/angelll.theweak.cytoidlevel\n",
      "未找到音频文件 【Hardcore】Requillio _ Dopam!ne 👻Free DL👻.mp3 对应于 song ID ant.requillio-t3 在 /data1/yuchen/cytoid/final_code/../dataset/A/ant.requillio-t3.cytoidlevel\n",
      "无法读取 /data1/yuchen/cytoid/final_code/../dataset/A/archore.lnd.lnyh.cytoidlevel/level.json: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/ap_mumayoru.ely.cytoidlevel/level.json\n",
      "未找到音频文件 kei_iwata - フロンティア↑↑エクスプローラー.ogg 对应于 song ID amaneku.frontier_exploler 在 /data1/yuchen/cytoid/final_code/../dataset/A/amaneku.frontier_exploler.cytoidlevel\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/ap_megalice.ely.cytoidlevel/level.json\n",
      "JSON 解析错误: /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.wwp.cytoidlevel/level.json\n",
      "未找到音频文件 (音源) 【SDVX】 そして黄金郷へ 【NOFX】 - 1.(音源) [SDVX] そして黄金郷へ [NOFX](Av29726758,P1).mp3 对应于 song ID anoppo.golden 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.golden.cytoidlevel\n",
      "未找到音频文件 雲落kyuu天 - Chapter.Q：Euphoric World - Rabbit House.ogg 对应于 song ID anoppo.euphoricworld 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.euphoricworld.cytoidlevel\n",
      "未找到音频文件 Sta,bqスタヂオ - アージェントシンメトリー.ogg 对应于 song ID anoppo.ink2 在 /data1/yuchen/cytoid/final_code/../dataset/A/anoppo.ink2.cytoidlevel\n",
      "目录不存在: /data1/yuchen/cytoid/final_code/../dataset/C\n",
      "未找到音频文件 kanone,Sennzai - 花と、雪と、ドラムンベース.ogg 对应于 song ID ztz.huayilun 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.huayilun.cytoidlevel\n",
      "未找到音频文件 申东辉 - NB Blast.mp3 对应于 song ID zeng.nbblast 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.nbblast.cytoidlevel\n",
      "未找到音频文件 イロドリミドリ - conflict (斉唱).ogg 对应于 song ID ztz.conflictcover 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.conflictcover.cytoidlevel\n",
      "未找到音频文件 Rintaro Soma - sølips.ogg 对应于 song ID ztz.solips 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.solips.cytoidlevel\n",
      "未找到音频文件 モリモリあつし - Grand-Guignol.mp3 对应于 song ID zeng.grandguignol 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.grandguignol.cytoidlevel\n",
      "未找到音频文件 星河一天.mp3 对应于 song ID zirei.st 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.st.cytoidlevel\n",
      "未找到音频文件 ビートまりお,あまね - ウサテイ20XX.ogg 对应于 song ID ztz.usatei20xxre 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.usatei20xxre.cytoidlevel\n",
      "未找到音频文件 かめりあ - Hello (BPM) 2021.mp3 对应于 song ID zeng.hellobpm 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.hellobpm.cytoidlevel\n",
      "未找到音频文件 Σvreka.mp3 对应于 song ID zirei.evreka 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.evreka.cytoidlevel\n",
      "未找到音频文件 モリモリあつし - Grand-Guignol.mp3 对应于 song ID zeng.grand 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.grand.cytoidlevel\n",
      "未找到音频文件 モンダイナイトリッパー！.mp3 对应于 song ID zirei.mondai 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.mondai.cytoidlevel\n",
      "未找到音频文件 卢文韬 - 奇轮！我的英雄（《激战奇轮2》OP）.mp3 对应于 song ID zeng.qilunmyhero 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.qilunmyhero.cytoidlevel\n",
      "未找到音频文件 六兆年と一夜物語，，.mp3 对应于 song ID zhong_yu_six 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zhong_yu_six.cytoidlevel\n",
      "未找到音频文件 細江慎治 - Kattobi KEIKYU Rider.ogg 对应于 song ID ztz.kattobikeikyurider 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.kattobikeikyurider.cytoidlevel\n",
      "未找到音频文件 Team Grimoire - Excalibur ～Revived resolution～.ogg 对应于 song ID ztz.excalibur 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.excalibur.cytoidlevel\n",
      "未找到音频文件 ぺのれり - Desperado Waltz.ogg 对应于 song ID ztz.desperadowaltz 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.desperadowaltz.cytoidlevel\n",
      "未找到音频文件 miko - 患部で止まってすぐ溶ける - 狂気の优昙华院.ogg 对应于 song ID ztz.huanbu 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.huanbu.cytoidlevel\n",
      "未找到音频文件 V∅rstia.mp3 对应于 song ID zirei.vo 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.vo.cytoidlevel\n",
      "未找到音频文件 ひとりきりのエデン.mp3 对应于 song ID zirei.d36 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.d36.cytoidlevel\n",
      "未找到音频文件 朧月.mp3 对应于 song ID zirei.ml 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.ml.cytoidlevel\n",
      "未找到音频文件 ビートまりお,あまね - ウサテイ20XX.mp3 对应于 song ID ztz.usatei20xx 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.usatei20xx.cytoidlevel\n",
      "未找到音频文件 ピノキオピー,初音ミク - 腐れ外道とチョコレゐト.ogg 对应于 song ID ztz.heterodoxusandchocolate 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.heterodoxusandchocolate.cytoidlevel\n",
      "未找到音频文件 初音 - 千本桜【名伶計畫 F 中文字幕】.mp3 对应于 song ID zhong_yu_1219 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zhong_yu_1219.cytoidlevel\n",
      "未找到音频文件 Se-U-Ra - ネジマキセカイの狂騒曲.mp3 对应于 song ID zeng.kuangsao 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.kuangsao.cytoidlevel\n",
      "未找到音频文件 超熊貓的周遊記.mp3 对应于 song ID zirei.fanta 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.fanta.cytoidlevel\n",
      "未找到音频文件 Taikes - 世界函数~World Function~.mp3 对应于 song ID zeng.worldfunction 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.worldfunction.cytoidlevel\n",
      "未找到音频文件 Ponchi,打打だいず - 星河一天 (Ponchi♪Remix).ogg 对应于 song ID ztz.xhytrmx 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.xhytrmx.cytoidlevel\n",
      "未找到音频文件 デルタライズクローのテーマ-安濑圣.mp3 对应于 song ID ztz.delta 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.delta.cytoidlevel\n",
      "未找到音频文件 盟月.mp3 对应于 song ID zirei.ddd 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.ddd.cytoidlevel\n",
      "未找到音频文件 小野秀幸 - Prophesy One.ogg 对应于 song ID ztz.prophesy1 在 /data1/yuchen/cytoid/final_code/../dataset/Z/ztz.prophesy1.cytoidlevel\n",
      "未找到音频文件 stεganography.mp3 对应于 song ID zirei.steganography 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zirei.steganography.cytoidlevel\n",
      "未找到 charts 文件 loveand - 副本.txt 对应于 song ID zeng.loveandj 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.loveandj.cytoidlevel\n",
      "未找到 charts 文件 emp - 副本.txt 对应于 song ID zeng.emp 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.emp.cytoidlevel\n",
      "未找到音频文件 清水達也 - IMAGE-MATERIAL-.mp3 对应于 song ID zeng.image 在 /data1/yuchen/cytoid/final_code/../dataset/Z/zeng.image.cytoidlevel\n",
      "总共跳过的曲子数量: 69\n",
      "跳过原因 'json_decode_error': 15 个曲子\n",
      "跳过原因 'missing_audio_file': 49 个曲子\n",
      "跳过原因 'missing_charts_file': 4 个曲子\n",
      "跳过原因 'read_error': 1 个曲子\n",
      "跳过原因 'missing_directory': 1 个曲子\n",
      "Filtered Data Count (Difficulty>=15): 217\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/artzumaru.asunoyozorashoukanhen.cytoidlevel/AsunoYozora.hard.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.miracleallextracoremix.cytoidlevel/ex.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.pandora06.cytoidlevel/ex.Tag.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.pandora01.cytoidlevel/exnewnew.Tag.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.calamityfortune.cytoidlevel/hard.txt\n",
      "JSON decode error for file: /data1/yuchen/cytoid/final_code/../dataset/A/atmzero.intensesinging.cytoidlevel/intense.Tag.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence Train Size: 858862\n",
      "Presence Validation Size: 214716\n",
      "Presence Validation Size after split: 107358\n",
      "Presence Test Size: 107358\n",
      "Epoch 1/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3996\n",
      "Saved Best Presence Model\n",
      "Epoch 2/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3695\n",
      "Saved Best Presence Model\n",
      "Epoch 3/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3430\n",
      "Saved Best Presence Model\n",
      "Epoch 4/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3294\n",
      "Saved Best Presence Model\n",
      "Epoch 5/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3150\n",
      "Saved Best Presence Model\n",
      "Epoch 6/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3057\n",
      "Saved Best Presence Model\n",
      "Epoch 7/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2988\n",
      "Saved Best Presence Model\n",
      "Epoch 8/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2934\n",
      "Saved Best Presence Model\n",
      "Epoch 9/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2872\n",
      "Saved Best Presence Model\n",
      "Epoch 10/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2834\n",
      "Saved Best Presence Model\n",
      "Epoch 11/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2771\n",
      "Saved Best Presence Model\n",
      "Epoch 12/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2765\n",
      "Saved Best Presence Model\n",
      "Epoch 13/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2746\n",
      "Saved Best Presence Model\n",
      "Epoch 14/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2748\n",
      "Epoch 15/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2700\n",
      "Saved Best Presence Model\n",
      "Epoch 16/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2707\n",
      "Epoch 17/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2649\n",
      "Saved Best Presence Model\n",
      "Epoch 18/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2646\n",
      "Saved Best Presence Model\n",
      "Epoch 19/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2626\n",
      "Saved Best Presence Model\n",
      "Epoch 20/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2617\n",
      "Saved Best Presence Model\n",
      "Epoch 21/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2600\n",
      "Saved Best Presence Model\n",
      "Epoch 22/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2579\n",
      "Saved Best Presence Model\n",
      "Epoch 23/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2619\n",
      "Epoch 24/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2576\n",
      "Saved Best Presence Model\n",
      "Epoch 25/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2602\n",
      "Epoch 26/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2557\n",
      "Saved Best Presence Model\n",
      "Epoch 27/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2583\n",
      "Epoch 28/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2545\n",
      "Saved Best Presence Model\n",
      "Epoch 29/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2545\n",
      "Saved Best Presence Model\n",
      "Epoch 30/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2543\n",
      "Saved Best Presence Model\n",
      "Epoch 31/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2520\n",
      "Saved Best Presence Model\n",
      "Epoch 32/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2531\n",
      "Epoch 33/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2526\n",
      "Epoch 34/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2506\n",
      "Saved Best Presence Model\n",
      "Epoch 35/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2528\n",
      "Epoch 36/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2504\n",
      "Saved Best Presence Model\n",
      "Epoch 37/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2506\n",
      "Epoch 38/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2498\n",
      "Saved Best Presence Model\n",
      "Epoch 39/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2491\n",
      "Saved Best Presence Model\n",
      "Epoch 40/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2503\n",
      "Epoch 41/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2486\n",
      "Saved Best Presence Model\n",
      "Epoch 42/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2474\n",
      "Saved Best Presence Model\n",
      "Epoch 43/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2475\n",
      "Epoch 44/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2479\n",
      "Epoch 45/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2472\n",
      "Saved Best Presence Model\n",
      "Epoch 46/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2492\n",
      "Epoch 47/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2457\n",
      "Saved Best Presence Model\n",
      "Epoch 48/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2474\n",
      "Epoch 49/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2457\n",
      "Epoch 50/50 - Training Presence Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205621/3220993348.py:1229: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Train Size: 858862\n",
      "Type Validation Size: 214716\n",
      "Type Validation Size after split: 107358\n",
      "Type Test Size: 107358\n",
      "Epoch 1/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1162, Train Acc: 83.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1110, Validation Acc: 83.77%\n",
      "Saved Best Type Model\n",
      "Epoch 2/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1107, Train Acc: 83.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1060, Validation Acc: 83.95%\n",
      "Saved Best Type Model\n",
      "Epoch 3/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1071, Train Acc: 83.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1023, Validation Acc: 84.24%\n",
      "Saved Best Type Model\n",
      "Epoch 4/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1041, Train Acc: 84.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0988, Validation Acc: 84.75%\n",
      "Saved Best Type Model\n",
      "Epoch 5/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1021, Train Acc: 84.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0965, Validation Acc: 85.04%\n",
      "Saved Best Type Model\n",
      "Epoch 6/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1002, Train Acc: 84.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0944, Validation Acc: 85.43%\n",
      "Saved Best Type Model\n",
      "Epoch 7/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0987, Train Acc: 84.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0936, Validation Acc: 85.50%\n",
      "Saved Best Type Model\n",
      "Epoch 8/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0976, Train Acc: 85.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0915, Validation Acc: 85.89%\n",
      "Saved Best Type Model\n",
      "Epoch 9/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0966, Train Acc: 85.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0907, Validation Acc: 86.11%\n",
      "Saved Best Type Model\n",
      "Epoch 10/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0957, Train Acc: 85.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0899, Validation Acc: 86.11%\n",
      "Saved Best Type Model\n",
      "Epoch 11/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0947, Train Acc: 85.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0896, Validation Acc: 86.29%\n",
      "Saved Best Type Model\n",
      "Epoch 12/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0940, Train Acc: 85.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0880, Validation Acc: 86.39%\n",
      "Saved Best Type Model\n",
      "Epoch 13/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0934, Train Acc: 85.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0887, Validation Acc: 86.56%\n",
      "Epoch 14/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0930, Train Acc: 85.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0894, Validation Acc: 86.34%\n",
      "Epoch 15/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0925, Train Acc: 85.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0875, Validation Acc: 86.56%\n",
      "Saved Best Type Model\n",
      "Epoch 16/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0919, Train Acc: 85.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0867, Validation Acc: 86.64%\n",
      "Saved Best Type Model\n",
      "Epoch 17/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0916, Train Acc: 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0861, Validation Acc: 86.79%\n",
      "Saved Best Type Model\n",
      "Epoch 18/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0911, Train Acc: 86.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0856, Validation Acc: 86.66%\n",
      "Saved Best Type Model\n",
      "Epoch 19/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0907, Train Acc: 86.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0855, Validation Acc: 86.73%\n",
      "Saved Best Type Model\n",
      "Epoch 20/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0905, Train Acc: 86.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0858, Validation Acc: 86.91%\n",
      "Epoch 21/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0901, Train Acc: 86.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0850, Validation Acc: 86.90%\n",
      "Saved Best Type Model\n",
      "Epoch 22/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0900, Train Acc: 86.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0841, Validation Acc: 86.98%\n",
      "Saved Best Type Model\n",
      "Epoch 23/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0897, Train Acc: 86.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0848, Validation Acc: 86.78%\n",
      "Epoch 24/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0895, Train Acc: 86.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0846, Validation Acc: 86.98%\n",
      "Epoch 25/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0891, Train Acc: 86.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0838, Validation Acc: 86.91%\n",
      "Saved Best Type Model\n",
      "Epoch 26/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0892, Train Acc: 86.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0845, Validation Acc: 87.06%\n",
      "Epoch 27/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0889, Train Acc: 86.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0826, Validation Acc: 87.28%\n",
      "Saved Best Type Model\n",
      "Epoch 28/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0886, Train Acc: 86.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0834, Validation Acc: 87.16%\n",
      "Epoch 29/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 85.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 30/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 31/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 32/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 33/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 34/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 35/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 36/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 37/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 38/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 39/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 40/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 41/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 42/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 43/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 44/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 45/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 46/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 47/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 48/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 49/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n",
      "Epoch 50/50 - Training Type Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: nan, Train Acc: 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3205621/3220993348.py:1415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  type_model.load_state_dict(torch.load(best_type_model_path))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1426: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path, map_location=device))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1431: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  type_model.load_state_dict(torch.load(best_type_model_path, map_location=device))\n",
      "/tmp/ipykernel_3205621/3220993348.py:1435: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  presence_model.load_state_dict(torch.load(best_presence_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: nan, Validation Acc: 83.77%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNNOnsetDetector(\n",
       "  (conv1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=2560, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the result of both model\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  # 移动到最顶部\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from pathlib import Path\n",
    "import json\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import enum\n",
    "import tqdm\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, precision_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 常量定义\n",
    "\n",
    "# %%\n",
    "# STFT 常量\n",
    "SAMPLE_RATE = 22050  \n",
    "HOP_LENGTH = 512     \n",
    "NMELS = 128        \n",
    "WINDOW_SIZE = 40  # 前后帧数\n",
    "NUM_EPOCHS = 50    # 训练轮数\n",
    "BATCH_SIZE = 64    # 批大小\n",
    "LEARNING_RATE = 1e-3\n",
    "DROPOUT = 0.5      # Dropout率\n",
    "\n",
    "# 检查 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 数据预处理函数\n",
    "\n",
    "# %%\n",
    "def contains_non_ascii(s: str) -> bool:\n",
    "    \"\"\"检查字符串中是否包含非ASCII字符。\"\"\"\n",
    "    return any(ord(c) > 127 for c in s)\n",
    "\n",
    "def extract_level_json_multiple(directories: List[Path], min_difficulty: int = 15) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    从多个目录中提取level.json文件，整理相关信息，并筛选出指定难度的曲目。\n",
    "    如果遇到无法解析的名字或其他问题，直接跳过该曲子。\n",
    "\n",
    "    Args:\n",
    "        directories (List[Path]): 包含多个子文件夹的主目录列表。\n",
    "        min_difficulty (int): 最低难度级别。\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: 包含每个级别的相关信息，限定为 difficulty>=min_difficulty 的曲目。\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    skipped_songs = 0\n",
    "    skipped_reasons = defaultdict(int)\n",
    "\n",
    "    for directory in directories:\n",
    "        if not directory.exists():\n",
    "            print(f\"目录不存在: {directory}\")\n",
    "            skipped_reasons['missing_directory'] += 1\n",
    "            continue\n",
    "        for folder_path in directory.iterdir():\n",
    "            if not folder_path.is_dir():\n",
    "                continue\n",
    "            json_file_path = folder_path / 'level.json'\n",
    "            if not json_file_path.is_file():\n",
    "                print(f\"缺少 level.json 文件在 {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_level_json'] += 1\n",
    "                continue\n",
    "            try:\n",
    "                with json_file_path.open('r', encoding='utf-8') as json_file:\n",
    "                    level_data = json.load(json_file)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"JSON 解析错误: {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['json_decode_error'] += 1\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"无法读取 {json_file_path}: {e}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['read_error'] += 1\n",
    "                continue\n",
    "\n",
    "            # 确保所有必要的字段存在\n",
    "            try:\n",
    "                level_id = level_data['id']\n",
    "                charts = level_data['charts']\n",
    "                music = level_data['music']\n",
    "            except KeyError as e:\n",
    "                print(f\"缺少键 {e} 在文件: {json_file_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_keys'] += 1\n",
    "                continue\n",
    "\n",
    "            if not charts:\n",
    "                print(f\"在文件 {json_file_path} 中未找到任何 charts\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['empty_charts'] += 1\n",
    "                continue\n",
    "\n",
    "            chart_difficulty = charts[0].get('difficulty', 0)\n",
    "            if chart_difficulty < min_difficulty:\n",
    "                continue\n",
    "\n",
    "            audio_file_name = music.get('path', '')\n",
    "            if not audio_file_name:\n",
    "                print(f\"在文件 {json_file_path} 中未指定 music path\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_music_path'] += 1\n",
    "                continue\n",
    "\n",
    "            audio_file_extensions = ['.mp3', '.ogg', '.wav']\n",
    "            audio_file_path = None\n",
    "            for ext in audio_file_extensions:\n",
    "                aud_path = folder_path / audio_file_name\n",
    "                if aud_path.suffix.lower() == ext and aud_path.is_file():\n",
    "                    audio_file_path = aud_path\n",
    "                    break\n",
    "            if audio_file_path is None:\n",
    "                print(f\"未找到音频文件 {audio_file_name} 对应于 song ID {level_id} 在 {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_audio_file'] += 1\n",
    "                continue\n",
    "\n",
    "            charts_path = folder_path / charts[0].get('path', '')\n",
    "            if not charts_path.is_file():\n",
    "                print(f\"未找到 charts 文件 {charts[0].get('path', '')} 对应于 song ID {level_id} 在 {folder_path}\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['missing_charts_file'] += 1\n",
    "                continue\n",
    "\n",
    "            # 创建唯一的ID，确保名称可解析\n",
    "            unique_id = f\"{directory.name}_{level_id}\"\n",
    "            try:\n",
    "                unique_id.encode('ascii')  # 检查是否为ASCII\n",
    "            except UnicodeEncodeError:\n",
    "                print(f\"无法解析的 unique_id: {unique_id}，跳过该曲子\")\n",
    "                skipped_songs += 1\n",
    "                skipped_reasons['unparseable_unique_id'] += 1\n",
    "                continue\n",
    "\n",
    "            # 添加到结果\n",
    "            result[unique_id] = {\n",
    "                'level': level_data,\n",
    "                'mp3_path': str(audio_file_path),\n",
    "                'charts_path': str(charts_path),\n",
    "                'charter': level_data.get('charter', ''),\n",
    "                'type': charts[0].get('type', ''),\n",
    "                'difficulty': chart_difficulty\n",
    "            }\n",
    "\n",
    "    print(f\"总共跳过的曲子数量: {skipped_songs}\")\n",
    "    for reason, count in skipped_reasons.items():\n",
    "        print(f\"跳过原因 '{reason}': {count} 个曲子\")\n",
    "    return result\n",
    "\n",
    "def extract_charts(path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    从JSON文件中提取图表数据。\n",
    "\n",
    "    Args:\n",
    "        path (str): 图表JSON文件的路径。\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: 图表数据。\n",
    "    \"\"\"\n",
    "    file_path = Path(path)\n",
    "    if file_path.exists() and file_path.is_file():\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                data = json.load(f)\n",
    "                return data\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"JSON decode error for file: {path}\")\n",
    "    return {}\n",
    "\n",
    "def find_single_tempo_songs(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    筛选出BPM不变的歌曲。\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): 包含所有歌曲信息的字典。\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: BPM不变的歌曲列表。\n",
    "    \"\"\"\n",
    "    single_tempo_songs = []\n",
    "    for song_id, song in data.items():\n",
    "        charts_data = extract_charts(song['charts_path'])\n",
    "        if charts_data and 'tempo_list' in charts_data:\n",
    "            if len(charts_data['tempo_list']) == 1:\n",
    "                single_tempo_songs.append(song)\n",
    "    return single_tempo_songs\n",
    "\n",
    "def map_note_to_time(data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    将音符映射到时间。\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): 图表数据。\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: 每个音符的时间映射信息。\n",
    "    \"\"\"\n",
    "    time_base = data.get('time_base', 1000) \n",
    "    offset_universal = 0.033 \n",
    "    offset = data.get('music_offset', 0) - offset_universal\n",
    "    tempo_list = sorted(data.get('tempo_list', []), key=lambda x: x['tick'])  \n",
    "    note_list = data.get('note_list', [])\n",
    "    \n",
    "    note_time_map = []\n",
    "    accumulated_time = 0 \n",
    "    last_tick = 0  \n",
    "    if not tempo_list:\n",
    "        return note_time_map\n",
    "    current_tempo = tempo_list[0]['value']  \n",
    "    tempo_index = 0  \n",
    "\n",
    "    for note in note_list:\n",
    "        note_tick = note['tick']\n",
    "        while tempo_index < len(tempo_list) - 1 and tempo_list[tempo_index + 1]['tick'] <= note_tick:\n",
    "            next_tempo_tick = tempo_list[tempo_index + 1]['tick']\n",
    "            ticks_in_interval = next_tempo_tick - last_tick\n",
    "            tick_duration = (current_tempo / time_base) \n",
    "            accumulated_time += ticks_in_interval * tick_duration\n",
    "            last_tick = next_tempo_tick\n",
    "            tempo_index += 1\n",
    "            current_tempo = tempo_list[tempo_index]['value']\n",
    "\n",
    "        ticks_in_interval = note_tick - last_tick\n",
    "        tick_duration = (current_tempo / time_base) \n",
    "        note_time = accumulated_time + ticks_in_interval * tick_duration\n",
    "        note_time_map.append({\n",
    "            'note_id': note.get('id', 0),\n",
    "            'note_tick': note_tick,\n",
    "            'note_time_microseconds': note_time - offset * 1_000_000,\n",
    "            'note_type': note.get('type', 0),\n",
    "            'note_x': note.get('x', 0.0)\n",
    "        })\n",
    "\n",
    "    return note_time_map\n",
    "\n",
    "def generate_mel_spectrogram(\n",
    "    audio_path: Path,\n",
    "    log_enable: bool = True,\n",
    "    bpm_info: List[Dict[str, float]] = None,\n",
    "    note_info: List[Dict[str, Any]] = None,\n",
    "    max_frames: int = 5000  # 新增参数，限制最大帧数\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    生成Mel频谱图及相应的标签，并限制其长度不超过max_frames。\n",
    "    \n",
    "    Args:\n",
    "        audio_path (Path): 音频文件路径。\n",
    "        log_enable (bool): 是否进行对数变换。\n",
    "        bpm_info (List[Dict[str, float]]): BPM信息。\n",
    "        note_info (List[Dict[str, Any]]): 音符信息。\n",
    "        max_frames (int): 最大帧数。\n",
    "    \n",
    "    Returns:\n",
    "        dict: 包含Mel频谱图、presence标签和position_labels的字典。\n",
    "    \"\"\"\n",
    "    data, sr = librosa.load(str(audio_path), sr=SAMPLE_RATE)\n",
    "    assert sr == SAMPLE_RATE, f\"Expected sample rate {SAMPLE_RATE}, but got {sr}\"\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=data,\n",
    "        sr=sr, \n",
    "        hop_length=HOP_LENGTH, \n",
    "        fmin=30.0, \n",
    "        n_mels=NMELS, \n",
    "        htk=True\n",
    "    )\n",
    "    if log_enable:\n",
    "        mel = np.log(np.clip(mel, 1e-5, None))\n",
    "    mel = mel.T  # (时间步, 特征)\n",
    "\n",
    "    # 限制Mel频谱图的长度\n",
    "    if mel.shape[0] > max_frames:\n",
    "        mel = mel[:max_frames]\n",
    "\n",
    "    data_dic = {\"mel\": mel}\n",
    "\n",
    "    # 初始化presence标签和position_labels\n",
    "    presence_labels = np.zeros(mel.shape[0], dtype=int)  # presence标签\n",
    "    position_labels = -1 * np.ones(mel.shape[0], dtype=int)  # -1表示无音符\n",
    "\n",
    "    if bpm_info and note_info:\n",
    "        mel_length = mel.shape[0]\n",
    "        for note in note_info:\n",
    "            time_sec = note['note_time_microseconds'] / 1_000_000\n",
    "            frame_idx = int(time_sec * SAMPLE_RATE / HOP_LENGTH)\n",
    "            if 0 <= frame_idx < mel_length:  # 确保 frame_idx 非负且不超出\n",
    "                presence_labels[frame_idx] = 1  # Presence\n",
    "                # 计算相对于窗口中心的相对位置（假设窗口大小为40）\n",
    "                position = frame_idx  # 根据具体需求调整\n",
    "                position_labels[frame_idx] = position\n",
    "\n",
    "    data_dic[\"labels\"] = presence_labels  # shape: (mel_length,)\n",
    "    data_dic[\"position_labels\"] = position_labels  # shape: (mel_length,)\n",
    "\n",
    "    return data_dic\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 数据集与数据加载\n",
    "\n",
    "# %%\n",
    "class TimeUnit(enum.Enum):\n",
    "    milliseconds = \"milliseconds\"\n",
    "    frames = \"frames\"\n",
    "    seconds = \"seconds\"\n",
    "\n",
    "class OnsetDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset 类，用于加载和提供数据。\n",
    "    每个样本包含当前帧及其前后40个帧（共81帧）。\n",
    "    \"\"\"\n",
    "    def __init__(self, data: Dict[str, Any], bpm_info: Dict[str, List[Dict[str, float]]], score_positions: Dict[str, List[Dict[str, Any]]], window_size: int = 40, transform=None):\n",
    "        self.data = data\n",
    "        self.bpm_info = bpm_info\n",
    "        self.score_positions = score_positions\n",
    "        self.transform = transform\n",
    "        self.window_size = window_size\n",
    "        self.samples = self.prepare_samples()\n",
    "        \n",
    "    def prepare_samples(self) -> List[Tuple[np.ndarray, np.ndarray, int]]:\n",
    "        \"\"\"\n",
    "        准备数据样本，每个样本包含81帧的Mel频谱图和对应的标签。\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for song_id, song in self.data.items():\n",
    "            mp3_path = song[\"mp3_path\"]\n",
    "            charts_path = song[\"charts_path\"]\n",
    "            difficulty = song['difficulty']\n",
    "            \n",
    "            mel_dict = generate_mel_spectrogram(\n",
    "                audio_path=Path(mp3_path),\n",
    "                log_enable=True,\n",
    "                bpm_info=self.bpm_info.get(song_id, None),\n",
    "                note_info=self.score_positions.get(song_id, None)\n",
    "            )\n",
    "            if \"labels\" in mel_dict:\n",
    "                mel = mel_dict[\"mel\"]  # shape: (num_frames, n_mels)\n",
    "                labels = mel_dict[\"labels\"]  # shape: (num_frames,)\n",
    "\n",
    "                num_frames = mel.shape[0]\n",
    "                for i in range(num_frames):\n",
    "                    start = max(i - self.window_size, 0)\n",
    "                    end = min(i + self.window_size + 1, num_frames)\n",
    "                    \n",
    "                    # 填充不足的帧\n",
    "                    pad_before = self.window_size - i if i < self.window_size else 0\n",
    "                    pad_after = (i + self.window_size + 1) - num_frames if (i + self.window_size + 1) > num_frames else 0\n",
    "                    \n",
    "                    mel_window = mel[start:end]\n",
    "                    if pad_before > 0:\n",
    "                        mel_window = np.pad(mel_window, ((pad_before, 0), (0, 0)), mode='constant')\n",
    "                    if pad_after > 0:\n",
    "                        mel_window = np.pad(mel_window, ((0, pad_after), (0, 0)), mode='constant')\n",
    "                    \n",
    "                    label = labels[i]\n",
    "                    \n",
    "                    samples.append((mel_window, label, difficulty))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        mel_window, label, difficulty = self.samples[idx]\n",
    "        mel_window = torch.from_numpy(mel_window).float()  # shape: (81, n_mels)\n",
    "        label = torch.tensor(label).float()  # shape: ()\n",
    "        \n",
    "        if self.transform:\n",
    "            mel_window, label = self.transform(mel_window, label)\n",
    "\n",
    "        return mel_window, label, difficulty\n",
    "\n",
    "def collate_fn_padded(batch: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    自定义的collate_fn，用于处理批次数据。\n",
    "    \"\"\"\n",
    "    mel, labels, difficulties = zip(*batch)\n",
    "    \n",
    "    mel = torch.stack(mel, dim=0)  # (batch_size, 81, n_mels)\n",
    "    labels = torch.stack(labels, dim=0)  # (batch_size,)\n",
    "\n",
    "    return mel, labels, difficulties\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Presence模型定义（保持代码2几乎不变）\n",
    "\n",
    "# %%\n",
    "class CNNOnsetDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    基于卷积神经网络（CNN）的Onset检测模型。\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, num_classes: int = 1, dropout: float = 0.5):\n",
    "        super(CNNOnsetDetector, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # 计算池化后的特征长度\n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)  # 防止特征长度为0\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)  # 假设经过三次池化\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 81, n_mels]\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # 转换为 [batch_size, n_mels, 81]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 64, 40]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 128, 20]\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 256, 10]\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 2560]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)  # [batch_size, num_classes]\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CNNOnsetFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_channels: int, dropout: float = 0.5):\n",
    "        super(CNNOnsetFeatureExtractor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, 81, n_mels)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, n_mels, 81)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 64, 40)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 128, 20)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, 256, 10)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # (batch_size, 2560)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # (batch_size, 512)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 不再执行fc2，直接返回512维特征\n",
    "        return x\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Type模型定义（修改为CNN）\n",
    "\n",
    "# %%\n",
    "class CNNTypePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    基于卷积神经网络（CNN）的Type预测模型。\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, num_types: int = 5, dropout: float = 0.5):\n",
    "        super(CNNTypePredictor, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # 计算池化后的特征长度\n",
    "        self.pool_layers = 3\n",
    "        self.feature_length = 81\n",
    "        for _ in range(self.pool_layers):\n",
    "            self.feature_length = self.feature_length // 2\n",
    "        self.feature_length = max(self.feature_length, 1)  # 防止特征长度为0\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * self.feature_length, 512)  # 假设经过三次池化\n",
    "        self.fc_type = nn.Linear(512, num_types)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, 81, n_mels]\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)  # 转换为 [batch_size, n_mels, 81]\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 64, 40]\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 128, 20]\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch_size, 256, 10]\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 2560]\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)  # [batch_size, 512]\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        type_out = self.fc_type(x)  # [batch_size, num_types]\n",
    "        \n",
    "        return type_out\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 可视化函数\n",
    "\n",
    "# %%\n",
    "def visualize_presence_predictions(mel: np.ndarray, labels: np.ndarray, preds: np.ndarray, start_time: float = 0, end_time: float = 5):\n",
    "    \"\"\"\n",
    "    可视化模型的presence预测结果与真实标签。\n",
    "\n",
    "    Args:\n",
    "        mel (np.ndarray): Mel频谱图，形状为 (seq_len, feature_dim)\n",
    "        labels (np.ndarray): 真实labels，形状为 (seq_len,)\n",
    "        preds (np.ndarray): 模型预测的presence分数，形状为 (seq_len,)\n",
    "        start_time (float): 可视化的开始时间（秒）\n",
    "        end_time (float): 可视化的结束时间（秒）\n",
    "    \"\"\"\n",
    "    # 应用 Sigmoid 激活\n",
    "    presence_pred = 1 / (1 + np.exp(-preds))\n",
    "    \n",
    "    # 应用阈值为0.5\n",
    "    presence_final = (presence_pred >= 0.5).astype(int)\n",
    "\n",
    "    # 计算时间轴\n",
    "    total_time = mel.shape[0] * HOP_LENGTH / SAMPLE_RATE\n",
    "    times = np.linspace(0, total_time, num=mel.shape[0])\n",
    "\n",
    "    # 确定可视化的帧范围\n",
    "    start_frame = int(start_time * SAMPLE_RATE / HOP_LENGTH)\n",
    "    end_frame = int(end_time * SAMPLE_RATE / HOP_LENGTH)\n",
    "\n",
    "    # 确保end_frame不超过序列长度\n",
    "    end_frame = min(end_frame, mel.shape[0])\n",
    "\n",
    "    # 裁剪数据\n",
    "    mel_cropped = mel[start_frame:end_frame]\n",
    "    labels_cropped = labels[start_frame:end_frame]\n",
    "    presence_pred_cropped = presence_pred[start_frame:end_frame]\n",
    "    presence_final_cropped = presence_final[start_frame:end_frame]\n",
    "\n",
    "    # 创建子图\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "    # 绘制Mel频谱图\n",
    "    img = librosa.display.specshow(\n",
    "        mel_cropped.T,\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        x_coords=times[start_frame:end_frame],\n",
    "        ax=axs[0],\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        fmax=8000\n",
    "    )\n",
    "    axs[0].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img, ax=axs[0], format='%+2.0f dB')\n",
    "\n",
    "    # 绘制Presence预测与真实标签\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        presence_pred_cropped.flatten(),\n",
    "        label='Presence Prediction (Raw)',\n",
    "        color='red',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        presence_final_cropped,\n",
    "        label='Presence Prediction (Threshold=0.50)',\n",
    "        color='orange',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    axs[1].plot(\n",
    "        times[start_frame:end_frame],\n",
    "        labels_cropped.flatten(),\n",
    "        label='Presence Ground Truth',\n",
    "        color='blue',\n",
    "        linestyle='dashed'\n",
    "    )\n",
    "\n",
    "    axs[1].set_title('Presence Predictions vs Ground Truth (Threshold: 0.50)')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].set_xlabel('Time (s)')\n",
    "    axs[1].set_ylabel('Presence')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_presence_predictions_single(mel: np.ndarray, label: np.ndarray, pred: np.ndarray, start_time: float = 0, end_time: float = 5):\n",
    "    \"\"\"\n",
    "    可视化单个样本的presence预测结果与真实标签。\n",
    "    \n",
    "    Args:\n",
    "        mel (np.ndarray): Mel频谱图，形状为 (81, n_mels)\n",
    "        label (np.ndarray): 真实labels，形状为 (1,)\n",
    "        pred (np.ndarray): 模型预测的presence分数，形状为 (1,)\n",
    "        start_time (float): 可视化的开始时间（秒）\n",
    "        end_time (float): 可视化的结束时间（秒）\n",
    "    \"\"\"\n",
    "    # 应用 Sigmoid 激活\n",
    "    presence_pred = 1 / (1 + np.exp(-pred))\n",
    "    \n",
    "    # 应用阈值为0.5\n",
    "    presence_final = (presence_pred >= 0.5).astype(int)\n",
    "    \n",
    "    # 计算时间轴（假设窗口中心帧对应当前时间）\n",
    "    total_time = WINDOW_SIZE * 2 * HOP_LENGTH / SAMPLE_RATE  # 前后帧总时间\n",
    "    times = np.linspace(-WINDOW_SIZE * HOP_LENGTH / SAMPLE_RATE, WINDOW_SIZE * HOP_LENGTH / SAMPLE_RATE, num=mel.shape[0])\n",
    "    \n",
    "    # 创建子图\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15, 10), sharex=True, gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    # 绘制Mel频谱图\n",
    "    img = librosa.display.specshow(\n",
    "        mel.T,\n",
    "        sr=SAMPLE_RATE,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        x_coords=times,\n",
    "        ax=axs[0],\n",
    "        x_axis='time',\n",
    "        y_axis='mel',\n",
    "        fmax=8000\n",
    "    )\n",
    "    axs[0].set_title('Mel Spectrogram')\n",
    "    fig.colorbar(img, ax=axs[0], format='%+2.0f dB')\n",
    "    \n",
    "    # 绘制Presence预测与真实标签\n",
    "    axs[1].bar(0, presence_pred, label='Presence Prediction (Raw)', color='red', alpha=0.6)\n",
    "    axs[1].bar(0, presence_final, label='Presence Prediction (Threshold=0.50)', color='orange', alpha=0.6)\n",
    "    axs[1].bar(0, label, label='Presence Ground Truth', color='blue', alpha=0.6)\n",
    "    \n",
    "    axs[1].set_title('Presence Predictions vs Ground Truth')\n",
    "    axs[1].legend(loc='upper right')\n",
    "    axs[1].set_xlabel('Current Frame')\n",
    "    axs[1].set_ylabel('Presence')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_type_predictions(mel: np.ndarray, labels: np.ndarray, preds: np.ndarray, start_time: float = 0, end_time: float = 5, hop_length: int = HOP_LENGTH, sample_rate: int = SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    可视化模型的Type预测结果与真实标签。\n",
    "\n",
    "    Args:\n",
    "        mel (np.ndarray): Mel频谱图，形状为 (seq_len, feature_dim)\n",
    "        labels (np.ndarray): 真实labels，形状为 (seq_len,)\n",
    "        preds (np.ndarray): 模型预测的type分数，形状为 (seq_len, num_types)\n",
    "        start_time (float): 可视化的开始时间（秒）\n",
    "        end_time (float): 可视化的结束时间（秒）\n",
    "        hop_length (int): hop_length参数\n",
    "        sample_rate (int): 采样率\n",
    "    \"\"\"\n",
    "    # 应用 Softmax 激活\n",
    "    preds_prob = F.softmax(torch.tensor(preds), dim=-1).numpy()\n",
    "\n",
    "    # 计算时间轴\n",
    "    total_time = mel.shape[0] * hop_length / sample_rate\n",
    "    times = np.linspace(0, total_time, num=mel.shape[0])\n",
    "\n",
    "    # 确定可视化的帧范围\n",
    "    start_frame = int(start_time * sample_rate / hop_length)\n",
    "    end_frame = int(end_time * sample_rate / hop_length)\n",
    "\n",
    "    # 裁剪数据\n",
    "    labels_cropped = labels[start_frame:end_frame]\n",
    "    preds_cropped = preds_prob[start_frame:end_frame]\n",
    "    times_cropped = times[start_frame:end_frame]\n",
    "\n",
    "    # 定义颜色映射（使用matplotlib的tab10颜色集）\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    num_types = preds_cropped.shape[1]\n",
    "    colors = [cmap(i) for i in range(num_types)]\n",
    "\n",
    "    # 创建图表\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    # 绘制类型概率\n",
    "    for type_idx in range(num_types):\n",
    "        plt.plot(\n",
    "            times_cropped,\n",
    "            preds_cropped[:, type_idx],\n",
    "            label=f'Type {type_idx}',\n",
    "            color=colors[type_idx],\n",
    "            alpha=0.6\n",
    "        )\n",
    "\n",
    "    # 绘制真实标签\n",
    "    for idx, label in enumerate(labels_cropped):\n",
    "        if label == 0:\n",
    "            continue  # 跳过类型0（假设为无事件）\n",
    "        plt.scatter(\n",
    "            times_cropped[idx],\n",
    "            preds_cropped[idx, label],\n",
    "            color=colors[label],\n",
    "            marker='x',\n",
    "            s=50,\n",
    "            label=f'Ground Truth Type {label}' if idx == 0 else \"\",  # 只为图例添加一次\n",
    "            zorder=5\n",
    "        )\n",
    "        # 绘制竖线\n",
    "        plt.axvline(\n",
    "            x=times_cropped[idx],\n",
    "            color=colors[label],\n",
    "            linestyle='--',\n",
    "            alpha=0.5,\n",
    "            linewidth=1\n",
    "        )\n",
    "\n",
    "    # 添加标题和标签\n",
    "    plt.title('Type Probabilities and Ground Truth', fontsize=14)\n",
    "    plt.xlabel('Time (s)', fontsize=12)\n",
    "    plt.ylabel('Probability', fontsize=12)\n",
    "\n",
    "    # 设置图例，避免重复\n",
    "    handles, labels_legend = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels_legend, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize='small')\n",
    "\n",
    "    # 设置 x 轴范围\n",
    "    plt.xlim(start_time, end_time)\n",
    "\n",
    "    # 只在底部显示 y 轴标签\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.yaxis.set_label_coords(1.05, 0.5)\n",
    "\n",
    "    # 显示图表\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_position_predictions(true_positions: List[int], pred_positions: List[int], num_samples: int = 100):\n",
    "    \"\"\"\n",
    "    可视化真实位置与预测位置的对比。\n",
    "    \n",
    "    Args:\n",
    "        true_positions (List[int]): 真实位置列表。\n",
    "        pred_positions (List[int]): 预测位置列表。\n",
    "        num_samples (int): 可视化的样本数量。\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    if len(true_positions) < num_samples:\n",
    "        num_samples = len(true_positions)\n",
    "    indices = np.random.choice(len(true_positions), size=num_samples, replace=False)\n",
    "    true = np.array(true_positions)[indices]\n",
    "    pred = np.array(pred_positions)[indices]\n",
    "    \n",
    "    plt.scatter(range(num_samples), true, label='True Position', alpha=0.6, color='blue')\n",
    "    plt.scatter(range(num_samples), pred, label='Predicted Position', alpha=0.6, color='red')\n",
    "    plt.title('True vs Predicted Note Positions')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Position Index')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_position_distribution(true_positions: List[int], pred_positions: List[int]):\n",
    "    \"\"\"\n",
    "    可视化真实位置与预测位置的分布。\n",
    "    \n",
    "    Args:\n",
    "        true_positions (List[int]): 真实位置列表。\n",
    "        pred_positions (List[int]): 预测位置列表。\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(true_positions, bins=81, alpha=0.5, label='True Positions', color='blue', density=True)\n",
    "    plt.hist(pred_positions, bins=81, alpha=0.5, label='Predicted Positions', color='red', density=True)\n",
    "    plt.title('Distribution of True and Predicted Positions')\n",
    "    plt.xlabel('Position Index')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 训练与验证函数\n",
    "\n",
    "# %%\n",
    "# Presence模型训练函数\n",
    "def train_epoch_cnn(model: nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device, loss_fn: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    训练一个epoch（CNN版）。\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Presence\", leave=False)\n",
    "\n",
    "    for mel, labels, difficulties in progress_bar:\n",
    "        mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "        labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(mel)  # (batch_size, 1)\n",
    "        outputs = outputs.squeeze(1)  # (batch_size)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "# Presence模型验证函数\n",
    "def validate_epoch_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module) -> Tuple[float, Dict[int, Dict[str, List[Any]]]]:\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    difficulty_preds = defaultdict(lambda: {'y_true': [], 'y_scores': []})\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validation Presence\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, difficulties in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(mel)  # (batch_size, 1)\n",
    "            outputs = outputs.squeeze(1)  # (batch_size)\n",
    "            # 移除以下行，因为labels已经是 (batch_size,) 形状\n",
    "            # labels = labels.squeeze(1)  # (batch_size)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            # 收集预测分数和真实标签，按难度级别分组\n",
    "            presence_pred_np = outputs.cpu().numpy()\n",
    "            presence_target_np = labels.cpu().numpy()\n",
    "\n",
    "            for i in range(mel.size(0)):\n",
    "                difficulty = difficulties[i]\n",
    "                y_true = presence_target_np[i]\n",
    "                y_score = presence_pred_np[i]\n",
    "                difficulty_preds[difficulty]['y_true'].append(y_true)\n",
    "                difficulty_preds[difficulty]['y_scores'].append(y_score)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss, difficulty_preds\n",
    "\n",
    "# Type模型训练函数（CNN版）\n",
    "def train_epoch_cnn_type(model: nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, device: torch.device, loss_fn: nn.Module, num_types: int) -> float:\n",
    "    \"\"\"\n",
    "    训练一个epoch（Type CNN版）。\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Training Type CNN\", leave=False)\n",
    "\n",
    "    for mel, labels, lengths in progress_bar:\n",
    "        mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "        labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_fn(type_pred, labels)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # 计算准确率\n",
    "        preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1)\n",
    "        acc = (preds == labels).float().mean().item()\n",
    "        running_acc += acc\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Acc': f'{acc*100:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Type模型验证函数（CNN版）\n",
    "def validate_epoch_cnn_type(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module, num_types: int) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    在验证集上评估模型（CNN版）。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Validation Type CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, lengths in progress_bar:\n",
    "            mel = mel.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(type_pred, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # 计算准确率\n",
    "            preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1)\n",
    "            acc = (preds == labels).float().mean().item()\n",
    "            running_acc += acc\n",
    "\n",
    "            progress_bar.set_postfix({'Loss': f'{loss.item():.4f}', 'Acc': f'{acc*100:.2f}%'})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 模型评估函数\n",
    "\n",
    "# %%\n",
    "def evaluate_test_set_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module):\n",
    "    \"\"\"\n",
    "    在测试集上评估CNN模型。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    difficulty_metrics = defaultdict(lambda: {'y_true': [], 'y_pred': []})\n",
    "    all_preds, all_labels = [], []\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Testing Presence CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, difficulties in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(mel)  # (batch_size, 1)\n",
    "            outputs = outputs.squeeze(1)  # (batch_size)\n",
    "            labels = labels.squeeze(1)  # (batch_size)\n",
    "\n",
    "            # 计算损失（可选）\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # 收集预测和标签\n",
    "            presence_pred_np = outputs.cpu().numpy()\n",
    "            presence_target_np = labels.cpu().numpy()\n",
    "\n",
    "            # 应用 Sigmoid 激活\n",
    "            presence_pred_sigmoid = 1 / (1 + np.exp(-presence_pred_np))\n",
    "\n",
    "            # 使用阈值0.5进行预测\n",
    "            y_pred = (presence_pred_sigmoid >= 0.5).astype(int)\n",
    "            y_true = presence_target_np.astype(int)\n",
    "\n",
    "            # 收集所有预测和标签用于分布\n",
    "            all_preds.extend(presence_pred_sigmoid.tolist())\n",
    "            all_labels.extend(presence_target_np.tolist())\n",
    "\n",
    "            # 按难度级别分组\n",
    "            for i in range(mel.size(0)):\n",
    "                difficulty = difficulties[i]\n",
    "                difficulty_metrics[difficulty]['y_true'].append(y_true[i])\n",
    "                difficulty_metrics[difficulty]['y_pred'].append(y_pred[i])\n",
    "\n",
    "    # 转换为 NumPy 数组\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # 绘制分布\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(all_preds, bins=50, alpha=0.7, label=\"Predictions\", color=\"blue\", density=True)\n",
    "    plt.hist(all_labels, bins=50, alpha=0.7, label=\"Ground Truth\", color=\"orange\", density=True)\n",
    "    plt.title(\"Frame-wise Prediction and Ground Truth Distribution\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 计算每个难度级别的指标\n",
    "    final_metrics = {}\n",
    "    for diff, metrics in difficulty_metrics.items():\n",
    "        y_true = np.array(metrics['y_true'])\n",
    "        y_pred = np.array(metrics['y_pred'])\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        final_metrics[diff] = {\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "        print(f\"Difficulty {diff}: Accuracy={acc:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1 Score={f1:.4f}\")\n",
    "\n",
    "    return final_metrics\n",
    "\n",
    "def evaluate_test_set_type_cnn(model: nn.Module, dataloader: DataLoader, device: torch.device, loss_fn: nn.Module, num_types: int):\n",
    "    \"\"\"\n",
    "    在测试集上评估Type CNN模型。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=\"Testing Type CNN\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mel, labels, lengths in progress_bar:\n",
    "            mel = mel.to(device)  # (batch_size, 81, n_mels)\n",
    "            labels = labels.to(device)  # (batch_size,)\n",
    "\n",
    "            # 前向传播\n",
    "            type_pred = model(mel)  # (batch_size, num_types)\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(type_pred, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # 收集预测和标签\n",
    "            preds = torch.argmax(F.softmax(type_pred, dim=1), dim=1).cpu().numpy()\n",
    "            true = labels.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(true.tolist())\n",
    "\n",
    "    # 计算指标\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    print(f\"Type Prediction - Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1_score': f1}\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 数据准备\n",
    "\n",
    "# %%\n",
    "current_directory = Path().cwd()\n",
    "dataset_dirs = [\n",
    "    current_directory / \"../dataset/A\",\n",
    "    current_directory / \"../dataset/B\",\n",
    "    current_directory / \"../dataset/C\",\n",
    "    current_directory / \"../dataset/Z\"\n",
    "]\n",
    "data = extract_level_json_multiple(dataset_dirs, min_difficulty=15)\n",
    "print(f\"Filtered Data Count (Difficulty>=15): {len(data)}\")\n",
    "# data = dict(list(data.items())[:30])\n",
    "bpm_info_dict = {}\n",
    "score_positions_dict = {}\n",
    "\n",
    "for unique_id, song in data.items():\n",
    "    level_data = song['level']\n",
    "    song_id = unique_id  # 使用唯一ID\n",
    "    charts_data = extract_charts(song['charts_path'])\n",
    "    if charts_data:\n",
    "        bpm_info = charts_data.get('tempo_list', [])\n",
    "        bpm_info_dict[song_id] = bpm_info\n",
    "        note_time_map = map_note_to_time(charts_data) \n",
    "        # 每个音符的详细信息，包括时间、类型和位置\n",
    "        score_positions = [] \n",
    "        for note in note_time_map:\n",
    "            score_positions.append({\n",
    "                'note_time_microseconds': note['note_time_microseconds'],\n",
    "                'note_type': note.get('note_type', 0),  # 确保此字段存在\n",
    "                'note_x': note.get('note_x', 0.0)      # 确保此字段存在\n",
    "            })\n",
    "        score_positions_dict[song_id] = score_positions\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 定义数据集和 DataLoader\n",
    "\n",
    "# %%\n",
    "# 定义Presence数据集和 DataLoader\n",
    "presence_dataset = OnsetDataset(\n",
    "    data=data, \n",
    "    bpm_info=bpm_info_dict, \n",
    "    score_positions=score_positions_dict,\n",
    "    window_size=WINDOW_SIZE  # 前后40帧\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(presence_dataset))\n",
    "val_size = len(presence_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(presence_dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Presence Train Size: {len(train_dataset)}\")\n",
    "print(f\"Presence Validation Size: {len(val_dataset)}\")\n",
    "# 一下是train 的代码---------------------------------------------------------------------------------------------------\n",
    "# 创建测试集（使用验证集的一部分作为测试集）\n",
    "test_size = int(0.5 * len(val_dataset))\n",
    "val_size = len(val_dataset) - test_size\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "print(f\"Presence Validation Size after split: {len(val_dataset)}\")\n",
    "print(f\"Presence Test Size: {len(test_dataset)}\")\n",
    "\n",
    "presence_train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate_fn_padded)\n",
    "presence_val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded)\n",
    "presence_test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Presence模型训练与评估\n",
    "\n",
    "# %%\n",
    "# 初始化Presence模型\n",
    "presence_model = CNNOnsetDetector(input_channels=NMELS, num_classes=1, dropout=DROPOUT)\n",
    "presence_model.to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "presence_optimizer = torch.optim.Adam(presence_model.parameters(), lr=LEARNING_RATE)\n",
    "presence_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 训练最佳Presence模型\n",
    "best_presence_val_loss = float('inf')\n",
    "best_presence_model_path = \"model/best_cnn_onset_model.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Training Presence Model\")\n",
    "    \n",
    "    # 训练\n",
    "    train_loss = train_epoch_cnn(presence_model, presence_train_loader, presence_optimizer, device, presence_loss_fn)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # 验证\n",
    "    val_loss, val_difficulty_preds = validate_epoch_cnn(presence_model, presence_val_loader, device, presence_loss_fn)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # 如果验证损失更低，则保存模型\n",
    "    if val_loss < best_presence_val_loss:\n",
    "        best_presence_val_loss = val_loss\n",
    "        torch.save(presence_model.state_dict(), best_presence_model_path)\n",
    "        print(\"Saved Best Presence Model\")\n",
    "\n",
    "# 加载最佳Presence模型\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()\n",
    "# 一下是train 的代码---------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 定义Type数据集和 DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=2.0, gamma=2, reduction='mean'):\n",
    "        \"\"\"\n",
    "        alpha: 类别平衡因子，可用于在类不平衡时对少数类进行重权重\n",
    "        gamma: 难易度调控参数，gamma越大，越专注在难分类的样本上\n",
    "        reduction: 损失聚合方式，'mean'或'sum'\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: [batch_size, num_classes]\n",
    "        # targets: [batch_size]\n",
    "\n",
    "        # 获取预测的概率分布\n",
    "        probs = F.softmax(inputs, dim=1)\n",
    "        # 取出对应真实类别的预测概率\n",
    "        pt = probs[range(len(targets)), targets]\n",
    "\n",
    "        # focal loss公式\n",
    "        loss = -self.alpha * (1 - pt)**self.gamma * torch.log(pt)\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "# %%\n",
    "class TypeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset 类，用于加载和提供数据。\n",
    "    每个样本包含当前帧及其前后40个帧（共81帧）。\n",
    "    \"\"\"\n",
    "    def __init__(self, data: Dict[str, Any], bpm_info: Dict[str, List[Dict[str, float]]], score_positions: Dict[str, List[Dict[str, Any]]], window_size: int = 40, transform=None):\n",
    "        self.data = data\n",
    "        self.bpm_info = bpm_info\n",
    "        self.score_positions = score_positions\n",
    "        self.transform = transform\n",
    "        self.window_size = window_size\n",
    "        self.samples = self.prepare_samples()\n",
    "        \n",
    "    def prepare_samples(self) -> List[Tuple[np.ndarray, int, int]]:\n",
    "        \"\"\"\n",
    "        准备数据样本，每个样本包含81帧的Mel频谱图和对应的类型标签。\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for song_id, song in self.data.items():\n",
    "            mp3_path = song[\"mp3_path\"]\n",
    "            charts_path = song[\"charts_path\"]\n",
    "            difficulty = song['difficulty']\n",
    "            \n",
    "            mel_dict = generate_mel_spectrogram(\n",
    "                audio_path=Path(mp3_path),\n",
    "                log_enable=True,\n",
    "                bpm_info=self.bpm_info.get(song_id, None),\n",
    "                note_info=self.score_positions.get(song_id, None)\n",
    "            )\n",
    "            if \"labels\" in mel_dict:\n",
    "                mel = mel_dict[\"mel\"]  # shape: (num_frames, n_mels)\n",
    "                labels = mel_dict[\"labels\"]  # shape: (num_frames,)\n",
    "\n",
    "                num_frames = mel.shape[0]\n",
    "                for i in range(num_frames):\n",
    "                    start = max(i - self.window_size, 0)\n",
    "                    end = min(i + self.window_size + 1, num_frames)\n",
    "                    \n",
    "                    # 填充不足的帧\n",
    "                    pad_before = self.window_size - i if i < self.window_size else 0\n",
    "                    pad_after = (i + self.window_size + 1) - num_frames if (i + self.window_size + 1) > num_frames else 0\n",
    "                    \n",
    "                    mel_window = mel[start:end]\n",
    "                    if pad_before > 0:\n",
    "                        mel_window = np.pad(mel_window, ((pad_before, 0), (0, 0)), mode='constant')\n",
    "                    if pad_after > 0:\n",
    "                        mel_window = np.pad(mel_window, ((0, pad_after), (0, 0)), mode='constant')\n",
    "                    \n",
    "                    label = labels[i]\n",
    "                    \n",
    "                    samples.append((mel_window, label, difficulty))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "        \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        mel_window, label, difficulty = self.samples[idx]\n",
    "        mel_window = torch.from_numpy(mel_window).float()  # shape: (81, n_mels)\n",
    "        label = torch.tensor(label).long()  # shape: ()\n",
    "        \n",
    "        if self.transform:\n",
    "            mel_window, label = self.transform(mel_window, label)\n",
    "\n",
    "        return mel_window, label, difficulty\n",
    "\n",
    "def collate_fn_padded_type(batch: List[Tuple[torch.Tensor, torch.Tensor, int]]) -> Tuple[torch.Tensor, torch.Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    自定义的collate_fn，用于处理批次数据。\n",
    "    \"\"\"\n",
    "    mel, labels, difficulties = zip(*batch)\n",
    "    \n",
    "    mel = torch.stack(mel, dim=0)  # (batch_size, 81, n_mels)\n",
    "    labels = torch.stack(labels, dim=0)  # (batch_size,)\n",
    "\n",
    "    return mel, labels, difficulties\n",
    "\n",
    "type_dataset = TypeDataset(\n",
    "    data=data, \n",
    "    bpm_info=bpm_info_dict, \n",
    "    score_positions=score_positions_dict,\n",
    "    window_size=WINDOW_SIZE  # 前后40帧\n",
    ")\n",
    "\n",
    "# 一下是train 的代码---------------------------------------------------------------------------------------------------\n",
    "# # 划分数据集\n",
    "type_train_size = int(0.8 * len(type_dataset))\n",
    "type_val_size = len(type_dataset) - type_train_size\n",
    "type_train_dataset, type_val_dataset = random_split(type_dataset, [type_train_size, type_val_size])\n",
    "\n",
    "print(f\"Type Train Size: {len(type_train_dataset)}\")\n",
    "print(f\"Type Validation Size: {len(type_val_dataset)}\")\n",
    "\n",
    "# 创建测试集（使用验证集的一部分作为测试集）\n",
    "type_test_size = int(0.5 * len(type_val_dataset))\n",
    "type_val_size = len(type_val_dataset) - type_test_size\n",
    "type_val_dataset, type_test_dataset = random_split(type_val_dataset, [type_val_size, type_test_size])\n",
    "\n",
    "print(f\"Type Validation Size after split: {len(type_val_dataset)}\")\n",
    "print(f\"Type Test Size: {len(type_test_dataset)}\")\n",
    "\n",
    "type_train_loader = DataLoader(type_train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, collate_fn=collate_fn_padded_type)\n",
    "type_val_loader = DataLoader(type_val_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded_type)\n",
    "type_test_loader = DataLoader(type_test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False, collate_fn=collate_fn_padded_type)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Type模型定义与训练\n",
    "\n",
    "# %%\n",
    "# 初始化Type模型\n",
    "num_types = 5  # 根据需求调整\n",
    "type_model = CNNTypePredictor(input_channels=NMELS, num_types=num_types, dropout=DROPOUT)\n",
    "type_model.to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "type_optimizer = torch.optim.Adam(type_model.parameters(), lr=LEARNING_RATE)\n",
    "type_loss_fn = FocalLoss(alpha=1.0, gamma=2, reduction='mean')\n",
    "\n",
    "\n",
    "# 训练最佳Type模型\n",
    "best_type_val_loss = float('inf')\n",
    "best_type_model_path = \"model/best_cnn_type_model.pth\"\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS} - Training Type Model\")\n",
    "    \n",
    "    # 训练\n",
    "    train_loss, train_acc = train_epoch_cnn_type(type_model, type_train_loader, type_optimizer, device, type_loss_fn, num_types)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
    "    \n",
    "    # 验证\n",
    "    val_loss, val_acc = validate_epoch_cnn_type(type_model, type_val_loader, device, type_loss_fn, num_types)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # 如果验证损失更低，则保存模型\n",
    "    if val_loss < best_type_val_loss:\n",
    "        best_type_val_loss = val_loss\n",
    "        torch.save(type_model.state_dict(), best_type_model_path)\n",
    "        print(\"Saved Best Type Model\")\n",
    "\n",
    "# 加载最佳Type模型\n",
    "type_model.load_state_dict(torch.load(best_type_model_path))\n",
    "type_model.to(device)\n",
    "type_model.eval()\n",
    "# 是train 的代码---------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "num_types = 5  # 根据需求调整\n",
    "best_presence_model_path = \"model/best_cnn_onset_model.pth\"\n",
    "best_type_model_path = \"model/best_cnn_type_model.pth\"\n",
    "\n",
    "presence_model = CNNOnsetDetector(input_channels=NMELS, num_classes=1, dropout=DROPOUT)\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path, map_location=device))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()  # 切换到评估模式\n",
    "\n",
    "type_model = CNNTypePredictor(input_channels=NMELS, num_types=num_types, dropout=DROPOUT)\n",
    "type_model.load_state_dict(torch.load(best_type_model_path, map_location=device))\n",
    "type_model.to(device)\n",
    "type_model.eval()\n",
    "\n",
    "presence_model.load_state_dict(torch.load(best_presence_model_path))\n",
    "presence_model.to(device)\n",
    "presence_model.eval()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
